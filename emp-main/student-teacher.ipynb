{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda87e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/emp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using decoder type: mlp\n",
      "RUN EMP-M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=128, out_features=1, bias=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from hydra.utils import instantiate, to_absolute_path\n",
    "import torch\n",
    "from importlib import import_module\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "teacher_dict = {\n",
    "    \"_target_\": \"src.model.trainer_forecast.Trainer\",\n",
    "    \"historical_steps\": 50,\n",
    "    \"future_steps\": 60,\n",
    "    \"dim\": 128,\n",
    "    \"encoder_depth\": 4,\n",
    "    \"num_heads\": 8,\n",
    "    \"mlp_ratio\": 4.0,\n",
    "    \"qkv_bias\": False,\n",
    "    \"drop_path\": 0.2,\n",
    "    \"attention_type\": \"standard\",  # \"standard\", \"linear\", \"performer\"\n",
    "    \"decoder\": \"mlp\",  # Decoder type: \"mlp\" or \"detr\"\n",
    "    \"decoder_embed_dim\": None,\n",
    "    \"decoder_num_modes\": None,\n",
    "    \"decoder_hidden_dim\": None,\n",
    "    \"pretrained_weights\": None,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"epochs\": 20,\n",
    "    \"warmup_epochs\": 10,\n",
    "}\n",
    "\n",
    "if teacher_dict[\"decoder\"] == \"mlp\":\n",
    "    checkpoint = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/checkpoints/empm.ckpt\"\n",
    "else:\n",
    "    checkpoint = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/checkpoints/empd.ckpt\"\n",
    "assert os.path.exists(checkpoint), f\"Checkpoint {checkpoint} does not exist\"\n",
    "\n",
    "model_path = teacher_dict[\"_target_\"]\n",
    "module = import_module(model_path[: model_path.rfind(\".\")])\n",
    "Model: pl.LightningModule = getattr(module, model_path[model_path.rfind(\".\") + 1 :])\n",
    "teacher = Model.load_from_checkpoint(checkpoint, **teacher_dict)\n",
    "\n",
    "# Cut the layer that gives the logits and keep the \"penultimate\" layer\n",
    "teacher.net.dense_predictor.pop(-1)  \n",
    "teacher.net.decoder.loc.pop(-1)\n",
    "teacher.net.decoder.pi.pop(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14602a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model instantiated with the following configuration:\n",
      "net: EMP(\n",
      "  (h_proj): Linear(in_features=5, out_features=128, bias=True)\n",
      "  (h_embed): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.067)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.067)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.133)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.133)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.200)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.200)\n",
      "    )\n",
      "  )\n",
      "  (lane_embed): LaneEmbeddingLayer(\n",
      "    (first_conv): Sequential(\n",
      "      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (second_conv): Sequential(\n",
      "      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (pos_embed): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.067)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.067)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.133)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.133)\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.200)\n",
      "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.200)\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (decoder): MultimodalDecoder(\n",
      "    (mode_embed): Embedding(6, 128)\n",
      "    (loc): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (pi): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (dense_predictor): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "val_metrics: MetricCollection(\n",
      "  (MR): MR()\n",
      "  (brier-minFDE6): brierMinFDE()\n",
      "  (minADE1): minADE()\n",
      "  (minADE6): minADE()\n",
      "  (minFDE1): minFDE()\n",
      "  (minFDE6): minFDE(),\n",
      "  prefix=val_\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Print the model layers\n",
    "print(\"Teacher model instantiated with the following configuration:\")\n",
    "for name, layer in teacher.named_children():\n",
    "    print(f\"{name}: {layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f535032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using decoder type: mlp\n",
      "RUN EMP-M\n",
      "Student model instantiated with the following configuration:\n",
      "net: EMP(\n",
      "  (h_proj): Linear(in_features=5, out_features=64, bias=True)\n",
      "  (h_embed): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): PerformerAttention(\n",
      "        (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): PerformerAttention(\n",
      "        (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.100)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.100)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): PerformerAttention(\n",
      "        (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.200)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.200)\n",
      "    )\n",
      "  )\n",
      "  (lane_embed): LaneEmbeddingLayer(\n",
      "    (first_conv): Sequential(\n",
      "      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (second_conv): Sequential(\n",
      "      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (pos_embed): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): PerformerAttention(\n",
      "        (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): PerformerAttention(\n",
      "        (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.100)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.100)\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): PerformerAttention(\n",
      "        (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (out_proj): Linear(in_features=64, out_features=64, bias=False)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path1): DropPath(drop_prob=0.200)\n",
      "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0.0, inplace=False)\n",
      "        (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (drop2): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path2): DropPath(drop_prob=0.200)\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (decoder): MultimodalDecoder(\n",
      "    (mode_embed): Embedding(9, 64)\n",
      "    (loc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (pi): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (dense_predictor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "val_metrics: MetricCollection(\n",
      "  (MR): MR()\n",
      "  (brier-minFDE6): brierMinFDE()\n",
      "  (minADE1): minADE()\n",
      "  (minADE6): minADE()\n",
      "  (minFDE1): minFDE()\n",
      "  (minFDE6): minFDE(),\n",
      "  prefix=val_\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "student_dict = {\n",
    "    \"_target_\": \"src.model.trainer_forecast.Trainer\",\n",
    "    \"dim\": 64,\n",
    "    \"historical_steps\": 50,\n",
    "    \"future_steps\": 60,\n",
    "    \"encoder_depth\": 3,\n",
    "    \"num_heads\": 4,\n",
    "    \"mlp_ratio\": 2.0,\n",
    "    \"qkv_bias\": False,\n",
    "    \"drop_path\": 0.2,\n",
    "    \"attention_type\": \"performer\",  # \"standard\", \"linear\", \"performer\"\n",
    "    \"decoder\": \"mlp\",\n",
    "    \"decoder_embed_dim\": 64,\n",
    "    \"decoder_num_modes\": 9,\n",
    "    \"decoder_hidden_dim\": 256,\n",
    "    \"pretrained_weights\": None,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"epochs\": 60,\n",
    "    \"warmup_epochs\": 10,\n",
    "}\n",
    "\n",
    "student = instantiate(student_dict)\n",
    "# Remove the last layer from the encoder or decoder\n",
    "student.net.dense_predictor = student.net.dense_predictor[:-1]  \n",
    "student.net.decoder.loc = student.net.decoder.loc[:-1]\n",
    "student.net.decoder.pi = student.net.decoder.pi[:-1]\n",
    "\n",
    "# Print the model layers\n",
    "print(\"Student model instantiated with the following configuration:\")\n",
    "for name, layer in student.named_children():\n",
    "    print(f\"{name}: {layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c057134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data root: /home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/data/emp/train, total number of files: 199908\n",
      "data root: /home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/data/emp/val, total number of files: 24988\n",
      "Using 50.0% of the training and validation datasets.\n",
      "Number of training samples: 99954 out of 199908\n",
      "Number of validation samples: 12494 out of 24988\n"
     ]
    }
   ],
   "source": [
    "# Create datamodule\n",
    "datamodule_dict = {\n",
    "    \"_target_\": \"src.datamodule.av2_datamodule.Av2DataModule\",\n",
    "    \"data_root\": \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/data\",\n",
    "    \"data_folder\": \"emp\",\n",
    "    \"train_batch_size\": 64,\n",
    "    \"val_batch_size\": 64,\n",
    "    \"test_batch_size\": 64,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 18,\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "\n",
    "datamodule = instantiate(datamodule_dict)\n",
    "\n",
    "FRACTION = 0.5  \n",
    "\n",
    "datamodule.setup(stage=\"fit\", train_fraction=FRACTION, val_fraction=FRACTION, test_fraction=FRACTION)\n",
    "\n",
    "train_dataloader = datamodule.train_dataloader()\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataloader.dataset)} out of {len(datamodule.full_train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataloader.dataset)} out of {len(datamodule.full_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1417b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if cuda is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82400251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from tqdm import tqdm\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# teacher = teacher.to(device)\n",
    "# teacher.eval()\n",
    "# features_list_train = []\n",
    "# features_list_val = []\n",
    "# points_train = []\n",
    "# points_val = []\n",
    "# with torch.no_grad():\n",
    "#     for data in tqdm(train_dataloader):\n",
    "#         for k in data.keys():\n",
    "#             if torch.is_tensor(data[k]): data[k] = data[k].to(device)\n",
    "        \n",
    "#         points_train.append(data)\n",
    "        \n",
    "#         features = teacher.net.get_features(data)\n",
    "#         features_list_train.append(features)\n",
    "        \n",
    "        \n",
    "#     for data in tqdm(val_dataloader):\n",
    "#         for k in data.keys():\n",
    "#             if torch.is_tensor(data[k]): data[k] = data[k].to(device)\n",
    "        \n",
    "#         features = teacher.net.get_features(data)\n",
    "#         features_list_val.append(features)\n",
    "#         points_val.append(data)\n",
    "        \n",
    "# # Save the features to a file\n",
    "# import pickle as pkl\n",
    "# output_file_train = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/features_train.pkl\"\n",
    "# with open(output_file_train, \"wb\") as f:\n",
    "#     pkl.dump(features_list_train, f)\n",
    "    \n",
    "# output_file_val = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/features_val.pkl\"\n",
    "# with open(output_file_val, \"wb\") as f:\n",
    "#     pkl.dump(features_list_val, f)\n",
    "\n",
    "\n",
    "# output_file_data = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/data_points_train.pkl\"\n",
    "# with open(output_file_data, \"wb\") as f:\n",
    "#     pkl.dump(points_train, f)\n",
    "\n",
    "# output_file_data = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/data_points_val.pkl\"\n",
    "# with open(output_file_data, \"wb\") as f:\n",
    "#     pkl.dump(points_val, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abfa6bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h-score: tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def h_score(t_feat, s_feat, tau=0.1, N_over_M=1.0):\n",
    "    \"\"\"\n",
    "    Compute h(T, S) as defined in Eq (19) in the paper.\n",
    "    \"\"\"\n",
    "    # Normalize features \n",
    "    t_feat = F.normalize(t_feat, dim=1)\n",
    "    s_feat = F.normalize(s_feat, dim=1)\n",
    "\n",
    "    # Similarity scores\n",
    "    sim = torch.sum(t_feat * s_feat, dim=1) / tau  # Exponent of e for numerator\n",
    "    numerator = torch.exp(sim)\n",
    "    denominator = numerator + N_over_M\n",
    "    h = numerator / denominator  # shape: (B,)\n",
    "    return h\n",
    "\n",
    "\n",
    "# Test function\n",
    "def test_h_score():\n",
    "    # Create dummy features\n",
    "    t_feat = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    s_feat = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "    # Compute h-score\n",
    "    h = h_score(t_feat, s_feat)\n",
    "\n",
    "    # Print result\n",
    "    print(\"h-score:\", h)\n",
    "    # Expected output: h-score: tensor([1.0000, 1.0000, 1.0000])\n",
    "    assert torch.allclose(h, torch.tensor([1.0, 1.0, 1.0]), atol=1e-4), \"h-score test failed!\"\n",
    "    \n",
    "test_h_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa2a810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critic loss: tensor(    0.0001)\n"
     ]
    }
   ],
   "source": [
    "def critic_loss(t_pos, s_pos, t_neg, s_neg, tau=0.1, N=1.0, M = 1.0):\n",
    "    \"\"\"\n",
    "    Compute the full critic loss:\n",
    "    - t_pos, s_pos: matched teacher/student features (C=1)\n",
    "    - t_neg, s_neg: mismatched features (C=0)\n",
    "    \"\"\"\n",
    "    N_over_M = N / M if M != 0 else 1.0  # Avoid division by zero\n",
    "    \n",
    "    # Positive pair scores\n",
    "    h_pos = h_score(t_pos, s_pos, tau, N_over_M)\n",
    "    loss_pos = torch.log(h_pos + 1e-8).mean() # We use mean as Monte Carlo estimate\n",
    "\n",
    "    # Negative pair scores\n",
    "    h_neg = h_score(t_neg, s_neg, tau, N_over_M)\n",
    "    loss_neg = torch.log(1 - h_neg + 1e-8).mean()\n",
    "\n",
    "    # Combine as in Eq (18)\n",
    "    loss = -(loss_pos + N * loss_neg)\n",
    "    return loss\n",
    "\n",
    "# Test function\n",
    "def test_critic_loss():\n",
    "    # Here I tried to find two tensors that would yield a loss of almost 0\n",
    "    t_pos = torch.tensor([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\n",
    "    s_pos = torch.tensor([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\n",
    "\n",
    "    t_neg = torch.tensor([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]])\n",
    "    s_neg = torch.tensor([[-1.0, 0.0], [0.0, -1.0], [-1.0, -1.0]])\n",
    "\n",
    "    # Compute critic loss\n",
    "    loss = critic_loss(t_pos, s_pos, t_neg, s_neg)\n",
    "\n",
    "    # Print result\n",
    "    print(\"Critic loss:\", loss)\n",
    "    # Expected output: Critic loss: tensor(1.)\n",
    "    assert torch.isclose(loss, torch.tensor(0.), atol=1e-4), \"Critic loss test failed!\"\n",
    "    \n",
    "test_critic_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e956fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load features from the saved file\n",
    "# from tqdm import tqdm\n",
    "# import pickle as pkl\n",
    "\n",
    "\n",
    "# output_file_train = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/features_train.pkl\"\n",
    "# with open(output_file_train, \"rb\") as f:\n",
    "#     features_list_train = pkl.load(f)\n",
    "    \n",
    "# output_file_val = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/features_val.pkl\"\n",
    "# with open(output_file_val, \"rb\") as f:\n",
    "#     features_list_val = pkl.load(f)\n",
    "    \n",
    "# output_file_data = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/data_points_train.pkl\"\n",
    "# with open(output_file_data, \"rb\") as f:\n",
    "#     points_train = pkl.load(f)\n",
    "    \n",
    "# output_file_data = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/data_points_val.pkl\"\n",
    "# with open(output_file_data, \"rb\") as f:\n",
    "#     points_val = pkl.load(f)\n",
    "    \n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0dd87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# student.train()\n",
    "# student = student.to(device)\n",
    "# teacher.to(device)\n",
    "# teacher.eval()\n",
    "# batch_size = 64\n",
    "\n",
    "# # Already organized in batches\n",
    "\n",
    "\n",
    "# # If the embedding dim of the student is different from the teacher, add a projection layer\n",
    "# # Get a batch of data\n",
    "# batch = points_train[0]\n",
    "# for k in batch.keys():\n",
    "#     if torch.is_tensor(batch[k]): \n",
    "#         batch[k] = batch[k].to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     dim_teacher = teacher.net.get_features(batch).shape[1]\n",
    "#     dim_student = student.net.get_features(batch).shape[1]\n",
    "\n",
    "# print(f\"Teacher feature dimension: {dim_teacher}, Student feature dimension: {dim_student}\")\n",
    "# projection_layer = None\n",
    "# if dim_teacher != dim_student:\n",
    "#     projection_layer = torch.nn.Linear(dim_student, dim_teacher)\n",
    "#     projection_layer.to(device)\n",
    "#     print(f\"Projection layer added: {projection_layer}\")\n",
    "    \n",
    "#     # Freeze the projection layer\n",
    "#     for param in projection_layer.parameters():\n",
    "#         param.requires_grad = False\n",
    "    \n",
    "# optimizer, scheduler = student.configure_optimizers()\n",
    "# optimizer = optimizer[0] if isinstance(optimizer, list) else optimizer\n",
    "# scheduler = scheduler[0] if isinstance(scheduler, list) else scheduler\n",
    "    \n",
    "# # M = nr of positive pairs, N = nr of negative pairs\n",
    "# M = len(features_list_train[0])  # Number of positive pairs in a batch\n",
    "# N = len(features_list_train[0])  # Number of negative pairs in a batch\n",
    "# for i in range(10):\n",
    "#     losses = []\n",
    "#     print(f\"Epoch {i+1}/{10}\")\n",
    "#     for idx in tqdm(range(len(points_train))):\n",
    "#         batch = points_train[idx]\n",
    "#         for k in batch.keys():\n",
    "#             if torch.is_tensor(batch[k]): batch[k] = batch[k].to(device)\n",
    "#         # Eliminate \"y\" key if it exists\n",
    "#         if 'y' in batch:\n",
    "#             del batch['y']\n",
    "#         feature_contrast = student.net.get_features(batch)\n",
    "\n",
    "#         if projection_layer is not None:\n",
    "#             feature_contrast = projection_layer(feature_contrast)\n",
    "\n",
    "\n",
    "#         batch_feats = features_list_train[idx]\n",
    "\n",
    "#         # Get a random feature from the batch\n",
    "#         random_idx = random.randint(0, len(batch_feats) - 1)\n",
    "#         t_pos = batch_feats[random_idx].unsqueeze(0)  # [1, feature_dim]\n",
    "#         s_pos = feature_contrast[random_idx].unsqueeze(0)  # [1, feature_dim]\n",
    "        \n",
    "#         # Get a random negative feature from the batch\n",
    "#         neg_idx = random.randint(0, len(batch_feats) - 1)\n",
    "#         while neg_idx == random_idx:  # Ensure it's different from the positive index\n",
    "#             neg_idx = random.randint(0, len(batch_feats) - 1)\n",
    "#         t_neg = batch_feats[neg_idx].unsqueeze(0)  # [1, feature_dim]\n",
    "#         s_neg = feature_contrast[neg_idx].unsqueeze(0)  # [1, feature_dim]\n",
    "#         # Compute the critic loss\n",
    "#         loss = critic_loss(t_pos, s_pos, t_neg, s_neg, tau=0.1, N=N, M=M)\n",
    "#         # print(f\"Critic loss: {loss.item()}\")\n",
    "        \n",
    "#         # Backpropagate the loss\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         losses.append(loss.item())\n",
    "#     losses = np.mean(losses)\n",
    "#     print(f\"Epoch {i+1} losses: {losses}\")\n",
    "#     if scheduler is not None:\n",
    "#         if isinstance(scheduler, list):\n",
    "#             for sch in scheduler:\n",
    "#                 sch.step()\n",
    "#         else:\n",
    "#             scheduler.step()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a1a025d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher feature dimension: 640, Student feature dimension: 448\n",
      "Learnable projection layer added: Linear(in_features=448, out_features=640, bias=True)\n"
     ]
    }
   ],
   "source": [
    "teacher.to(device)\n",
    "student.to(device)\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "for k in batch.keys():\n",
    "    if torch.is_tensor(batch[k]): batch[k] = batch[k].to(device)\n",
    "# Find the expected output size\n",
    "with torch.no_grad():\n",
    "    dim_teacher = teacher.net.get_features(batch).shape[1]\n",
    "    dim_student = student.net.get_features(batch).shape[1]\n",
    "\n",
    "print(f\"Teacher feature dimension: {dim_teacher}, Student feature dimension: {dim_student}\")\n",
    "\n",
    "# Create learnable projection layer\n",
    "projection_layer = None\n",
    "if dim_teacher != dim_student:\n",
    "    projection_layer = torch.nn.Linear(dim_student, dim_teacher).to(device)\n",
    "    print(f\"Learnable projection layer added: {projection_layer}\")\n",
    "    \n",
    "    # Freeze the projection layer\n",
    "    for param in projection_layer.parameters():\n",
    "        param.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "401c0bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting online contrastive training with custom loss and memory bank...\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▋         | 100/1562 [00:42<10:06,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100: Loss = 3.9611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 200/1562 [01:23<09:28,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200: Loss = 3.8717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▉        | 300/1562 [02:04<09:52,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300: Loss = 3.4674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26%|██▌       | 400/1562 [02:45<09:46,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400: Loss = 3.6989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 500/1562 [03:28<07:30,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500: Loss = 3.2551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|███▊      | 600/1562 [04:11<07:07,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600: Loss = 3.5387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  45%|████▍     | 700/1562 [04:54<06:42,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700: Loss = 3.5656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████     | 800/1562 [05:38<05:59,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800: Loss = 4.2850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 900/1562 [06:23<05:11,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900: Loss = 3.8064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64%|██████▍   | 1000/1562 [07:09<04:23,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss = 3.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  70%|███████   | 1100/1562 [07:56<03:48,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100: Loss = 3.4285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  77%|███████▋  | 1200/1562 [08:44<03:04,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200: Loss = 3.4903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  83%|████████▎ | 1300/1562 [09:33<02:14,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300: Loss = 3.3120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  90%|████████▉ | 1400/1562 [10:22<01:23,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400: Loss = 3.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 1500/1562 [11:13<00:34,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500: Loss = 3.5449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1562/1562 [11:45<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average Loss: 3.9268\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   6%|▋         | 100/1562 [00:54<13:10,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100: Loss = 3.6565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  13%|█▎        | 200/1562 [01:49<12:52,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200: Loss = 3.4739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  19%|█▉        | 300/1562 [02:45<12:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300: Loss = 3.0539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  26%|██▌       | 400/1562 [03:41<11:03,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400: Loss = 3.1822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  32%|███▏      | 500/1562 [04:38<10:40,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500: Loss = 3.2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  38%|███▊      | 600/1562 [05:37<09:36,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600: Loss = 3.4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  45%|████▍     | 700/1562 [06:36<08:40,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700: Loss = 3.3599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  51%|█████     | 800/1562 [07:36<08:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800: Loss = 3.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  58%|█████▊    | 900/1562 [08:38<06:59,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900: Loss = 3.4033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  64%|██████▍   | 1000/1562 [09:40<05:59,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss = 3.0143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  70%|███████   | 1100/1562 [10:43<05:07,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100: Loss = 3.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  77%|███████▋  | 1200/1562 [11:48<04:02,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200: Loss = 3.0140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  83%|████████▎ | 1300/1562 [12:53<02:50,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300: Loss = 3.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  90%|████████▉ | 1400/1562 [14:00<01:49,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400: Loss = 3.3966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  96%|█████████▌| 1500/1562 [15:08<00:43,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500: Loss = 3.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1562/1562 [15:50<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Average Loss: 3.3757\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   6%|▋         | 100/1562 [01:11<17:22,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100: Loss = 3.0966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  13%|█▎        | 200/1562 [02:23<16:26,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200: Loss = 3.6980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  19%|█▉        | 300/1562 [03:36<16:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300: Loss = 3.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  26%|██▌       | 400/1562 [04:49<14:33,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400: Loss = 3.4281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  32%|███▏      | 500/1562 [06:04<13:34,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500: Loss = 4.0264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  38%|███▊      | 600/1562 [07:20<12:07,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600: Loss = 3.4876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  45%|████▍     | 700/1562 [08:34<10:48,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700: Loss = 3.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  51%|█████     | 800/1562 [09:49<10:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800: Loss = 3.3929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  58%|█████▊    | 900/1562 [11:08<08:59,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900: Loss = 3.4166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  64%|██████▍   | 1000/1562 [12:24<07:27,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000: Loss = 3.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  70%|███████   | 1100/1562 [13:41<06:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100: Loss = 3.9392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  71%|███████   | 1108/1562 [13:47<05:39,  1.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m pos_features \u001b[38;5;241m=\u001b[39m teacher\u001b[38;5;241m.\u001b[39mnet\u001b[38;5;241m.\u001b[39mget_features(batch)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Update memory buffer with new features (FIFO queue)\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m pos_features_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mpos_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Concatenate new features to memory buffer\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m pos_features_cpu:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "teacher.to(device)\n",
    "student.to(device)\n",
    "student.train()\n",
    "teacher.eval()\n",
    "\n",
    "memory_bank_size = 2048  # Reduced memory bank size for better management\n",
    "memory_buffer = []\n",
    "\n",
    "# Create optimizer\n",
    "if projection_layer is not None:\n",
    "    all_params = list(student.parameters()) + list(projection_layer.parameters())\n",
    "    optimizer = torch.optim.AdamW(all_params, lr=1e-4, weight_decay=1e-4)\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(student.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "def contrastive_loss_batch_online(student_feats, pos_features, neg_features=None, tau=0.1, NEG_RATIO=1.0):\n",
    "    \"\"\"\n",
    "    Online contrastive loss function using your custom critic loss\n",
    "    \"\"\"\n",
    "    batch_size = student_feats.shape[0]\n",
    "    \n",
    "    if batch_size == 1:\n",
    "        return F.mse_loss(student_feats, pos_features)\n",
    "    \n",
    "    # For negative pairs\n",
    "    if neg_features is not None and neg_features.shape[0] > 0:\n",
    "        # Sample negative features randomly based on ratio\n",
    "        num_negatives = min(int(batch_size * NEG_RATIO), neg_features.shape[0])\n",
    "        if num_negatives > 0:\n",
    "            neg_indices = torch.randperm(neg_features.shape[0])[:num_negatives]\n",
    "            \n",
    "            t_pos = pos_features  # [B, feature_dim]\n",
    "            s_pos = student_feats  # [B, feature_dim]\n",
    "            \n",
    "            t_neg = neg_features[neg_indices]  # [neg_samples, feature_dim]\n",
    "            \n",
    "            # Create corresponding student negatives by cycling through student features\n",
    "            s_neg_indices = torch.arange(num_negatives) % batch_size\n",
    "            s_neg = student_feats[s_neg_indices]  # [neg_samples, feature_dim]\n",
    "            \n",
    "            # print(\"s_pos shape:\", s_pos.shape)\n",
    "            # print(\"t_pos shape:\", t_pos.shape)\n",
    "            # print(\"t_neg shape:\", t_neg.shape)\n",
    "            # print(\"s_neg shape:\", s_neg.shape)\n",
    "            \n",
    "            M = t_pos.shape[0]  # Number of positive pairs\n",
    "            N = t_neg.shape[0]  # Number of negative pairs\n",
    "            \n",
    "            loss = critic_loss(t_pos, s_pos, t_neg, s_neg, tau=tau, N=N, M=M)\n",
    "        else:\n",
    "            loss = F.mse_loss(student_feats, pos_features)\n",
    "    else:\n",
    "        # Fallback to MSE if no negatives available\n",
    "        loss = F.mse_loss(student_feats, pos_features)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "epochs = 5\n",
    "print(\"Starting online contrastive training with custom loss and memory bank...\")\n",
    "\n",
    "NEG_RATIO = 0.2\n",
    "\n",
    "losses = []\n",
    "LOSS_BUFFER_SIZE = 3000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    # The training loop iterates directly over the train_dataloader\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        for k in batch.keys():\n",
    "            if torch.is_tensor(batch[k]): \n",
    "                batch[k] = batch[k].to(device)\n",
    "        \n",
    "        # Eliminate \"y\" key if it exists\n",
    "        if 'y' in batch:\n",
    "            del batch['y']\n",
    "        \n",
    "        # Get student features\n",
    "        student_features = student.net.get_features(batch)\n",
    "        \n",
    "        # Apply projection\n",
    "        if projection_layer is not None:\n",
    "            student_features = projection_layer(student_features)\n",
    "        \n",
    "        # Generate positive features on-the-fly from the teacher\n",
    "        with torch.no_grad():\n",
    "            pos_features = teacher.net.get_features(batch)\n",
    "        \n",
    "            # Update memory buffer with new features (FIFO queue)\n",
    "            pos_features_cpu = pos_features.cpu()\n",
    "            \n",
    "            # Concatenate new features to memory buffer\n",
    "            for feature in pos_features_cpu:\n",
    "                memory_buffer.append(feature)\n",
    "            \n",
    "            # Limit memory buffer size\n",
    "            if len(memory_buffer) > memory_bank_size:\n",
    "                memory_buffer.pop(0)\n",
    "        \n",
    "        # Prepare negative features for loss computation\n",
    "        neg_features_for_loss = None\n",
    "        if len(memory_buffer) > 0:\n",
    "            # Convert memory buffer back to GPU tensors for loss computation\n",
    "            neg_features_for_loss = torch.stack(memory_buffer).to(device)\n",
    "            \n",
    "        loss = contrastive_loss_batch_online(\n",
    "            student_features, \n",
    "            pos_features, \n",
    "            neg_features=neg_features_for_loss, \n",
    "            tau=0.1, \n",
    "            NEG_RATIO=NEG_RATIO\n",
    "        )\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        if len(losses) > LOSS_BUFFER_SIZE:\n",
    "            losses.pop(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if num_batches % 10 == 0:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            if len(losses) > 50:\n",
    "                window_size = min(50, len(losses) // 10)\n",
    "                smoothed_losses = np.convolve(losses, np.ones(window_size)/window_size, mode='valid')\n",
    "                smooth_x = np.arange(window_size-1, len(losses))\n",
    "                plt.plot(smooth_x, smoothed_losses, color='blue', linewidth=2, label=f'Moving Average (window={window_size})')\n",
    "            else:\n",
    "                plt.plot(np.arange(len(losses)), losses, color='lightblue', linewidth=1, label='Raw Loss')\n",
    "\n",
    "            \n",
    "            plt.xlabel('Batch')\n",
    "            plt.ylabel('Loss Value')\n",
    "            plt.title(f'Epoch {epoch + 1} Loss Progress (Moving Average)')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"loss_distillation_smoothed_{epoch + 1}.png\", dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        if num_batches % 100 == 0:\n",
    "            print(f\"Batch {num_batches}: Loss = {loss.item():.4f}\")\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    if num_batches > 0:\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1} completed. Average Loss: {avg_loss:.4f}\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch + 1} completed. No batches were processed.\")\n",
    "\n",
    "print(\"Online contrastive training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "751d75da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'student_model_custom_contrastive.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save({\n",
    "    'student_state_dict': student.state_dict(),\n",
    "    'projection_layer_state_dict': projection_layer.state_dict() if projection_layer else None,\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': epochs,\n",
    "}, 'student_model_custom_contrastive.pth')\n",
    "\n",
    "print(\"Model saved as 'student_model_custom_contrastive.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e79292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using decoder type: mlp\n",
      "RUN EMP-M\n",
      "Test loss after loading model: 3.2877\n"
     ]
    }
   ],
   "source": [
    "# Load the model for testing\n",
    "checkpoint = torch.load('student_model_custom_contrastive.pth')\n",
    "student = instantiate(student_dict)\n",
    "# Remove the last layer from the encoder or decoder\n",
    "student.net.dense_predictor = student.net.dense_predictor[:-1]  \n",
    "student.net.decoder.loc = student.net.decoder.loc[:-1]\n",
    "student.net.decoder.pi = student.net.decoder.pi[:-1]\n",
    "student.load_state_dict(checkpoint['student_state_dict'])  # <-- FIXED LINE\n",
    "\n",
    "teacher.eval()\n",
    "student.eval()\n",
    "teacher.to(device)\n",
    "student.to(device)\n",
    "\n",
    "batch_pos = next(iter(train_dataloader))\n",
    "for k in batch_pos.keys():\n",
    "    if torch.is_tensor(batch_pos[k]): \n",
    "        batch_pos[k] = batch_pos[k].to(device)\n",
    "# Eliminate \"y\" key if it exists\n",
    "if 'y' in batch_pos:\n",
    "    del batch_pos['y']\n",
    "    \n",
    "batch_neg = next(iter(train_dataloader))\n",
    "for k in batch_neg.keys():\n",
    "    if torch.is_tensor(batch_neg[k]): \n",
    "        batch_neg[k] = batch_neg[k].to(device)\n",
    "# Eliminate \"y\" key if it exists\n",
    "if 'y' in batch_neg:\n",
    "    del batch_neg['y']\n",
    "\n",
    "# After loading student and teacher and before loss calculation\n",
    "with torch.no_grad():\n",
    "    pos_teacher_features = teacher.net.get_features(batch_pos)\n",
    "    neg_teacher_features = teacher.net.get_features(batch_neg)\n",
    "    pos_student_features = student.net.get_features(batch_pos)\n",
    "\n",
    "    # Project student features if needed\n",
    "    if pos_teacher_features.shape[1] != pos_student_features.shape[1]:\n",
    "        projection_layer = torch.nn.Linear(pos_student_features.shape[1], pos_teacher_features.shape[1]).to(device)\n",
    "        # Optionally load projection weights if you saved them\n",
    "        if 'projection_layer_state_dict' in checkpoint and checkpoint['projection_layer_state_dict'] is not None:\n",
    "            projection_layer.load_state_dict(checkpoint['projection_layer_state_dict'])\n",
    "        pos_student_features = projection_layer(pos_student_features)\n",
    "\n",
    "loss = contrastive_loss_batch_online(\n",
    "    pos_student_features, \n",
    "    pos_teacher_features, \n",
    "    neg_features=neg_teacher_features, \n",
    "    tau=0.1, \n",
    "    NEG_RATIO=NEG_RATIO\n",
    ")\n",
    "print(f\"Test loss after loading model: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4c9644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using decoder type: mlp\n",
      "RUN EMP-M\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 1/313 [00:01<08:57,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 285.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 2/313 [00:01<04:29,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 333.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|          | 3/313 [00:02<02:58,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 362.2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏         | 4/313 [00:02<02:22,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 480.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 5/313 [00:02<01:59,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 336.8015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 6/313 [00:03<01:43,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 350.4828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▏         | 7/313 [00:03<01:34,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 245.2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 8/313 [00:03<01:26,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 364.3583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 9/313 [00:03<01:19,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 370.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▎         | 10/313 [00:03<01:15,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 307.4930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▎         | 11/313 [00:04<01:10,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 336.2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 12/313 [00:04<01:10,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 371.9744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 13/313 [00:04<01:09,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 407.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|▍         | 14/313 [00:04<01:08,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 370.7653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▍         | 15/313 [00:05<01:07,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 428.9459\n",
      "Loss for epoch 1, batch: 362.8737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|▌         | 17/313 [00:05<01:02,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 356.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 18/313 [00:05<01:02,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 397.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▌         | 19/313 [00:05<01:02,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 393.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|▋         | 20/313 [00:06<01:01,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 242.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 21/313 [00:06<01:01,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 449.3475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|▋         | 22/313 [00:06<01:01,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 313.8423\n",
      "Loss for epoch 1, batch: 353.8736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 24/313 [00:06<00:59,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 284.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 25/313 [00:07<01:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 371.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|▊         | 26/313 [00:07<01:01,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 289.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▊         | 27/313 [00:07<01:03,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 366.1032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 28/313 [00:07<01:02,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 440.2894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|▉         | 29/313 [00:07<01:03,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 332.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|▉         | 30/313 [00:08<01:01,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 364.6490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|▉         | 31/313 [00:08<01:03,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 314.9058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 32/313 [00:08<01:05,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 433.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 33/313 [00:08<01:05,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 382.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 34/313 [00:09<01:04,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 314.3686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█         | 35/313 [00:09<01:03,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 318.2587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 36/313 [00:09<01:02,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 335.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 37/313 [00:09<01:03,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 385.7719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 38/313 [00:10<01:04,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 330.5747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 39/313 [00:10<01:06,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 489.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 40/313 [00:10<01:05,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 499.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 41/313 [00:10<01:05,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 418.8035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|█▎        | 42/313 [00:11<01:04,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 388.6758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|█▎        | 43/313 [00:11<01:04,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 414.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|█▍        | 44/313 [00:11<01:04,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 282.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|█▍        | 45/313 [00:11<01:06,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 399.8519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|█▍        | 46/313 [00:12<01:04,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 280.3168\n",
      "Loss for epoch 1, batch: 255.6490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  15%|█▌        | 48/313 [00:12<00:59,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 364.4626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▌        | 49/313 [00:12<00:59,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 400.9965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▌        | 50/313 [00:12<00:57,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 395.7108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  16%|█▋        | 51/313 [00:13<00:55,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 291.4653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  17%|█▋        | 52/313 [00:13<00:55,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 338.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  17%|█▋        | 53/313 [00:13<00:54,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 368.1588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  17%|█▋        | 54/313 [00:13<00:54,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 468.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18%|█▊        | 55/313 [00:13<00:55,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 285.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18%|█▊        | 56/313 [00:14<00:57,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 320.2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  18%|█▊        | 57/313 [00:14<00:58,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 412.5793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▊        | 58/313 [00:14<00:57,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 347.4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▉        | 59/313 [00:14<00:58,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 328.6171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▉        | 60/313 [00:15<00:56,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 482.7646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  19%|█▉        | 61/313 [00:15<00:55,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 296.8341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|█▉        | 62/313 [00:15<00:57,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 294.6202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|██        | 63/313 [00:15<00:58,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 360.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  20%|██        | 64/313 [00:16<00:59,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 372.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██        | 65/313 [00:16<00:59,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 385.9076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██        | 66/313 [00:16<01:01,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 278.7875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  21%|██▏       | 67/313 [00:16<01:01,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 437.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 68/313 [00:17<01:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 380.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 69/313 [00:17<01:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 533.2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 70/313 [00:17<00:58,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 378.6333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  23%|██▎       | 71/313 [00:17<00:58,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 446.9014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  23%|██▎       | 72/313 [00:17<00:57,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 377.2294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  23%|██▎       | 73/313 [00:18<00:55,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 315.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24%|██▎       | 74/313 [00:18<00:54,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 359.1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24%|██▍       | 75/313 [00:18<00:52,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 364.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24%|██▍       | 76/313 [00:18<00:54,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 463.2545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▍       | 77/313 [00:19<00:55,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 259.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▍       | 78/313 [00:19<00:55,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 409.2771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  25%|██▌       | 79/313 [00:19<00:54,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 415.5723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26%|██▌       | 80/313 [00:19<00:53,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 407.3905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26%|██▌       | 81/313 [00:20<00:53,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 331.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  26%|██▌       | 82/313 [00:20<00:51,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 258.4328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  27%|██▋       | 83/313 [00:20<00:51,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 395.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  27%|██▋       | 84/313 [00:20<00:52,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 403.2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  27%|██▋       | 85/313 [00:20<00:52,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 410.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  27%|██▋       | 86/313 [00:21<00:51,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 323.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|██▊       | 87/313 [00:21<00:50,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 323.6117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|██▊       | 88/313 [00:21<00:50,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 378.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  28%|██▊       | 89/313 [00:21<00:51,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 385.6454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  29%|██▉       | 90/313 [00:22<00:51,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 237.3598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  29%|██▉       | 91/313 [00:22<00:51,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 323.6263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  29%|██▉       | 92/313 [00:22<00:51,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 339.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  30%|██▉       | 93/313 [00:22<00:51,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 264.4967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  30%|███       | 94/313 [00:23<00:50,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 447.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  30%|███       | 95/313 [00:23<00:49,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 332.0335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  31%|███       | 96/313 [00:23<00:49,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 413.1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  31%|███       | 97/313 [00:23<00:49,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 334.3734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  31%|███▏      | 98/313 [00:23<00:48,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 294.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 99/313 [00:24<00:47,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 295.7199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 100/313 [00:24<00:48,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 386.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 101/313 [00:24<00:47,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 289.5653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33%|███▎      | 102/313 [00:24<00:47,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 331.3228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33%|███▎      | 103/313 [00:25<00:46,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 312.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  33%|███▎      | 104/313 [00:25<00:47,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 346.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███▎      | 105/313 [00:25<00:48,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 397.0311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███▍      | 106/313 [00:25<00:48,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 304.3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  34%|███▍      | 107/313 [00:26<00:49,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 452.3322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▍      | 108/313 [00:26<00:47,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 370.4235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▍      | 109/313 [00:26<00:45,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 360.1095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▌      | 110/313 [00:26<00:44,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 343.8559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▌      | 111/313 [00:26<00:45,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 408.3548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|███▌      | 112/313 [00:27<00:46,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 322.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|███▌      | 113/313 [00:27<00:46,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 289.5149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|███▋      | 114/313 [00:27<00:45,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 327.5196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  37%|███▋      | 115/313 [00:27<00:45,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 360.7697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  37%|███▋      | 116/313 [00:28<00:46,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 305.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  37%|███▋      | 117/313 [00:28<00:46,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 249.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|███▊      | 118/313 [00:28<00:45,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 350.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|███▊      | 119/313 [00:28<00:45,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 268.0307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  38%|███▊      | 120/313 [00:29<00:46,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 250.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  39%|███▊      | 121/313 [00:29<00:47,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 329.1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  39%|███▉      | 122/313 [00:29<00:44,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 325.7759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  39%|███▉      | 123/313 [00:29<00:44,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 280.1406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40%|███▉      | 124/313 [00:29<00:44,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 394.5261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40%|███▉      | 125/313 [00:30<00:44,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 367.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  40%|████      | 126/313 [00:30<00:42,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 302.1962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  41%|████      | 127/313 [00:30<00:41,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 276.5529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  41%|████      | 128/313 [00:30<00:42,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 304.6687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  41%|████      | 129/313 [00:31<00:41,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 342.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42%|████▏     | 130/313 [00:31<00:40,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 293.7610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42%|████▏     | 131/313 [00:31<00:40,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 377.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42%|████▏     | 132/313 [00:31<00:40,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 349.5352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  42%|████▏     | 133/313 [00:31<00:40,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 433.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|████▎     | 134/313 [00:32<00:39,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 360.4385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|████▎     | 135/313 [00:32<00:40,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 340.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|████▎     | 136/313 [00:32<00:40,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 314.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 137/313 [00:32<00:39,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 266.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 138/313 [00:33<00:40,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 257.1228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  44%|████▍     | 139/313 [00:33<00:41,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 291.4588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  45%|████▍     | 140/313 [00:33<00:41,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 287.6133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  45%|████▌     | 141/313 [00:33<00:40,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 369.4890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  45%|████▌     | 142/313 [00:34<00:40,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 250.5443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 143/313 [00:34<00:40,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 318.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▌     | 144/313 [00:34<00:39,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 359.5394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  46%|████▋     | 145/313 [00:34<00:39,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 278.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47%|████▋     | 146/313 [00:35<00:39,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 409.6145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47%|████▋     | 147/313 [00:35<00:39,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 229.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47%|████▋     | 148/313 [00:35<00:38,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 303.3301\n",
      "Loss for epoch 1, batch: 181.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48%|████▊     | 150/313 [00:35<00:36,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 300.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  48%|████▊     | 151/313 [00:36<00:39,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 284.3603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  49%|████▊     | 152/313 [00:36<00:38,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 349.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  49%|████▉     | 153/313 [00:36<00:37,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 237.0809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  49%|████▉     | 154/313 [00:36<00:37,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 194.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|████▉     | 155/313 [00:37<00:37,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 285.3707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|████▉     | 156/313 [00:37<00:36,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 249.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 157/313 [00:37<00:36,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 249.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  50%|█████     | 158/313 [00:37<00:36,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 272.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████     | 159/313 [00:38<00:35,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 255.5233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████     | 160/313 [00:38<00:34,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 291.2833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|█████▏    | 161/313 [00:38<00:33,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 374.6580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  52%|█████▏    | 162/313 [00:38<00:33,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 287.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  52%|█████▏    | 163/313 [00:38<00:33,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 227.4325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  52%|█████▏    | 164/313 [00:39<00:33,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 321.2265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  53%|█████▎    | 165/313 [00:39<00:34,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 211.6369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  53%|█████▎    | 166/313 [00:39<00:35,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 249.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  53%|█████▎    | 167/313 [00:39<00:35,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 300.5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54%|█████▎    | 168/313 [00:40<00:35,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 392.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54%|█████▍    | 169/313 [00:40<00:34,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 219.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54%|█████▍    | 170/313 [00:40<00:34,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 340.9252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  55%|█████▍    | 171/313 [00:40<00:35,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 251.6275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  55%|█████▍    | 172/313 [00:41<00:35,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 299.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  55%|█████▌    | 173/313 [00:41<00:35,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 194.5157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  56%|█████▌    | 174/313 [00:41<00:35,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 270.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  56%|█████▌    | 175/313 [00:41<00:35,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 248.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  56%|█████▌    | 176/313 [00:42<00:34,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 213.4404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  57%|█████▋    | 177/313 [00:42<00:33,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 221.4819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  57%|█████▋    | 178/313 [00:42<00:33,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 250.6827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  57%|█████▋    | 179/313 [00:42<00:32,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 249.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 180/313 [00:43<00:32,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 216.4513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 181/313 [00:43<00:31,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 238.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 182/313 [00:43<00:30,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 230.4812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  58%|█████▊    | 183/313 [00:43<00:29,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 229.6236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  59%|█████▉    | 184/313 [00:44<00:29,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1, batch: 173.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  59%|█████▉    | 184/313 [00:44<00:31,  4.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(batch[k]):\n\u001b[0;32m---> 19\u001b[0m         batch[k] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m preds \u001b[38;5;241m=\u001b[39m student(batch)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# preds['y_hat']: (batch, 9, 60, 2), batch['y'][:, 0, :, :] : (batch, 60, 2)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "student = instantiate(student_dict)\n",
    "checkpoint = torch.load('student_model_custom_contrastive.pth')\n",
    "student.load_state_dict(checkpoint['student_state_dict'], strict=False)\n",
    "\n",
    "student.to(device)\n",
    "student.train()\n",
    "\n",
    "optimizer, scheduler = student.configure_optimizers()\n",
    "optimizer = optimizer[0] if isinstance(optimizer, list) else optimizer\n",
    "scheduler = scheduler[0] if isinstance(scheduler, list) else scheduler\n",
    "\n",
    "dataloader = datamodule.train_dataloader()\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch+1}/5\")\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        for k in batch.keys():\n",
    "            if torch.is_tensor(batch[k]):\n",
    "                batch[k] = batch[k].to(device)\n",
    "        preds = student(batch)\n",
    "        # preds['y_hat']: (batch, 9, 60, 2), batch['y'][:, 0, :, :] : (batch, 60, 2)\n",
    "        gt_traj_ego = batch['y'][:, 0, :, :]  # (batch, 60, 2)\n",
    "        pred_modes = preds['y_hat']           # (batch, 9, 60, 2)\n",
    "        # Compute ADE for each mode\n",
    "        gt_expanded = gt_traj_ego.unsqueeze(1).expand(-1, pred_modes.shape[1], -1, -1)  # (batch, 9, 60, 2)\n",
    "        displacement_errors = torch.norm(pred_modes - gt_expanded, dim=-1)  # (batch, 9, 60)\n",
    "        ade_per_mode = displacement_errors.mean(dim=-1)  # (batch, 9)\n",
    "        best_mode_idx = ade_per_mode.argmin(dim=1)       # (batch,)\n",
    "        batch_indices = torch.arange(pred_modes.shape[0])\n",
    "        best_pred = pred_modes[batch_indices, best_mode_idx]  # (batch, 60, 2)\n",
    "        # Now compute loss\n",
    "        loss = torch.nn.functional.mse_loss(best_pred, gt_traj_ego)\n",
    "        print(f\"Loss for epoch {epoch+1}, batch: {loss.item():.4f}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    print(f\"Epoch {epoch+1} done.\")\n",
    "\n",
    "print(\"Fine-tuning complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a48918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using decoder type: mlp\n",
      "RUN EMP-M\n",
      "Loaded trained weights (non-strict mode)\n",
      "data root: /home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/data/emp/train, total number of files: 199908\n",
      "data root: /home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/data/emp/val, total number of files: 24988\n",
      "Using 10.0% of the training and validation datasets.\n",
      "Evaluating trajectory prediction model...\n",
      "Inspection of predictions and ground truth:\n",
      "Prediction type: <class 'dict'>\n",
      "  y_hat: torch.Size([64, 9, 60, 2])\n",
      "  pi: torch.Size([64, 9])\n",
      "  y_hat_others: torch.Size([64, 50, 60, 2])\n",
      "  y_hat_eps: torch.Size([64, 9, 2])\n",
      "  x_agent: torch.Size([64, 64])\n",
      "Ground truth 'y' shape: torch.Size([64, 51, 60, 2])\n",
      "Validation MSE (best mode): 388.4232 ± 73.3702\n",
      "Validation MAE (best mode): 10.5574 ± 1.1664\n",
      "Validation ADE (best mode): 19.5709 ± 13.8144\n",
      "Validation FDE (best mode): 38.2336 ± 26.4699\n",
      "\n",
      "Evaluating using prediction confidence weights...\n",
      "Confidence-based MSE: 388.4663 ± 73.3734\n",
      "Confidence-based MAE: 10.5602 ± 1.1661\n",
      "Confidence-based ADE: 19.5745 ± 13.8122\n",
      "Confidence-based FDE: 38.2382 ± 26.4734\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint without the logit layers\n",
    "checkpoint_path = 'student_model_custom_contrastive.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Create a fresh student model with full layers\n",
    "student_full = instantiate(student_dict)\n",
    "\n",
    "# Load the trained weights\n",
    "try:\n",
    "    student_full.load_state_dict(checkpoint['student_state_dict'], strict=False)\n",
    "    print(\"Loaded trained weights (non-strict mode)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading weights: {e}\")\n",
    "    model_dict = student_full.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in checkpoint['student_state_dict'].items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    student_full.load_state_dict(model_dict)\n",
    "    print(\"Loaded compatible weights manually\")\n",
    "\n",
    "student_full = student_full.to(device)\n",
    "student_full.eval()\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': student_full.state_dict(),\n",
    "    'model_config': student_dict,\n",
    "    'training_info': {\n",
    "        'epochs_trained': checkpoint.get('epoch', 'unknown'),\n",
    "        'architecture': 'student_with_contrastive_learning'\n",
    "    }\n",
    "}, 'student_model_full_with_predictions.pth')\n",
    "\n",
    "datamodule.setup(stage=\"validate\", train_fraction=0.1, val_fraction=0.1, test_fraction=0.1)\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "\n",
    "print(\"Evaluating trajectory prediction model...\")\n",
    "\n",
    "# First, let's inspect the prediction structure\n",
    "sample_batch = next(iter(val_dataloader))\n",
    "for k in sample_batch.keys():\n",
    "    if torch.is_tensor(sample_batch[k]):\n",
    "        sample_batch[k] = sample_batch[k].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_preds = student_full(sample_batch)\n",
    "\n",
    "print(\"Inspection of predictions and ground truth:\")\n",
    "print(f\"Prediction type: {type(sample_preds)}\")\n",
    "if isinstance(sample_preds, dict):\n",
    "    for key, value in sample_preds.items():\n",
    "        if torch.is_tensor(value):\n",
    "            print(f\"  {key}: {value.shape}\")\n",
    "\n",
    "print(f\"Ground truth 'y' shape: {sample_batch['y'].shape}\")\n",
    "\n",
    "# Multi-modal trajectory prediction evaluation\n",
    "mse_errors = []\n",
    "mae_errors = []\n",
    "ade_errors = []\n",
    "fde_errors = []\n",
    "\n",
    "def evaluate_multimodal_prediction(pred_modes, gt_traj_ego):\n",
    "    \"\"\"\n",
    "    Evaluate multi-modal prediction by selecting the best mode\n",
    "    pred_modes: (batch, num_modes, time, 2)\n",
    "    gt_traj_ego: (batch, time, 2)\n",
    "    \"\"\"\n",
    "    batch_size, num_modes, time_steps, _ = pred_modes.shape\n",
    "    \n",
    "    # Compute ADE for each mode\n",
    "    # Expand gt_traj_ego to match pred_modes shape\n",
    "    gt_expanded = gt_traj_ego.unsqueeze(1).expand(-1, num_modes, -1, -1)  # (batch, num_modes, time, 2)\n",
    "    \n",
    "    # Compute displacement errors for all modes\n",
    "    displacement_errors = torch.norm(pred_modes - gt_expanded, dim=-1)  # (batch, num_modes, time)\n",
    "    \n",
    "    # ADE for each mode: average over time\n",
    "    ade_per_mode = displacement_errors.mean(dim=-1)  # (batch, num_modes)\n",
    "    \n",
    "    # FDE for each mode: final time step\n",
    "    fde_per_mode = displacement_errors[:, :, -1]  # (batch, num_modes)\n",
    "    \n",
    "    # Select best mode (lowest ADE)\n",
    "    best_mode_idx = ade_per_mode.argmin(dim=1)  # (batch,)\n",
    "    \n",
    "    # Extract best ADE and FDE\n",
    "    batch_indices = torch.arange(batch_size)\n",
    "    best_ade = ade_per_mode[batch_indices, best_mode_idx]  # (batch,)\n",
    "    best_fde = fde_per_mode[batch_indices, best_mode_idx]  # (batch,)\n",
    "    \n",
    "    # Get best trajectory for MSE/MAE computation\n",
    "    best_traj = pred_modes[batch_indices, best_mode_idx]  # (batch, time, 2)\n",
    "    \n",
    "    return best_traj, best_ade, best_fde\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    for k in batch.keys():\n",
    "        if torch.is_tensor(batch[k]):\n",
    "            batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = student_full(batch)\n",
    "        \n",
    "        # Extract multi-modal predictions\n",
    "        if isinstance(preds, dict) and 'y_hat' in preds:\n",
    "            pred_modes = preds['y_hat']  # (batch, 9, 60, 2)\n",
    "        else:\n",
    "            print(\"Could not find 'y_hat' in predictions\")\n",
    "            break\n",
    "        \n",
    "        # Extract ego agent ground truth (first agent, index 0)\n",
    "        gt_traj_all = batch['y']  # (batch, 42, 60, 2)\n",
    "        gt_traj_ego = gt_traj_all[:, 0, :, :]  # (batch, 60, 2) - ego agent only\n",
    "        \n",
    "        # Evaluate multi-modal prediction\n",
    "        best_traj, batch_ade, batch_fde = evaluate_multimodal_prediction(pred_modes, gt_traj_ego)\n",
    "        \n",
    "        # Compute MSE and MAE using best trajectory\n",
    "        mse = torch.nn.functional.mse_loss(best_traj, gt_traj_ego)\n",
    "        mae = torch.nn.functional.l1_loss(best_traj, gt_traj_ego)\n",
    "        \n",
    "        mse_errors.append(mse.item())\n",
    "        mae_errors.append(mae.item())\n",
    "        ade_errors.extend(batch_ade.cpu().numpy())\n",
    "        fde_errors.extend(batch_fde.cpu().numpy())\n",
    "\n",
    "print(f\"Validation MSE (best mode): {np.mean(mse_errors):.4f} ± {np.std(mse_errors):.4f}\")\n",
    "print(f\"Validation MAE (best mode): {np.mean(mae_errors):.4f} ± {np.std(mae_errors):.4f}\")\n",
    "print(f\"Validation ADE (best mode): {np.mean(ade_errors):.4f} ± {np.std(ade_errors):.4f}\")\n",
    "print(f\"Validation FDE (best mode): {np.mean(fde_errors):.4f} ± {np.std(fde_errors):.4f}\")\n",
    "\n",
    "# Additional analysis: evaluate using prediction confidence (pi weights)\n",
    "if 'pi' in sample_preds:\n",
    "    print(\"\\nEvaluating using prediction confidence weights...\")\n",
    "    conf_mse_errors = []\n",
    "    conf_mae_errors = []\n",
    "    conf_ade_errors = []\n",
    "    conf_fde_errors = []\n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        for k in batch.keys():\n",
    "            if torch.is_tensor(batch[k]):\n",
    "                batch[k] = batch[k].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = student_full(batch)\n",
    "            pred_modes = preds['y_hat']  # (batch, 9, 60, 2)\n",
    "            pi_weights = preds['pi']  # (batch, 9) - confidence scores\n",
    "            \n",
    "            gt_traj_all = batch['y']\n",
    "            gt_traj_ego = gt_traj_all[:, 0, :, :]  # (batch, 60, 2)\n",
    "            \n",
    "            # Select mode with highest confidence\n",
    "            best_conf_idx = pi_weights.argmax(dim=1)  # (batch,)\n",
    "            batch_indices = torch.arange(pred_modes.shape[0])\n",
    "            conf_best_traj = pred_modes[batch_indices, best_conf_idx]  # (batch, 60, 2)\n",
    "            \n",
    "            # Compute metrics\n",
    "            conf_mse = torch.nn.functional.mse_loss(conf_best_traj, gt_traj_ego)\n",
    "            conf_mae = torch.nn.functional.l1_loss(conf_best_traj, gt_traj_ego)\n",
    "            \n",
    "            # ADE/FDE for confidence-based selection\n",
    "            displacement_errors = torch.norm(conf_best_traj - gt_traj_ego, dim=-1)\n",
    "            conf_ade = displacement_errors.mean(dim=-1)\n",
    "            conf_fde = displacement_errors[:, -1]\n",
    "            \n",
    "            conf_mse_errors.append(conf_mse.item())\n",
    "            conf_mae_errors.append(conf_mae.item())\n",
    "            conf_ade_errors.extend(conf_ade.cpu().numpy())\n",
    "            conf_fde_errors.extend(conf_fde.cpu().numpy())\n",
    "    \n",
    "    print(f\"Confidence-based MSE: {np.mean(conf_mse_errors):.4f} ± {np.std(conf_mse_errors):.4f}\")\n",
    "    print(f\"Confidence-based MAE: {np.mean(conf_mae_errors):.4f} ± {np.std(conf_mae_errors):.4f}\")\n",
    "    print(f\"Confidence-based ADE: {np.mean(conf_ade_errors):.4f} ± {np.std(conf_ade_errors):.4f}\")\n",
    "    print(f\"Confidence-based FDE: {np.mean(conf_fde_errors):.4f} ± {np.std(conf_fde_errors):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2959d421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using decoder type: mlp\n",
      "RUN EMP-M\n",
      "data root: /home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/data/emp/train, total number of files: 199908\n",
      "data root: /home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/data/emp/val, total number of files: 24988\n",
      "Using 10.0% of the training and validation datasets.\n",
      "Evaluating trajectory prediction model...\n",
      "Inspection of predictions and ground truth:\n",
      "Prediction type: <class 'dict'>\n",
      "  y_hat: torch.Size([64, 6, 60, 2])\n",
      "  pi: torch.Size([64, 6])\n",
      "  y_hat_others: torch.Size([64, 44, 60, 2])\n",
      "  y_hat_eps: torch.Size([64, 6, 2])\n",
      "  x_agent: torch.Size([64, 128])\n",
      "Ground truth 'y' shape: torch.Size([64, 45, 60, 2])\n",
      "Validation MSE (best mode): 0.8327 ± 0.6760\n",
      "Validation MAE (best mode): 0.4323 ± 0.0488\n",
      "Validation ADE (best mode): 0.7080 ± 0.7275\n",
      "Validation FDE (best mode): 1.6843 ± 2.0672\n",
      "\n",
      "Evaluating using prediction confidence weights...\n",
      "Confidence-based MSE: 5.3941 ± 2.0615\n",
      "Confidence-based MAE: 0.9974 ± 0.1312\n",
      "Confidence-based ADE: 1.7182 ± 1.8246\n",
      "Confidence-based FDE: 4.3709 ± 5.1262\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint without the logit layers\n",
    "checkpoint_path = 'student_model_custom_contrastive.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# # Create a fresh student model with full layers\n",
    "# student_full = instantiate(student_dict)\n",
    "\n",
    "# # Load the trained weights\n",
    "# try:\n",
    "#     student_full.load_state_dict(checkpoint['student_state_dict'], strict=False)\n",
    "#     print(\"Loaded trained weights (non-strict mode)\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading weights: {e}\")\n",
    "#     model_dict = student_full.state_dict()\n",
    "#     pretrained_dict = {k: v for k, v in checkpoint['student_state_dict'].items() if k in model_dict}\n",
    "#     model_dict.update(pretrained_dict)\n",
    "#     student_full.load_state_dict(model_dict)\n",
    "#     print(\"Loaded compatible weights manually\")\n",
    "\n",
    "# student_full = student_full.to(device)\n",
    "# student_full.eval()\n",
    "\n",
    "# torch.save({\n",
    "#     'model_state_dict': student_full.state_dict(),\n",
    "#     'model_config': student_dict,\n",
    "#     'training_info': {\n",
    "#         'epochs_trained': checkpoint.get('epoch', 'unknown'),\n",
    "#         'architecture': 'student_with_contrastive_learning'\n",
    "#     }\n",
    "# }, 'student_model_full_with_predictions.pth')\n",
    "\n",
    "if teacher_dict[\"decoder\"] == \"mlp\":\n",
    "    checkpoint = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/checkpoints/empm.ckpt\"\n",
    "else:\n",
    "    checkpoint = \"/home/alex/UNI EMERGENCY/Project/DeepLeaning-Lab/emp-main/checkpoints/empd.ckpt\"\n",
    "assert os.path.exists(checkpoint), f\"Checkpoint {checkpoint} does not exist\"\n",
    "\n",
    "model_path = teacher_dict[\"_target_\"]\n",
    "module = import_module(model_path[: model_path.rfind(\".\")])\n",
    "Model: pl.LightningModule = getattr(module, model_path[model_path.rfind(\".\") + 1 :])\n",
    "teacher = Model.load_from_checkpoint(checkpoint, **teacher_dict)\n",
    "teacher.to(device)\n",
    "teacher.eval()\n",
    "\n",
    "datamodule.setup(stage=\"validate\", train_fraction=0.1, val_fraction=0.1, test_fraction=0.1)\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "\n",
    "print(\"Evaluating trajectory prediction model...\")\n",
    "\n",
    "# First, let's inspect the prediction structure\n",
    "sample_batch = next(iter(val_dataloader))\n",
    "for k in sample_batch.keys():\n",
    "    if torch.is_tensor(sample_batch[k]):\n",
    "        sample_batch[k] = sample_batch[k].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_preds = teacher(sample_batch)\n",
    "\n",
    "print(\"Inspection of predictions and ground truth:\")\n",
    "print(f\"Prediction type: {type(sample_preds)}\")\n",
    "if isinstance(sample_preds, dict):\n",
    "    for key, value in sample_preds.items():\n",
    "        if torch.is_tensor(value):\n",
    "            print(f\"  {key}: {value.shape}\")\n",
    "\n",
    "print(f\"Ground truth 'y' shape: {sample_batch['y'].shape}\")\n",
    "\n",
    "# Multi-modal trajectory prediction evaluation\n",
    "mse_errors = []\n",
    "mae_errors = []\n",
    "ade_errors = []\n",
    "fde_errors = []\n",
    "\n",
    "def evaluate_multimodal_prediction(pred_modes, gt_traj_ego):\n",
    "    \"\"\"\n",
    "    Evaluate multi-modal prediction by selecting the best mode\n",
    "    pred_modes: (batch, num_modes, time, 2)\n",
    "    gt_traj_ego: (batch, time, 2)\n",
    "    \"\"\"\n",
    "    batch_size, num_modes, time_steps, _ = pred_modes.shape\n",
    "    \n",
    "    # Compute ADE for each mode\n",
    "    # Expand gt_traj_ego to match pred_modes shape\n",
    "    gt_expanded = gt_traj_ego.unsqueeze(1).expand(-1, num_modes, -1, -1)  # (batch, num_modes, time, 2)\n",
    "    \n",
    "    # Compute displacement errors for all modes\n",
    "    displacement_errors = torch.norm(pred_modes - gt_expanded, dim=-1)  # (batch, num_modes, time)\n",
    "    \n",
    "    # ADE for each mode: average over time\n",
    "    ade_per_mode = displacement_errors.mean(dim=-1)  # (batch, num_modes)\n",
    "    \n",
    "    # FDE for each mode: final time step\n",
    "    fde_per_mode = displacement_errors[:, :, -1]  # (batch, num_modes)\n",
    "    \n",
    "    # Select best mode (lowest ADE)\n",
    "    best_mode_idx = ade_per_mode.argmin(dim=1)  # (batch,)\n",
    "    \n",
    "    # Extract best ADE and FDE\n",
    "    batch_indices = torch.arange(batch_size)\n",
    "    best_ade = ade_per_mode[batch_indices, best_mode_idx]  # (batch,)\n",
    "    best_fde = fde_per_mode[batch_indices, best_mode_idx]  # (batch,)\n",
    "    \n",
    "    # Get best trajectory for MSE/MAE computation\n",
    "    best_traj = pred_modes[batch_indices, best_mode_idx]  # (batch, time, 2)\n",
    "    \n",
    "    return best_traj, best_ade, best_fde\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    for k in batch.keys():\n",
    "        if torch.is_tensor(batch[k]):\n",
    "            batch[k] = batch[k].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = teacher(batch)\n",
    "        \n",
    "        # Extract multi-modal predictions\n",
    "        if isinstance(preds, dict) and 'y_hat' in preds:\n",
    "            pred_modes = preds['y_hat']  # (batch, 9, 60, 2)\n",
    "        else:\n",
    "            print(\"Could not find 'y_hat' in predictions\")\n",
    "            break\n",
    "        \n",
    "        # Extract ego agent ground truth (first agent, index 0)\n",
    "        gt_traj_all = batch['y']  # (batch, 42, 60, 2)\n",
    "        gt_traj_ego = gt_traj_all[:, 0, :, :]  # (batch, 60, 2) - ego agent only\n",
    "        \n",
    "        # Evaluate multi-modal prediction\n",
    "        best_traj, batch_ade, batch_fde = evaluate_multimodal_prediction(pred_modes, gt_traj_ego)\n",
    "        \n",
    "        # Compute MSE and MAE using best trajectory\n",
    "        mse = torch.nn.functional.mse_loss(best_traj, gt_traj_ego)\n",
    "        mae = torch.nn.functional.l1_loss(best_traj, gt_traj_ego)\n",
    "        \n",
    "        mse_errors.append(mse.item())\n",
    "        mae_errors.append(mae.item())\n",
    "        ade_errors.extend(batch_ade.cpu().numpy())\n",
    "        fde_errors.extend(batch_fde.cpu().numpy())\n",
    "\n",
    "print(f\"Validation MSE (best mode): {np.mean(mse_errors):.4f} ± {np.std(mse_errors):.4f}\")\n",
    "print(f\"Validation MAE (best mode): {np.mean(mae_errors):.4f} ± {np.std(mae_errors):.4f}\")\n",
    "print(f\"Validation ADE (best mode): {np.mean(ade_errors):.4f} ± {np.std(ade_errors):.4f}\")\n",
    "print(f\"Validation FDE (best mode): {np.mean(fde_errors):.4f} ± {np.std(fde_errors):.4f}\")\n",
    "\n",
    "# Additional analysis: evaluate using prediction confidence (pi weights)\n",
    "if 'pi' in sample_preds:\n",
    "    print(\"\\nEvaluating using prediction confidence weights...\")\n",
    "    conf_mse_errors = []\n",
    "    conf_mae_errors = []\n",
    "    conf_ade_errors = []\n",
    "    conf_fde_errors = []\n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        for k in batch.keys():\n",
    "            if torch.is_tensor(batch[k]):\n",
    "                batch[k] = batch[k].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = teacher(batch)\n",
    "            pred_modes = preds['y_hat']  # (batch, 9, 60, 2)\n",
    "            pi_weights = preds['pi']  # (batch, 9) - confidence scores\n",
    "            \n",
    "            gt_traj_all = batch['y']\n",
    "            gt_traj_ego = gt_traj_all[:, 0, :, :]  # (batch, 60, 2)\n",
    "            \n",
    "            # Select mode with highest confidence\n",
    "            best_conf_idx = pi_weights.argmax(dim=1)  # (batch,)\n",
    "            batch_indices = torch.arange(pred_modes.shape[0])\n",
    "            conf_best_traj = pred_modes[batch_indices, best_conf_idx]  # (batch, 60, 2)\n",
    "            \n",
    "            # Compute metrics\n",
    "            conf_mse = torch.nn.functional.mse_loss(conf_best_traj, gt_traj_ego)\n",
    "            conf_mae = torch.nn.functional.l1_loss(conf_best_traj, gt_traj_ego)\n",
    "            \n",
    "            # ADE/FDE for confidence-based selection\n",
    "            displacement_errors = torch.norm(conf_best_traj - gt_traj_ego, dim=-1)\n",
    "            conf_ade = displacement_errors.mean(dim=-1)\n",
    "            conf_fde = displacement_errors[:, -1]\n",
    "            \n",
    "            conf_mse_errors.append(conf_mse.item())\n",
    "            conf_mae_errors.append(conf_mae.item())\n",
    "            conf_ade_errors.extend(conf_ade.cpu().numpy())\n",
    "            conf_fde_errors.extend(conf_fde.cpu().numpy())\n",
    "    \n",
    "    print(f\"Confidence-based MSE: {np.mean(conf_mse_errors):.4f} ± {np.std(conf_mse_errors):.4f}\")\n",
    "    print(f\"Confidence-based MAE: {np.mean(conf_mae_errors):.4f} ± {np.std(conf_mae_errors):.4f}\")\n",
    "    print(f\"Confidence-based ADE: {np.mean(conf_ade_errors):.4f} ± {np.std(conf_ade_errors):.4f}\")\n",
    "    print(f\"Confidence-based FDE: {np.mean(conf_fde_errors):.4f} ± {np.std(conf_fde_errors):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
