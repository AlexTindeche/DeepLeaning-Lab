RANDOM SEARCH RESULTS
================================================================================
Started: 2025-07-08 14:33:20
Total experiments: 20
================================================================================

Experiment 1
--------------------------------------------------
HYPERPARAMETERS:
  dim: 24
  encoder_depth: 3
  num_heads: 4
  mlp_ratio: 5
  attention_type: performer
  decoder_embed_dim: 24
  decoder_num_modes: 6
  decoder_hidden_dim: 192
  model_params: 278,921

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4211
  val_MR: 0.9609
  val_brier-minFDE6: 40.6738
  val_minADE1: 20.3966
  val_minADE6: 20.3915
  val_minFDE1: 40.0324
  val_minFDE6: 39.9680

Epoch 1:
  train/loss: 13.4495
  train/loss_step: 13.4495
  train/reg_loss: 8.9403
  train/reg_loss_step: 8.9403
  train/cls_loss: 0.5498
  train/cls_loss_step: 0.5498
  train/others_reg_loss: 3.9593
  train/others_reg_loss_step: 3.9593
  val/reg_loss: 8.1786
  val_MR: 0.9435
  val_brier-minFDE6: 29.4438
  val_minADE1: 16.1243
  val_minADE6: 15.9246
  val_minFDE1: 29.5768
  val_minFDE6: 29.2137

Epoch 2:
  train/loss: 8.3427
  train/loss_step: 8.3427
  train/reg_loss: 3.2312
  train/reg_loss_step: 3.2312
  train/cls_loss: 1.3877
  train/cls_loss_step: 1.3877
  train/others_reg_loss: 3.7237
  train/others_reg_loss_step: 3.7237
  val/reg_loss: 3.0178
  val_MR: 0.7969
  val_brier-minFDE6: 10.9308
  val_minADE1: 7.7190
  val_minADE6: 6.0415
  val_minFDE1: 15.1736
  val_minFDE6: 10.4961
  train/loss_epoch: 14.4236
  train/reg_loss_epoch: 9.5068
  train/cls_loss_epoch: 1.0094
  train/others_reg_loss_epoch: 3.9074

Epoch 3:
  train/loss: 6.3913
  train/loss_step: 6.3913
  train/reg_loss: 1.4152
  train/reg_loss_step: 1.4152
  train/cls_loss: 1.7364
  train/cls_loss_step: 1.7364
  train/others_reg_loss: 3.2397
  train/others_reg_loss_step: 3.2397
  val/reg_loss: 1.7484
  val_MR: 0.7408
  val_brier-minFDE6: 8.1928
  val_minADE1: 10.3628
  val_minADE6: 3.6511
  val_minFDE1: 21.5590
  val_minFDE6: 7.5703
  train/loss_epoch: 9.9405
  train/reg_loss_epoch: 5.1191
  train/cls_loss_epoch: 0.9974
  train/others_reg_loss_epoch: 3.8240

Epoch 4:
  train/loss: 6.6049
  train/loss_step: 6.6049
  train/reg_loss: 1.7400
  train/reg_loss_step: 1.7400
  train/cls_loss: 1.8320
  train/cls_loss_step: 1.8320
  train/others_reg_loss: 3.0329
  train/others_reg_loss_step: 3.0329
  val/reg_loss: 1.3932
  val_MR: 0.6735
  val_brier-minFDE6: 7.0474
  val_minADE1: 10.7673
  val_minADE6: 2.9848
  val_minFDE1: 22.2948
  val_minFDE6: 6.3395
  train/loss_epoch: 7.4095
  train/reg_loss_epoch: 2.1707
  train/cls_loss_epoch: 1.5022
  train/others_reg_loss_epoch: 3.7366

Epoch 5:
  train/loss: 5.8576
  train/loss_step: 5.8576
  train/reg_loss: 1.4183
  train/reg_loss_step: 1.4183
  train/cls_loss: 1.7057
  train/cls_loss_step: 1.7057
  train/others_reg_loss: 2.7336
  train/others_reg_loss_step: 2.7336
  val/reg_loss: 1.2251
  val_MR: 0.6791
  val_brier-minFDE6: 6.3271
  val_minADE1: 5.7895
  val_minADE6: 2.6564
  val_minFDE1: 13.2618
  val_minFDE6: 5.6609
  train/loss_epoch: 6.4210
  train/reg_loss_epoch: 1.4811
  train/cls_loss_epoch: 1.7404
  train/others_reg_loss_epoch: 3.1995

Epoch 6:
  train/loss: 5.1020
  train/loss_step: 5.1020
  train/reg_loss: 0.9780
  train/reg_loss_step: 0.9780
  train/cls_loss: 1.6705
  train/cls_loss_step: 1.6705
  train/others_reg_loss: 2.4535
  train/others_reg_loss_step: 2.4535
  val/reg_loss: 1.1751
  val_MR: 0.6871
  val_brier-minFDE6: 6.2933
  val_minADE1: 5.5909
  val_minADE6: 2.5667
  val_minFDE1: 12.7151
  val_minFDE6: 5.6351
  train/loss_epoch: 5.7064
  train/reg_loss_epoch: 1.3275
  train/cls_loss_epoch: 1.7672
  train/others_reg_loss_epoch: 2.6117

Epoch 7:
  train/loss: 4.8036
  train/loss_step: 4.8036
  train/reg_loss: 1.1805
  train/reg_loss_step: 1.1805
  train/cls_loss: 1.7644
  train/cls_loss_step: 1.7644
  train/others_reg_loss: 1.8587
  train/others_reg_loss_step: 1.8587
  val/reg_loss: 1.3157
  val_MR: 0.7284
  val_brier-minFDE6: 6.8135
  val_minADE1: 9.8411
  val_minADE6: 2.8310
  val_minFDE1: 21.6808
  val_minFDE6: 6.0921
  train/loss_epoch: 5.4604
  train/reg_loss_epoch: 1.2778
  train/cls_loss_epoch: 1.7596
  train/others_reg_loss_epoch: 2.4230

Epoch 8:
  train/loss: 4.6139
  train/loss_step: 4.6139
  train/reg_loss: 1.1122
  train/reg_loss_step: 1.1122
  train/cls_loss: 1.7281
  train/cls_loss_step: 1.7281
  train/others_reg_loss: 1.7736
  train/others_reg_loss_step: 1.7736
  val/reg_loss: 1.2284
  val_MR: 0.6833
  val_brier-minFDE6: 6.2884
  val_minADE1: 6.5924
  val_minADE6: 2.6715
  val_minFDE1: 14.1697
  val_minFDE6: 5.6149
  train/loss_epoch: 5.2916
  train/reg_loss_epoch: 1.2413
  train/cls_loss_epoch: 1.7654
  train/others_reg_loss_epoch: 2.2849

Epoch 9:
  train/loss: 4.0637
  train/loss_step: 4.0637
  train/reg_loss: 0.9340
  train/reg_loss_step: 0.9340
  train/cls_loss: 1.6855
  train/cls_loss_step: 1.6855
  train/others_reg_loss: 1.4443
  train/others_reg_loss_step: 1.4443
  val/reg_loss: 1.1726
  val_MR: 0.6709
  val_brier-minFDE6: 6.1249
  val_minADE1: 4.8633
  val_minADE6: 2.5663
  val_minFDE1: 11.2245
  val_minFDE6: 5.4699
  train/loss_epoch: 4.9303
  train/reg_loss_epoch: 1.2352
  train/cls_loss_epoch: 1.7656
  train/others_reg_loss_epoch: 1.9294

Epoch 10:
  train/loss: 4.5562
  train/loss_step: 4.5562
  train/reg_loss: 1.1236
  train/reg_loss_step: 1.1236
  train/cls_loss: 1.7345
  train/cls_loss_step: 1.7345
  train/others_reg_loss: 1.6981
  train/others_reg_loss_step: 1.6981
  val/reg_loss: 1.0882
  val_MR: 0.6406
  val_brier-minFDE6: 6.0059
  val_minADE1: 4.9095
  val_minADE6: 2.4067
  val_minFDE1: 11.6117
  val_minFDE6: 5.3398
  train/loss_epoch: 4.7654
  train/reg_loss_epoch: 1.2088
  train/cls_loss_epoch: 1.7715
  train/others_reg_loss_epoch: 1.7851

Epoch 11:
  train/loss: 4.7766
  train/loss_step: 4.7766
  train/reg_loss: 1.4890
  train/reg_loss_step: 1.4890
  train/cls_loss: 1.6946
  train/cls_loss_step: 1.6946
  train/others_reg_loss: 1.5930
  train/others_reg_loss_step: 1.5930
  val/reg_loss: 1.2418
  val_MR: 0.6843
  val_brier-minFDE6: 6.1446
  val_minADE1: 5.8719
  val_minADE6: 2.7047
  val_minFDE1: 14.8834
  val_minFDE6: 5.4873
  train/loss_epoch: 4.7782
  train/reg_loss_epoch: 1.2379
  train/cls_loss_epoch: 1.7986
  train/others_reg_loss_epoch: 1.7418

Epoch 12:
  train/loss: 4.6862
  train/loss_step: 4.6862
  train/reg_loss: 1.2834
  train/reg_loss_step: 1.2834
  train/cls_loss: 1.6929
  train/cls_loss_step: 1.6929
  train/others_reg_loss: 1.7099
  train/others_reg_loss_step: 1.7099
  val/reg_loss: 1.1954
  val_MR: 0.6611
  val_brier-minFDE6: 6.3290
  val_minADE1: 6.2068
  val_minADE6: 2.6251
  val_minFDE1: 14.6992
  val_minFDE6: 5.6692
  train/loss_epoch: 4.5929
  train/reg_loss_epoch: 1.1985
  train/cls_loss_epoch: 1.7806
  train/others_reg_loss_epoch: 1.6139

Epoch 13:
  train/loss: 4.7733
  train/loss_step: 4.7733
  train/reg_loss: 1.4503
  train/reg_loss_step: 1.4503
  train/cls_loss: 1.9063
  train/cls_loss_step: 1.9063
  train/others_reg_loss: 1.4167
  train/others_reg_loss_step: 1.4167
  val/reg_loss: 1.0707
  val_MR: 0.6434
  val_brier-minFDE6: 5.9592
  val_minADE1: 4.9611
  val_minADE6: 2.3934
  val_minFDE1: 11.4507
  val_minFDE6: 5.2803
  train/loss_epoch: 4.4203
  train/reg_loss_epoch: 1.1344
  train/cls_loss_epoch: 1.7629
  train/others_reg_loss_epoch: 1.5229

Epoch 14:
  train/loss: 3.8599
  train/loss_step: 3.8599
  train/reg_loss: 1.0441
  train/reg_loss_step: 1.0441
  train/cls_loss: 1.7065
  train/cls_loss_step: 1.7065
  train/others_reg_loss: 1.1093
  train/others_reg_loss_step: 1.1093
  val/reg_loss: 1.0298
  val_MR: 0.5923
  val_brier-minFDE6: 5.8462
  val_minADE1: 4.3351
  val_minADE6: 2.3242
  val_minFDE1: 10.3717
  val_minFDE6: 5.1933
  train/loss_epoch: 4.3894
  train/reg_loss_epoch: 1.1217
  train/cls_loss_epoch: 1.7658
  train/others_reg_loss_epoch: 1.5020

Epoch 15:
  train/loss: 4.1781
  train/loss_step: 4.1781
  train/reg_loss: 0.9949
  train/reg_loss_step: 0.9949
  train/cls_loss: 1.7560
  train/cls_loss_step: 1.7560
  train/others_reg_loss: 1.4273
  train/others_reg_loss_step: 1.4273
  val/reg_loss: 1.0057
  val_MR: 0.5767
  val_brier-minFDE6: 5.8193
  val_minADE1: 4.2453
  val_minADE6: 2.2607
  val_minFDE1: 10.4589
  val_minFDE6: 5.1576
  train/loss_epoch: 4.1634
  train/reg_loss_epoch: 1.0522
  train/cls_loss_epoch: 1.7311
  train/others_reg_loss_epoch: 1.3801

Epoch 16:
  train/loss: 4.5856
  train/loss_step: 4.5856
  train/reg_loss: 1.5065
  train/reg_loss_step: 1.5065
  train/cls_loss: 1.7225
  train/cls_loss_step: 1.7225
  train/others_reg_loss: 1.3566
  train/others_reg_loss_step: 1.3566
  val/reg_loss: 0.9887
  val_MR: 0.5863
  val_brier-minFDE6: 5.7752
  val_minADE1: 4.1437
  val_minADE6: 2.2321
  val_minFDE1: 10.2673
  val_minFDE6: 5.1252
  train/loss_epoch: 4.1502
  train/reg_loss_epoch: 1.0428
  train/cls_loss_epoch: 1.7398
  train/others_reg_loss_epoch: 1.3676

Epoch 17:
  train/loss: 4.4458
  train/loss_step: 4.4458
  train/reg_loss: 1.2380
  train/reg_loss_step: 1.2380
  train/cls_loss: 1.6862
  train/cls_loss_step: 1.6862
  train/others_reg_loss: 1.5215
  train/others_reg_loss_step: 1.5215
  val/reg_loss: 0.9791
  val_MR: 0.5629
  val_brier-minFDE6: 5.7610
  val_minADE1: 4.1081
  val_minADE6: 2.2103
  val_minFDE1: 10.3330
  val_minFDE6: 5.1165
  train/loss_epoch: 4.0991
  train/reg_loss_epoch: 1.0324
  train/cls_loss_epoch: 1.7195
  train/others_reg_loss_epoch: 1.3473

Epoch 18:
  train/loss: 4.0952
  train/loss_step: 4.0952
  train/reg_loss: 1.1909
  train/reg_loss_step: 1.1909
  train/cls_loss: 1.6584
  train/cls_loss_step: 1.6584
  train/others_reg_loss: 1.2459
  train/others_reg_loss_step: 1.2459
  val/reg_loss: 0.9680
  val_MR: 0.5669
  val_brier-minFDE6: 5.6932
  val_minADE1: 3.9962
  val_minADE6: 2.1922
  val_minFDE1: 10.0804
  val_minFDE6: 5.0591
  train/loss_epoch: 3.9707
  train/reg_loss_epoch: 1.0048
  train/cls_loss_epoch: 1.6926
  train/others_reg_loss_epoch: 1.2733

Epoch 19:
  train/loss: 3.6898
  train/loss_step: 3.6898
  train/reg_loss: 0.8245
  train/reg_loss_step: 0.8245
  train/cls_loss: 1.6559
  train/cls_loss_step: 1.6559
  train/others_reg_loss: 1.2094
  train/others_reg_loss_step: 1.2094
  val/reg_loss: 0.9697
  val_MR: 0.5635
  val_brier-minFDE6: 5.6894
  val_minADE1: 3.9084
  val_minADE6: 2.1928
  val_minFDE1: 9.7856
  val_minFDE6: 5.0534
  train/loss_epoch: 3.8839
  train/reg_loss_epoch: 0.9659
  train/cls_loss_epoch: 1.6846
  train/others_reg_loss_epoch: 1.2335

Epoch 20:
  train/loss: 3.6973
  train/loss_step: 3.6973
  train/reg_loss: 0.9380
  train/reg_loss_step: 0.9380
  train/cls_loss: 1.5347
  train/cls_loss_step: 1.5347
  train/others_reg_loss: 1.2247
  train/others_reg_loss_step: 1.2247
  val/reg_loss: 0.9638
  val_MR: 0.5605
  val_brier-minFDE6: 5.6747
  val_minADE1: 3.7688
  val_minADE6: 2.1830
  val_minFDE1: 9.5119
  val_minFDE6: 5.0425
  train/loss_epoch: 3.8312
  train/reg_loss_epoch: 0.9660
  train/cls_loss_epoch: 1.6612
  train/others_reg_loss_epoch: 1.2041

FINAL VALIDATION RESULTS:
  train/loss: 3.8097
  train/loss_step: 3.6973
  train/reg_loss: 0.9463
  train/reg_loss_step: 0.9380
  train/cls_loss: 1.6674
  train/cls_loss_step: 1.5347
  train/others_reg_loss: 1.1961
  train/others_reg_loss_step: 1.2247
  val/reg_loss: 0.9638
  val_MR: 0.5605
  val_brier-minFDE6: 5.6747
  val_minADE1: 3.7688
  val_minADE6: 2.1830
  val_minFDE1: 9.5119
  val_minFDE6: 5.0425
  train/loss_epoch: 3.8097
  train/reg_loss_epoch: 0.9463
  train/cls_loss_epoch: 1.6674
  train/others_reg_loss_epoch: 1.1961

================================================================================

Experiment 2
--------------------------------------------------
HYPERPARAMETERS:
  dim: 32
  encoder_depth: 5
  num_heads: 8
  mlp_ratio: 1
  attention_type: performer
  decoder_embed_dim: 32
  decoder_num_modes: 6
  decoder_hidden_dim: 256
  model_params: 315,665

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4628
  val_MR: 0.9609
  val_brier-minFDE6: 40.8277
  val_minADE1: 20.4648
  val_minADE6: 20.4628
  val_minFDE1: 40.2154
  val_minFDE6: 40.1324

Epoch 1:
  train/loss: 13.4365
  train/loss_step: 13.4365
  train/reg_loss: 8.3912
  train/reg_loss_step: 8.3912
  train/cls_loss: 0.6454
  train/cls_loss_step: 0.6454
  train/others_reg_loss: 4.3998
  train/others_reg_loss_step: 4.3998
  val/reg_loss: 7.9655
  val_MR: 0.9032
  val_brier-minFDE6: 32.1078
  val_minADE1: 15.7844
  val_minADE6: 15.6294
  val_minFDE1: 32.0285
  val_minFDE6: 31.9098

Epoch 2:
  train/loss: 8.3716
  train/loss_step: 8.3716
  train/reg_loss: 2.0299
  train/reg_loss_step: 2.0299
  train/cls_loss: 1.6278
  train/cls_loss_step: 1.6278
  train/others_reg_loss: 4.7139
  train/others_reg_loss_step: 4.7139
  val/reg_loss: 2.1618
  val_MR: 0.7518
  val_brier-minFDE6: 9.1789
  val_minADE1: 8.2857
  val_minADE6: 4.3984
  val_minFDE1: 15.8642
  val_minFDE6: 8.6387
  train/loss_epoch: 14.2629
  train/reg_loss_epoch: 9.4665
  train/cls_loss_epoch: 0.9519
  train/others_reg_loss_epoch: 3.8445

Epoch 3:
  train/loss: 6.6388
  train/loss_step: 6.6388
  train/reg_loss: 0.8921
  train/reg_loss_step: 0.8921
  train/cls_loss: 1.7974
  train/cls_loss_step: 1.7974
  train/others_reg_loss: 3.9493
  train/others_reg_loss_step: 3.9493
  val/reg_loss: 1.4609
  val_MR: 0.6354
  val_brier-minFDE6: 7.2472
  val_minADE1: 7.3106
  val_minADE6: 3.0769
  val_minFDE1: 15.7075
  val_minFDE6: 6.5625
  train/loss_epoch: 9.3732
  train/reg_loss_epoch: 4.3750
  train/cls_loss_epoch: 1.1252
  train/others_reg_loss_epoch: 3.8730

Epoch 4:
  train/loss: 5.5603
  train/loss_step: 5.5603
  train/reg_loss: 1.1568
  train/reg_loss_step: 1.1568
  train/cls_loss: 1.7603
  train/cls_loss_step: 1.7603
  train/others_reg_loss: 2.6432
  train/others_reg_loss_step: 2.6432
  val/reg_loss: 1.3480
  val_MR: 0.6797
  val_brier-minFDE6: 6.6405
  val_minADE1: 5.9912
  val_minADE6: 2.8950
  val_minFDE1: 13.0488
  val_minFDE6: 5.9485
  train/loss_epoch: 7.0892
  train/reg_loss_epoch: 1.6630
  train/cls_loss_epoch: 1.6817
  train/others_reg_loss_epoch: 3.7444

Epoch 5:
  train/loss: 5.1551
  train/loss_step: 5.1551
  train/reg_loss: 1.1880
  train/reg_loss_step: 1.1880
  train/cls_loss: 1.6764
  train/cls_loss_step: 1.6764
  train/others_reg_loss: 2.2907
  train/others_reg_loss_step: 2.2907
  val/reg_loss: 1.2230
  val_MR: 0.6577
  val_brier-minFDE6: 6.1910
  val_minADE1: 5.8654
  val_minADE6: 2.6559
  val_minFDE1: 12.8092
  val_minFDE6: 5.5219
  train/loss_epoch: 6.1666
  train/reg_loss_epoch: 1.3415
  train/cls_loss_epoch: 1.7719
  train/others_reg_loss_epoch: 3.0533

Epoch 6:
  train/loss: 5.7877
  train/loss_step: 5.7877
  train/reg_loss: 1.5172
  train/reg_loss_step: 1.5172
  train/cls_loss: 1.7713
  train/cls_loss_step: 1.7713
  train/others_reg_loss: 2.4991
  train/others_reg_loss_step: 2.4991
  val/reg_loss: 1.1739
  val_MR: 0.6615
  val_brier-minFDE6: 6.1513
  val_minADE1: 5.0657
  val_minADE6: 2.5634
  val_minFDE1: 11.7558
  val_minFDE6: 5.4909
  train/loss_epoch: 5.4556
  train/reg_loss_epoch: 1.2708
  train/cls_loss_epoch: 1.7542
  train/others_reg_loss_epoch: 2.4306

Epoch 7:
  train/loss: 4.6511
  train/loss_step: 4.6511
  train/reg_loss: 1.3945
  train/reg_loss_step: 1.3945
  train/cls_loss: 1.7036
  train/cls_loss_step: 1.7036
  train/others_reg_loss: 1.5531
  train/others_reg_loss_step: 1.5531
  val/reg_loss: 1.1327
  val_MR: 0.6484
  val_brier-minFDE6: 6.0800
  val_minADE1: 5.1364
  val_minADE6: 2.4896
  val_minFDE1: 11.9619
  val_minFDE6: 5.4239
  train/loss_epoch: 5.1309
  train/reg_loss_epoch: 1.2149
  train/cls_loss_epoch: 1.7396
  train/others_reg_loss_epoch: 2.1764

Epoch 8:
  train/loss: 4.7034
  train/loss_step: 4.7034
  train/reg_loss: 1.2365
  train/reg_loss_step: 1.2365
  train/cls_loss: 1.7211
  train/cls_loss_step: 1.7211
  train/others_reg_loss: 1.7458
  train/others_reg_loss_step: 1.7458
  val/reg_loss: 1.1565
  val_MR: 0.6510
  val_brier-minFDE6: 6.2727
  val_minADE1: 5.0856
  val_minADE6: 2.5303
  val_minFDE1: 12.1322
  val_minFDE6: 5.6007
  train/loss_epoch: 4.9749
  train/reg_loss_epoch: 1.2229
  train/cls_loss_epoch: 1.7662
  train/others_reg_loss_epoch: 1.9857

Epoch 9:
  train/loss: 4.9460
  train/loss_step: 4.9460
  train/reg_loss: 1.3945
  train/reg_loss_step: 1.3945
  train/cls_loss: 1.8095
  train/cls_loss_step: 1.8095
  train/others_reg_loss: 1.7420
  train/others_reg_loss_step: 1.7420
  val/reg_loss: 1.2681
  val_MR: 0.6428
  val_brier-minFDE6: 6.4640
  val_minADE1: 8.5558
  val_minADE6: 2.7597
  val_minFDE1: 18.2151
  val_minFDE6: 5.7452
  train/loss_epoch: 4.6891
  train/reg_loss_epoch: 1.1935
  train/cls_loss_epoch: 1.7545
  train/others_reg_loss_epoch: 1.7411

Epoch 10:
  train/loss: 3.9484
  train/loss_step: 3.9484
  train/reg_loss: 1.0468
  train/reg_loss_step: 1.0468
  train/cls_loss: 1.7625
  train/cls_loss_step: 1.7625
  train/others_reg_loss: 1.1391
  train/others_reg_loss_step: 1.1391
  val/reg_loss: 1.0188
  val_MR: 0.6074
  val_brier-minFDE6: 5.8452
  val_minADE1: 5.5280
  val_minADE6: 2.2867
  val_minFDE1: 13.2334
  val_minFDE6: 5.1733
  train/loss_epoch: 4.5296
  train/reg_loss_epoch: 1.1623
  train/cls_loss_epoch: 1.7616
  train/others_reg_loss_epoch: 1.6058

Epoch 11:
  train/loss: 3.9123
  train/loss_step: 3.9123
  train/reg_loss: 1.0274
  train/reg_loss_step: 1.0274
  train/cls_loss: 1.7129
  train/cls_loss_step: 1.7129
  train/others_reg_loss: 1.1719
  train/others_reg_loss_step: 1.1719
  val/reg_loss: 1.0154
  val_MR: 0.5851
  val_brier-minFDE6: 5.7656
  val_minADE1: 3.9613
  val_minADE6: 2.2873
  val_minFDE1: 9.6902
  val_minFDE6: 5.1206
  train/loss_epoch: 4.4429
  train/reg_loss_epoch: 1.1356
  train/cls_loss_epoch: 1.7759
  train/others_reg_loss_epoch: 1.5314

Epoch 12:
  train/loss: 3.5628
  train/loss_step: 3.5628
  train/reg_loss: 0.6613
  train/reg_loss_step: 0.6613
  train/cls_loss: 1.6992
  train/cls_loss_step: 1.6992
  train/others_reg_loss: 1.2024
  train/others_reg_loss_step: 1.2024
  val/reg_loss: 1.0792
  val_MR: 0.5817
  val_brier-minFDE6: 5.8487
  val_minADE1: 4.0942
  val_minADE6: 2.4172
  val_minFDE1: 9.7957
  val_minFDE6: 5.1973
  train/loss_epoch: 4.2460
  train/reg_loss_epoch: 1.0842
  train/cls_loss_epoch: 1.7457
  train/others_reg_loss_epoch: 1.4161

Epoch 13:
  train/loss: 3.3299
  train/loss_step: 3.3299
  train/reg_loss: 0.7342
  train/reg_loss_step: 0.7342
  train/cls_loss: 1.5912
  train/cls_loss_step: 1.5912
  train/others_reg_loss: 1.0046
  train/others_reg_loss_step: 1.0046
  val/reg_loss: 1.0492
  val_MR: 0.6046
  val_brier-minFDE6: 5.7944
  val_minADE1: 4.1693
  val_minADE6: 2.3686
  val_minFDE1: 10.0542
  val_minFDE6: 5.1682
  train/loss_epoch: 4.3515
  train/reg_loss_epoch: 1.1222
  train/cls_loss_epoch: 1.7646
  train/others_reg_loss_epoch: 1.4648

Epoch 14:
  train/loss: 4.1384
  train/loss_step: 4.1384
  train/reg_loss: 1.0302
  train/reg_loss_step: 1.0302
  train/cls_loss: 1.7045
  train/cls_loss_step: 1.7045
  train/others_reg_loss: 1.4038
  train/others_reg_loss_step: 1.4038
  val/reg_loss: 0.9844
  val_MR: 0.5725
  val_brier-minFDE6: 5.7407
  val_minADE1: 3.9439
  val_minADE6: 2.2216
  val_minFDE1: 9.9580
  val_minFDE6: 5.0943
  train/loss_epoch: 4.1045
  train/reg_loss_epoch: 1.0428
  train/cls_loss_epoch: 1.7278
  train/others_reg_loss_epoch: 1.3338

Epoch 15:
  train/loss: 3.8833
  train/loss_step: 3.8833
  train/reg_loss: 0.8610
  train/reg_loss_step: 0.8610
  train/cls_loss: 1.8225
  train/cls_loss_step: 1.8225
  train/others_reg_loss: 1.1998
  train/others_reg_loss_step: 1.1998
  val/reg_loss: 1.0595
  val_MR: 0.5727
  val_brier-minFDE6: 6.0746
  val_minADE1: 4.2410
  val_minADE6: 2.3696
  val_minFDE1: 10.6767
  val_minFDE6: 5.3947
  train/loss_epoch: 4.0802
  train/reg_loss_epoch: 1.0396
  train/cls_loss_epoch: 1.7326
  train/others_reg_loss_epoch: 1.3080

Epoch 16:
  train/loss: 4.1054
  train/loss_step: 4.1054
  train/reg_loss: 1.0083
  train/reg_loss_step: 1.0083
  train/cls_loss: 1.8491
  train/cls_loss_step: 1.8491
  train/others_reg_loss: 1.2480
  train/others_reg_loss_step: 1.2480
  val/reg_loss: 1.0080
  val_MR: 0.5599
  val_brier-minFDE6: 5.8464
  val_minADE1: 4.1536
  val_minADE6: 2.2616
  val_minFDE1: 10.2310
  val_minFDE6: 5.1818
  train/loss_epoch: 3.9932
  train/reg_loss_epoch: 1.0122
  train/cls_loss_epoch: 1.7119
  train/others_reg_loss_epoch: 1.2691

Epoch 17:
  train/loss: 3.4084
  train/loss_step: 3.4084
  train/reg_loss: 0.6159
  train/reg_loss_step: 0.6159
  train/cls_loss: 1.6076
  train/cls_loss_step: 1.6076
  train/others_reg_loss: 1.1850
  train/others_reg_loss_step: 1.1850
  val/reg_loss: 0.9907
  val_MR: 0.5529
  val_brier-minFDE6: 5.6967
  val_minADE1: 3.7996
  val_minADE6: 2.2387
  val_minFDE1: 9.4520
  val_minFDE6: 5.0507
  train/loss_epoch: 3.9123
  train/reg_loss_epoch: 0.9855
  train/cls_loss_epoch: 1.6935
  train/others_reg_loss_epoch: 1.2333

Epoch 18:
  train/loss: 3.8179
  train/loss_step: 3.8179
  train/reg_loss: 0.8525
  train/reg_loss_step: 0.8525
  train/cls_loss: 1.6744
  train/cls_loss_step: 1.6744
  train/others_reg_loss: 1.2910
  train/others_reg_loss_step: 1.2910
  val/reg_loss: 0.9610
  val_MR: 0.5543
  val_brier-minFDE6: 5.6650
  val_minADE1: 3.7013
  val_minADE6: 2.1747
  val_minFDE1: 9.2550
  val_minFDE6: 5.0219
  train/loss_epoch: 3.9166
  train/reg_loss_epoch: 0.9845
  train/cls_loss_epoch: 1.7200
  train/others_reg_loss_epoch: 1.2121

Epoch 19:
  train/loss: 3.2535
  train/loss_step: 3.2535
  train/reg_loss: 0.5788
  train/reg_loss_step: 0.5788
  train/cls_loss: 1.6037
  train/cls_loss_step: 1.6037
  train/others_reg_loss: 1.0710
  train/others_reg_loss_step: 1.0710
  val/reg_loss: 0.9542
  val_MR: 0.5421
  val_brier-minFDE6: 5.6425
  val_minADE1: 3.6148
  val_minADE6: 2.1644
  val_minFDE1: 9.0616
  val_minFDE6: 5.0067
  train/loss_epoch: 3.8503
  train/reg_loss_epoch: 0.9731
  train/cls_loss_epoch: 1.6886
  train/others_reg_loss_epoch: 1.1886

Epoch 20:
  train/loss: 3.5068
  train/loss_step: 3.5068
  train/reg_loss: 0.8810
  train/reg_loss_step: 0.8810
  train/cls_loss: 1.6670
  train/cls_loss_step: 1.6670
  train/others_reg_loss: 0.9588
  train/others_reg_loss_step: 0.9588
  val/reg_loss: 0.9536
  val_MR: 0.5443
  val_brier-minFDE6: 5.6415
  val_minADE1: 3.6495
  val_minADE6: 2.1640
  val_minFDE1: 9.1444
  val_minFDE6: 5.0062
  train/loss_epoch: 3.7949
  train/reg_loss_epoch: 0.9496
  train/cls_loss_epoch: 1.6686
  train/others_reg_loss_epoch: 1.1767

FINAL VALIDATION RESULTS:
  train/loss: 3.7890
  train/loss_step: 3.5068
  train/reg_loss: 0.9539
  train/reg_loss_step: 0.8810
  train/cls_loss: 1.6738
  train/cls_loss_step: 1.6670
  train/others_reg_loss: 1.1614
  train/others_reg_loss_step: 0.9588
  val/reg_loss: 0.9536
  val_MR: 0.5443
  val_brier-minFDE6: 5.6415
  val_minADE1: 3.6495
  val_minADE6: 2.1640
  val_minFDE1: 9.1444
  val_minFDE6: 5.0062
  train/loss_epoch: 3.7890
  train/reg_loss_epoch: 0.9539
  train/cls_loss_epoch: 1.6738
  train/others_reg_loss_epoch: 1.1614

================================================================================

Experiment 3
--------------------------------------------------
HYPERPARAMETERS:
  dim: 48
  encoder_depth: 1
  num_heads: 8
  mlp_ratio: 4
  attention_type: standard
  decoder_embed_dim: 48
  decoder_num_modes: 6
  decoder_hidden_dim: 64
  model_params: 304,257

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4168
  val_MR: 0.9609
  val_brier-minFDE6: 40.7075
  val_minADE1: 20.3978
  val_minADE6: 20.3821
  val_minFDE1: 40.0796
  val_minFDE6: 40.0202

Epoch 1:
  train/loss: 10.7795
  train/loss_step: 10.7795
  train/reg_loss: 6.1158
  train/reg_loss_step: 6.1158
  train/cls_loss: 0.8102
  train/cls_loss_step: 0.8102
  train/others_reg_loss: 3.8534
  train/others_reg_loss_step: 3.8534
  val/reg_loss: 6.5812
  val_MR: 0.9669
  val_brier-minFDE6: 27.1830
  val_minADE1: 13.4637
  val_minADE6: 12.9962
  val_minFDE1: 27.3762
  val_minFDE6: 26.9112

Epoch 2:
  train/loss: 6.9798
  train/loss_step: 6.9798
  train/reg_loss: 1.5636
  train/reg_loss_step: 1.5636
  train/cls_loss: 1.4255
  train/cls_loss_step: 1.4255
  train/others_reg_loss: 3.9907
  train/others_reg_loss_step: 3.9907
  val/reg_loss: 1.6817
  val_MR: 0.6989
  val_brier-minFDE6: 7.9611
  val_minADE1: 5.8606
  val_minADE6: 3.4954
  val_minFDE1: 12.5205
  val_minFDE6: 7.4030
  train/loss_epoch: 13.5889
  train/reg_loss_epoch: 8.6550
  train/cls_loss_epoch: 1.0317
  train/others_reg_loss_epoch: 3.9022

Epoch 3:
  train/loss: 7.0503
  train/loss_step: 7.0503
  train/reg_loss: 1.3343
  train/reg_loss_step: 1.3343
  train/cls_loss: 1.7555
  train/cls_loss_step: 1.7555
  train/others_reg_loss: 3.9605
  train/others_reg_loss_step: 3.9605
  val/reg_loss: 1.3700
  val_MR: 0.6420
  val_brier-minFDE6: 6.7214
  val_minADE1: 6.9798
  val_minADE6: 2.9518
  val_minFDE1: 14.4117
  val_minFDE6: 6.0320
  train/loss_epoch: 8.5085
  train/reg_loss_epoch: 3.4565
  train/cls_loss_epoch: 1.2014
  train/others_reg_loss_epoch: 3.8506

Epoch 4:
  train/loss: 8.2544
  train/loss_step: 8.2544
  train/reg_loss: 2.7085
  train/reg_loss_step: 2.7085
  train/cls_loss: 1.9822
  train/cls_loss_step: 1.9822
  train/others_reg_loss: 3.5636
  train/others_reg_loss_step: 3.5636
  val/reg_loss: 2.9013
  val_MR: 0.7875
  val_brier-minFDE6: 12.5008
  val_minADE1: 10.6667
  val_minADE6: 5.8364
  val_minFDE1: 21.0199
  val_minFDE6: 11.7608
  train/loss_epoch: 7.0349
  train/reg_loss_epoch: 1.3968
  train/cls_loss_epoch: 1.7192
  train/others_reg_loss_epoch: 3.9189

Epoch 5:
  train/loss: 4.6981
  train/loss_step: 4.6981
  train/reg_loss: 0.7464
  train/reg_loss_step: 0.7464
  train/cls_loss: 1.6953
  train/cls_loss_step: 1.6953
  train/others_reg_loss: 2.2564
  train/others_reg_loss_step: 2.2564
  val/reg_loss: 1.1311
  val_MR: 0.6136
  val_brier-minFDE6: 5.9583
  val_minADE1: 4.5835
  val_minADE6: 2.4970
  val_minFDE1: 10.4050
  val_minFDE6: 5.2899
  train/loss_epoch: 6.9828
  train/reg_loss_epoch: 1.4066
  train/cls_loss_epoch: 1.8067
  train/others_reg_loss_epoch: 3.7694

Epoch 6:
  train/loss: 5.0511
  train/loss_step: 5.0511
  train/reg_loss: 1.1979
  train/reg_loss_step: 1.1979
  train/cls_loss: 1.6332
  train/cls_loss_step: 1.6332
  train/others_reg_loss: 2.2200
  train/others_reg_loss_step: 2.2200
  val/reg_loss: 1.0930
  val_MR: 0.6312
  val_brier-minFDE6: 5.9820
  val_minADE1: 4.3792
  val_minADE6: 2.4296
  val_minFDE1: 10.5411
  val_minFDE6: 5.3370
  train/loss_epoch: 6.0754
  train/reg_loss_epoch: 1.2229
  train/cls_loss_epoch: 1.7831
  train/others_reg_loss_epoch: 3.0694

Epoch 7:
  train/loss: 4.8874
  train/loss_step: 4.8874
  train/reg_loss: 1.0433
  train/reg_loss_step: 1.0433
  train/cls_loss: 1.6678
  train/cls_loss_step: 1.6678
  train/others_reg_loss: 2.1763
  train/others_reg_loss_step: 2.1763
  val/reg_loss: 1.0568
  val_MR: 0.5938
  val_brier-minFDE6: 5.9404
  val_minADE1: 4.5755
  val_minADE6: 2.3598
  val_minFDE1: 10.9259
  val_minFDE6: 5.2760
  train/loss_epoch: 5.1288
  train/reg_loss_epoch: 1.1147
  train/cls_loss_epoch: 1.7441
  train/others_reg_loss_epoch: 2.2700

Epoch 8:
  train/loss: 4.1868
  train/loss_step: 4.1868
  train/reg_loss: 1.1003
  train/reg_loss_step: 1.1003
  train/cls_loss: 1.7630
  train/cls_loss_step: 1.7630
  train/others_reg_loss: 1.3235
  train/others_reg_loss_step: 1.3235
  val/reg_loss: 1.0608
  val_MR: 0.5946
  val_brier-minFDE6: 5.9422
  val_minADE1: 4.5760
  val_minADE6: 2.3665
  val_minFDE1: 10.8508
  val_minFDE6: 5.2756
  train/loss_epoch: 4.9409
  train/reg_loss_epoch: 1.1238
  train/cls_loss_epoch: 1.7554
  train/others_reg_loss_epoch: 2.0617

Epoch 9:
  train/loss: 4.4758
  train/loss_step: 4.4758
  train/reg_loss: 0.8138
  train/reg_loss_step: 0.8138
  train/cls_loss: 2.1263
  train/cls_loss_step: 2.1263
  train/others_reg_loss: 1.5356
  train/others_reg_loss_step: 1.5356
  val/reg_loss: 1.1408
  val_MR: 0.6593
  val_brier-minFDE6: 6.3216
  val_minADE1: 6.2339
  val_minADE6: 2.5246
  val_minFDE1: 14.0163
  val_minFDE6: 5.6042
  train/loss_epoch: 4.6582
  train/reg_loss_epoch: 1.0771
  train/cls_loss_epoch: 1.7393
  train/others_reg_loss_epoch: 1.8417

Epoch 10:
  train/loss: 4.1682
  train/loss_step: 4.1682
  train/reg_loss: 0.9156
  train/reg_loss_step: 0.9156
  train/cls_loss: 1.9062
  train/cls_loss_step: 1.9062
  train/others_reg_loss: 1.3463
  train/others_reg_loss_step: 1.3463
  val/reg_loss: 1.0554
  val_MR: 0.5933
  val_brier-minFDE6: 6.0583
  val_minADE1: 4.9000
  val_minADE6: 2.3672
  val_minFDE1: 12.0045
  val_minFDE6: 5.3812
  train/loss_epoch: 4.3124
  train/reg_loss_epoch: 1.0535
  train/cls_loss_epoch: 1.7297
  train/others_reg_loss_epoch: 1.5292

Epoch 11:
  train/loss: 3.8261
  train/loss_step: 3.8261
  train/reg_loss: 0.9978
  train/reg_loss_step: 0.9978
  train/cls_loss: 1.6024
  train/cls_loss_step: 1.6024
  train/others_reg_loss: 1.2259
  train/others_reg_loss_step: 1.2259
  val/reg_loss: 1.0596
  val_MR: 0.6230
  val_brier-minFDE6: 5.9455
  val_minADE1: 4.5643
  val_minADE6: 2.3732
  val_minFDE1: 10.6687
  val_minFDE6: 5.2971
  train/loss_epoch: 4.2275
  train/reg_loss_epoch: 1.0325
  train/cls_loss_epoch: 1.7404
  train/others_reg_loss_epoch: 1.4547

Epoch 12:
  train/loss: 4.2186
  train/loss_step: 4.2186
  train/reg_loss: 1.2909
  train/reg_loss_step: 1.2909
  train/cls_loss: 1.7221
  train/cls_loss_step: 1.7221
  train/others_reg_loss: 1.2056
  train/others_reg_loss_step: 1.2056
  val/reg_loss: 1.0099
  val_MR: 0.6070
  val_brier-minFDE6: 5.9403
  val_minADE1: 4.7322
  val_minADE6: 2.2617
  val_minFDE1: 11.7546
  val_minFDE6: 5.2782
  train/loss_epoch: 4.2625
  train/reg_loss_epoch: 1.0659
  train/cls_loss_epoch: 1.7331
  train/others_reg_loss_epoch: 1.4635

Epoch 13:
  train/loss: 3.6101
  train/loss_step: 3.6101
  train/reg_loss: 0.7653
  train/reg_loss_step: 0.7653
  train/cls_loss: 1.6037
  train/cls_loss_step: 1.6037
  train/others_reg_loss: 1.2411
  train/others_reg_loss_step: 1.2411
  val/reg_loss: 0.9605
  val_MR: 0.5465
  val_brier-minFDE6: 5.6250
  val_minADE1: 3.8600
  val_minADE6: 2.1763
  val_minFDE1: 9.4715
  val_minFDE6: 4.9810
  train/loss_epoch: 4.1800
  train/reg_loss_epoch: 1.0439
  train/cls_loss_epoch: 1.7493
  train/others_reg_loss_epoch: 1.3868

Epoch 14:
  train/loss: 4.2099
  train/loss_step: 4.2099
  train/reg_loss: 0.9398
  train/reg_loss_step: 0.9398
  train/cls_loss: 1.7642
  train/cls_loss_step: 1.7642
  train/others_reg_loss: 1.5059
  train/others_reg_loss_step: 1.5059
  val/reg_loss: 1.1368
  val_MR: 0.5621
  val_brier-minFDE6: 5.6177
  val_minADE1: 4.8505
  val_minADE6: 2.5090
  val_minFDE1: 10.4460
  val_minFDE6: 4.9481
  train/loss_epoch: 4.0878
  train/reg_loss_epoch: 1.0248
  train/cls_loss_epoch: 1.7259
  train/others_reg_loss_epoch: 1.3372

Epoch 15:
  train/loss: 3.6962
  train/loss_step: 3.6962
  train/reg_loss: 1.0349
  train/reg_loss_step: 1.0349
  train/cls_loss: 1.5943
  train/cls_loss_step: 1.5943
  train/others_reg_loss: 1.0670
  train/others_reg_loss_step: 1.0670
  val/reg_loss: 0.9140
  val_MR: 0.5625
  val_brier-minFDE6: 5.3240
  val_minADE1: 3.6054
  val_minADE6: 2.0622
  val_minFDE1: 9.0519
  val_minFDE6: 4.6763
  train/loss_epoch: 3.9248
  train/reg_loss_epoch: 0.9643
  train/cls_loss_epoch: 1.7066
  train/others_reg_loss_epoch: 1.2540

Epoch 16:
  train/loss: 3.5289
  train/loss_step: 3.5289
  train/reg_loss: 0.6415
  train/reg_loss_step: 0.6415
  train/cls_loss: 1.5846
  train/cls_loss_step: 1.5846
  train/others_reg_loss: 1.3028
  train/others_reg_loss_step: 1.3028
  val/reg_loss: 0.8191
  val_MR: 0.5373
  val_brier-minFDE6: 4.8778
  val_minADE1: 3.6272
  val_minADE6: 1.8965
  val_minFDE1: 8.9840
  val_minFDE6: 4.2400
  train/loss_epoch: 3.8501
  train/reg_loss_epoch: 0.9209
  train/cls_loss_epoch: 1.7096
  train/others_reg_loss_epoch: 1.2196

Epoch 17:
  train/loss: 3.5974
  train/loss_step: 3.5974
  train/reg_loss: 0.7850
  train/reg_loss_step: 0.7850
  train/cls_loss: 1.6251
  train/cls_loss_step: 1.6251
  train/others_reg_loss: 1.1873
  train/others_reg_loss_step: 1.1873
  val/reg_loss: 0.7473
  val_MR: 0.5152
  val_brier-minFDE6: 4.6383
  val_minADE1: 3.6213
  val_minADE6: 1.7439
  val_minFDE1: 9.1150
  val_minFDE6: 4.0058
  train/loss_epoch: 3.7394
  train/reg_loss_epoch: 0.8639
  train/cls_loss_epoch: 1.7263
  train/others_reg_loss_epoch: 1.1492

Epoch 18:
  train/loss: 3.8341
  train/loss_step: 3.8341
  train/reg_loss: 0.9950
  train/reg_loss_step: 0.9950
  train/cls_loss: 1.7051
  train/cls_loss_step: 1.7051
  train/others_reg_loss: 1.1341
  train/others_reg_loss_step: 1.1341
  val/reg_loss: 0.7470
  val_MR: 0.5220
  val_brier-minFDE6: 4.4636
  val_minADE1: 3.7415
  val_minADE6: 1.7707
  val_minFDE1: 9.0591
  val_minFDE6: 3.8180
  train/loss_epoch: 3.5348
  train/reg_loss_epoch: 0.7752
  train/cls_loss_epoch: 1.6825
  train/others_reg_loss_epoch: 1.0771

Epoch 19:
  train/loss: 3.4679
  train/loss_step: 3.4679
  train/reg_loss: 0.6306
  train/reg_loss_step: 0.6306
  train/cls_loss: 1.7051
  train/cls_loss_step: 1.7051
  train/others_reg_loss: 1.1322
  train/others_reg_loss_step: 1.1322
  val/reg_loss: 0.6848
  val_MR: 0.5204
  val_brier-minFDE6: 4.3215
  val_minADE1: 3.3821
  val_minADE6: 1.6253
  val_minFDE1: 8.4521
  val_minFDE6: 3.6944
  train/loss_epoch: 3.4328
  train/reg_loss_epoch: 0.7299
  train/cls_loss_epoch: 1.6788
  train/others_reg_loss_epoch: 1.0241

Epoch 20:
  train/loss: 2.9939
  train/loss_step: 2.9939
  train/reg_loss: 0.6027
  train/reg_loss_step: 0.6027
  train/cls_loss: 1.6446
  train/cls_loss_step: 1.6446
  train/others_reg_loss: 0.7465
  train/others_reg_loss_step: 0.7465
  val/reg_loss: 0.6691
  val_MR: 0.4984
  val_brier-minFDE6: 4.2359
  val_minADE1: 3.2395
  val_minADE6: 1.5964
  val_minFDE1: 8.1656
  val_minFDE6: 3.6065
  train/loss_epoch: 3.3292
  train/reg_loss_epoch: 0.6964
  train/cls_loss_epoch: 1.6578
  train/others_reg_loss_epoch: 0.9750

FINAL VALIDATION RESULTS:
  train/loss: 3.2338
  train/loss_step: 2.9939
  train/reg_loss: 0.6538
  train/reg_loss_step: 0.6027
  train/cls_loss: 1.6339
  train/cls_loss_step: 1.6446
  train/others_reg_loss: 0.9462
  train/others_reg_loss_step: 0.7465
  val/reg_loss: 0.6691
  val_MR: 0.4984
  val_brier-minFDE6: 4.2359
  val_minADE1: 3.2395
  val_minADE6: 1.5964
  val_minFDE1: 8.1656
  val_minFDE6: 3.6065
  train/loss_epoch: 3.2338
  train/reg_loss_epoch: 0.6538
  train/cls_loss_epoch: 1.6339
  train/others_reg_loss_epoch: 0.9462

================================================================================

Experiment 4
--------------------------------------------------
HYPERPARAMETERS:
  dim: 128
  encoder_depth: 2
  num_heads: 4
  mlp_ratio: 2
  attention_type: linear
  decoder_embed_dim: 128
  decoder_num_modes: 3
  decoder_hidden_dim: 256
  model_params: 956,913

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.5260
  val_MR: 0.9609
  val_brier-minFDE6: 40.8096
  val_minADE1: 20.5428
  val_minADE6: 20.5393
  val_minFDE1: 40.3911
  val_minFDE6: 40.3592

Epoch 1:
  train/loss: 8.1723
  train/loss_step: 8.1723
  train/reg_loss: 3.7227
  train/reg_loss_step: 3.7227
  train/cls_loss: 0.8267
  train/cls_loss_step: 0.8267
  train/others_reg_loss: 3.6229
  train/others_reg_loss_step: 3.6229
  val/reg_loss: 3.4596
  val_MR: 0.9067
  val_brier-minFDE6: 15.7349
  val_minADE1: 7.7095
  val_minADE6: 6.8721
  val_minFDE1: 16.8545
  val_minFDE6: 15.4603

Epoch 2:
  train/loss: 6.1292
  train/loss_step: 6.1292
  train/reg_loss: 1.8686
  train/reg_loss_step: 1.8686
  train/cls_loss: 1.0980
  train/cls_loss_step: 1.0980
  train/others_reg_loss: 3.1626
  train/others_reg_loss_step: 3.1626
  val/reg_loss: 2.0129
  val_MR: 0.8073
  val_brier-minFDE6: 9.2767
  val_minADE1: 8.7663
  val_minADE6: 4.1150
  val_minFDE1: 16.9006
  val_minFDE6: 8.8371
  train/loss_epoch: 11.5721
  train/reg_loss_epoch: 6.9876
  train/cls_loss_epoch: 0.7083
  train/others_reg_loss_epoch: 3.8762

Epoch 3:
  train/loss: 5.0884
  train/loss_step: 5.0884
  train/reg_loss: 1.4053
  train/reg_loss_step: 1.4053
  train/cls_loss: 1.0539
  train/cls_loss_step: 1.0539
  train/others_reg_loss: 2.6291
  train/others_reg_loss_step: 2.6291
  val/reg_loss: 1.5864
  val_MR: 0.8051
  val_brier-minFDE6: 7.7563
  val_minADE1: 5.7758
  val_minADE6: 3.3260
  val_minFDE1: 12.6576
  val_minFDE6: 7.3176
  train/loss_epoch: 7.2368
  train/reg_loss_epoch: 2.4229
  train/cls_loss_epoch: 1.0209
  train/others_reg_loss_epoch: 3.7930

Epoch 4:
  train/loss: 5.2493
  train/loss_step: 5.2493
  train/reg_loss: 1.9563
  train/reg_loss_step: 1.9563
  train/cls_loss: 1.1770
  train/cls_loss_step: 1.1770
  train/others_reg_loss: 2.1160
  train/others_reg_loss_step: 2.1160
  val/reg_loss: 1.8002
  val_MR: 0.8091
  val_brier-minFDE6: 8.7203
  val_minADE1: 7.7599
  val_minADE6: 3.6986
  val_minFDE1: 16.5495
  val_minFDE6: 8.2405
  train/loss_epoch: 6.0421
  train/reg_loss_epoch: 1.7054
  train/cls_loss_epoch: 1.0913
  train/others_reg_loss_epoch: 3.2454

Epoch 5:
  train/loss: 4.3528
  train/loss_step: 4.3528
  train/reg_loss: 1.5267
  train/reg_loss_step: 1.5267
  train/cls_loss: 1.1278
  train/cls_loss_step: 1.1278
  train/others_reg_loss: 1.6983
  train/others_reg_loss_step: 1.6983
  val/reg_loss: 1.3365
  val_MR: 0.7610
  val_brier-minFDE6: 6.8838
  val_minADE1: 4.6256
  val_minADE6: 2.8574
  val_minFDE1: 11.0416
  val_minFDE6: 6.4442
  train/loss_epoch: 5.0431
  train/reg_loss_epoch: 1.5217
  train/cls_loss_epoch: 1.0941
  train/others_reg_loss_epoch: 2.4273

Epoch 6:
  train/loss: 4.2364
  train/loss_step: 4.2364
  train/reg_loss: 1.5763
  train/reg_loss_step: 1.5763
  train/cls_loss: 1.2210
  train/cls_loss_step: 1.2210
  train/others_reg_loss: 1.4392
  train/others_reg_loss_step: 1.4392
  val/reg_loss: 1.7111
  val_MR: 0.7772
  val_brier-minFDE6: 8.6261
  val_minADE1: 6.5283
  val_minADE6: 3.5553
  val_minFDE1: 15.0592
  val_minFDE6: 8.1497
  train/loss_epoch: 4.6657
  train/reg_loss_epoch: 1.5069
  train/cls_loss_epoch: 1.0984
  train/others_reg_loss_epoch: 2.0603

Epoch 7:
  train/loss: 3.6259
  train/loss_step: 3.6259
  train/reg_loss: 1.1216
  train/reg_loss_step: 1.1216
  train/cls_loss: 1.0725
  train/cls_loss_step: 1.0725
  train/others_reg_loss: 1.4319
  train/others_reg_loss_step: 1.4319
  val/reg_loss: 1.2673
  val_MR: 0.7364
  val_brier-minFDE6: 6.7041
  val_minADE1: 4.1609
  val_minADE6: 2.7365
  val_minFDE1: 9.9885
  val_minFDE6: 6.2702
  train/loss_epoch: 4.4651
  train/reg_loss_epoch: 1.4977
  train/cls_loss_epoch: 1.1097
  train/others_reg_loss_epoch: 1.8578

Epoch 8:
  train/loss: 3.9438
  train/loss_step: 3.9438
  train/reg_loss: 1.0475
  train/reg_loss_step: 1.0475
  train/cls_loss: 1.1554
  train/cls_loss_step: 1.1554
  train/others_reg_loss: 1.7408
  train/others_reg_loss_step: 1.7408
  val/reg_loss: 1.2640
  val_MR: 0.7646
  val_brier-minFDE6: 6.6149
  val_minADE1: 4.4714
  val_minADE6: 2.7345
  val_minFDE1: 10.3393
  val_minFDE6: 6.1778
  train/loss_epoch: 4.0783
  train/reg_loss_epoch: 1.4089
  train/cls_loss_epoch: 1.0992
  train/others_reg_loss_epoch: 1.5701

Epoch 9:
  train/loss: 3.5863
  train/loss_step: 3.5863
  train/reg_loss: 1.0345
  train/reg_loss_step: 1.0345
  train/cls_loss: 1.1100
  train/cls_loss_step: 1.1100
  train/others_reg_loss: 1.4418
  train/others_reg_loss_step: 1.4418
  val/reg_loss: 1.3175
  val_MR: 0.7566
  val_brier-minFDE6: 6.7292
  val_minADE1: 4.6944
  val_minADE6: 2.8322
  val_minFDE1: 11.4601
  val_minFDE6: 6.3119
  train/loss_epoch: 4.1896
  train/reg_loss_epoch: 1.4864
  train/cls_loss_epoch: 1.1071
  train/others_reg_loss_epoch: 1.5962

Epoch 10:
  train/loss: 3.2935
  train/loss_step: 3.2935
  train/reg_loss: 1.0216
  train/reg_loss_step: 1.0216
  train/cls_loss: 1.0935
  train/cls_loss_step: 1.0935
  train/others_reg_loss: 1.1784
  train/others_reg_loss_step: 1.1784
  val/reg_loss: 1.1540
  val_MR: 0.7177
  val_brier-minFDE6: 6.3292
  val_minADE1: 4.2061
  val_minADE6: 2.5229
  val_minFDE1: 10.3507
  val_minFDE6: 5.8793
  train/loss_epoch: 4.0787
  train/reg_loss_epoch: 1.4503
  train/cls_loss_epoch: 1.1046
  train/others_reg_loss_epoch: 1.5238

Epoch 11:
  train/loss: 3.9994
  train/loss_step: 3.9994
  train/reg_loss: 1.5236
  train/reg_loss_step: 1.5236
  train/cls_loss: 1.1129
  train/cls_loss_step: 1.1129
  train/others_reg_loss: 1.3629
  train/others_reg_loss_step: 1.3629
  val/reg_loss: 1.2753
  val_MR: 0.7520
  val_brier-minFDE6: 6.7282
  val_minADE1: 4.2236
  val_minADE6: 2.7195
  val_minFDE1: 10.5029
  val_minFDE6: 6.3014
  train/loss_epoch: 3.9573
  train/reg_loss_epoch: 1.3975
  train/cls_loss_epoch: 1.0941
  train/others_reg_loss_epoch: 1.4657

Epoch 12:
  train/loss: 3.5174
  train/loss_step: 3.5174
  train/reg_loss: 1.2108
  train/reg_loss_step: 1.2108
  train/cls_loss: 1.0602
  train/cls_loss_step: 1.0602
  train/others_reg_loss: 1.2464
  train/others_reg_loss_step: 1.2464
  val/reg_loss: 1.1641
  val_MR: 0.7360
  val_brier-minFDE6: 6.0958
  val_minADE1: 4.5257
  val_minADE6: 2.4949
  val_minFDE1: 10.8149
  val_minFDE6: 5.6610
  train/loss_epoch: 3.9097
  train/reg_loss_epoch: 1.3726
  train/cls_loss_epoch: 1.1007
  train/others_reg_loss_epoch: 1.4364

Epoch 13:
  train/loss: 3.0722
  train/loss_step: 3.0722
  train/reg_loss: 1.1447
  train/reg_loss_step: 1.1447
  train/cls_loss: 0.9911
  train/cls_loss_step: 0.9911
  train/others_reg_loss: 0.9363
  train/others_reg_loss_step: 0.9363
  val/reg_loss: 1.0828
  val_MR: 0.7418
  val_brier-minFDE6: 5.8754
  val_minADE1: 3.7142
  val_minADE6: 2.3771
  val_minFDE1: 8.9803
  val_minFDE6: 5.4790
  train/loss_epoch: 3.8083
  train/reg_loss_epoch: 1.3103
  train/cls_loss_epoch: 1.0993
  train/others_reg_loss_epoch: 1.3988

Epoch 14:
  train/loss: 3.1724
  train/loss_step: 3.1724
  train/reg_loss: 1.1176
  train/reg_loss_step: 1.1176
  train/cls_loss: 1.1172
  train/cls_loss_step: 1.1172
  train/others_reg_loss: 0.9377
  train/others_reg_loss_step: 0.9377
  val/reg_loss: 0.9899
  val_MR: 0.7342
  val_brier-minFDE6: 5.5373
  val_minADE1: 3.7185
  val_minADE6: 2.2017
  val_minFDE1: 9.1776
  val_minFDE6: 5.0727
  train/loss_epoch: 3.5374
  train/reg_loss_epoch: 1.1983
  train/cls_loss_epoch: 1.0890
  train/others_reg_loss_epoch: 1.2501

Epoch 15:
  train/loss: 2.5496
  train/loss_step: 2.5496
  train/reg_loss: 0.7759
  train/reg_loss_step: 0.7759
  train/cls_loss: 1.0185
  train/cls_loss_step: 1.0185
  train/others_reg_loss: 0.7551
  train/others_reg_loss_step: 0.7551
  val/reg_loss: 0.9121
  val_MR: 0.7017
  val_brier-minFDE6: 5.0684
  val_minADE1: 3.3357
  val_minADE6: 2.0346
  val_minFDE1: 8.1728
  val_minFDE6: 4.6572
  train/loss_epoch: 3.1182
  train/reg_loss_epoch: 1.0301
  train/cls_loss_epoch: 1.0769
  train/others_reg_loss_epoch: 1.0112

Epoch 16:
  train/loss: 2.8149
  train/loss_step: 2.8149
  train/reg_loss: 0.9431
  train/reg_loss_step: 0.9431
  train/cls_loss: 1.0235
  train/cls_loss_step: 1.0235
  train/others_reg_loss: 0.8483
  train/others_reg_loss_step: 0.8483
  val/reg_loss: 0.9075
  val_MR: 0.6707
  val_brier-minFDE6: 5.2177
  val_minADE1: 3.3562
  val_minADE6: 2.0364
  val_minFDE1: 8.3659
  val_minFDE6: 4.7931
  train/loss_epoch: 3.0311
  train/reg_loss_epoch: 1.0168
  train/cls_loss_epoch: 1.0795
  train/others_reg_loss_epoch: 0.9348

Epoch 17:
  train/loss: 2.6222
  train/loss_step: 2.6222
  train/reg_loss: 0.7955
  train/reg_loss_step: 0.7955
  train/cls_loss: 1.0524
  train/cls_loss_step: 1.0524
  train/others_reg_loss: 0.7743
  train/others_reg_loss_step: 0.7743
  val/reg_loss: 0.8717
  val_MR: 0.7093
  val_brier-minFDE6: 4.9863
  val_minADE1: 3.2104
  val_minADE6: 1.9642
  val_minFDE1: 7.9520
  val_minFDE6: 4.5922
  train/loss_epoch: 2.8563
  train/reg_loss_epoch: 0.9376
  train/cls_loss_epoch: 1.0763
  train/others_reg_loss_epoch: 0.8423

Epoch 18:
  train/loss: 2.7023
  train/loss_step: 2.7023
  train/reg_loss: 0.9892
  train/reg_loss_step: 0.9892
  train/cls_loss: 1.1205
  train/cls_loss_step: 1.1205
  train/others_reg_loss: 0.5926
  train/others_reg_loss_step: 0.5926
  val/reg_loss: 0.7748
  val_MR: 0.6621
  val_brier-minFDE6: 4.6467
  val_minADE1: 3.2347
  val_minADE6: 1.7934
  val_minFDE1: 8.0991
  val_minFDE6: 4.2336
  train/loss_epoch: 2.7380
  train/reg_loss_epoch: 0.8808
  train/cls_loss_epoch: 1.0639
  train/others_reg_loss_epoch: 0.7934

Epoch 19:
  train/loss: 2.8422
  train/loss_step: 2.8422
  train/reg_loss: 1.1252
  train/reg_loss_step: 1.1252
  train/cls_loss: 1.0637
  train/cls_loss_step: 1.0637
  train/others_reg_loss: 0.6533
  train/others_reg_loss_step: 0.6533
  val/reg_loss: 0.7479
  val_MR: 0.6468
  val_brier-minFDE6: 4.4752
  val_minADE1: 2.9411
  val_minADE6: 1.7326
  val_minFDE1: 7.4026
  val_minFDE6: 4.0710
  train/loss_epoch: 2.5983
  train/reg_loss_epoch: 0.8105
  train/cls_loss_epoch: 1.0397
  train/others_reg_loss_epoch: 0.7481

Epoch 20:
  train/loss: 2.1587
  train/loss_step: 2.1587
  train/reg_loss: 0.5658
  train/reg_loss_step: 0.5658
  train/cls_loss: 0.9853
  train/cls_loss_step: 0.9853
  train/others_reg_loss: 0.6076
  train/others_reg_loss_step: 0.6076
  val/reg_loss: 0.7222
  val_MR: 0.6430
  val_brier-minFDE6: 4.3532
  val_minADE1: 2.8291
  val_minADE6: 1.6879
  val_minFDE1: 7.1730
  val_minFDE6: 3.9534
  train/loss_epoch: 2.5253
  train/reg_loss_epoch: 0.7680
  train/cls_loss_epoch: 1.0384
  train/others_reg_loss_epoch: 0.7189

FINAL VALIDATION RESULTS:
  train/loss: 2.4598
  train/loss_step: 2.1587
  train/reg_loss: 0.7363
  train/reg_loss_step: 0.5658
  train/cls_loss: 1.0235
  train/cls_loss_step: 0.9853
  train/others_reg_loss: 0.7001
  train/others_reg_loss_step: 0.6076
  val/reg_loss: 0.7222
  val_MR: 0.6430
  val_brier-minFDE6: 4.3532
  val_minADE1: 2.8291
  val_minADE6: 1.6879
  val_minFDE1: 7.1730
  val_minFDE6: 3.9534
  train/loss_epoch: 2.4598
  train/reg_loss_epoch: 0.7363
  train/cls_loss_epoch: 1.0235
  train/others_reg_loss_epoch: 0.7001

================================================================================

Experiment 5
--------------------------------------------------
HYPERPARAMETERS:
  dim: 128
  encoder_depth: 4
  num_heads: 8
  mlp_ratio: 6
  attention_type: standard
  decoder_embed_dim: 128
  decoder_num_modes: 9
  decoder_hidden_dim: 192
  model_params: 2,522,289

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4700
  val_MR: 0.9609
  val_brier-minFDE6: 40.6250
  val_minADE1: 20.4577
  val_minADE6: 20.4475
  val_minFDE1: 39.9658
  val_minFDE6: 39.9385

Epoch 1:
  train/loss: 8.0252
  train/loss_step: 8.0252
  train/reg_loss: 3.3095
  train/reg_loss_step: 3.3095
  train/cls_loss: 1.1407
  train/cls_loss_step: 1.1407
  train/others_reg_loss: 3.5751
  train/others_reg_loss_step: 3.5751
  val/reg_loss: 3.5626
  val_MR: 0.8898
  val_brier-minFDE6: 17.1695
  val_minADE1: 7.6543
  val_minADE6: 7.0503
  val_minFDE1: 17.9178
  val_minFDE6: 16.8816

Epoch 2:
  train/loss: 7.4679
  train/loss_step: 7.4679
  train/reg_loss: 2.0311
  train/reg_loss_step: 2.0311
  train/cls_loss: 1.4030
  train/cls_loss_step: 1.4030
  train/others_reg_loss: 4.0339
  train/others_reg_loss_step: 4.0339
  val/reg_loss: 2.7343
  val_MR: 0.7802
  val_brier-minFDE6: 11.9021
  val_minADE1: 5.7772
  val_minADE6: 5.4053
  val_minFDE1: 12.6874
  val_minFDE6: 11.4663
  train/loss_epoch: 12.1738
  train/reg_loss_epoch: 7.0306
  train/cls_loss_epoch: 1.2376
  train/others_reg_loss_epoch: 3.9056

Epoch 3:
  train/loss: 5.9871
  train/loss_step: 5.9871
  train/reg_loss: 1.0752
  train/reg_loss_step: 1.0752
  train/cls_loss: 2.0903
  train/cls_loss_step: 2.0903
  train/others_reg_loss: 2.8215
  train/others_reg_loss_step: 2.8215
  val/reg_loss: 1.2093
  val_MR: 0.5655
  val_brier-minFDE6: 6.3595
  val_minADE1: 7.6083
  val_minADE6: 2.6691
  val_minFDE1: 14.8420
  val_minFDE6: 5.6743
  train/loss_epoch: 7.6388
  train/reg_loss_epoch: 2.5314
  train/cls_loss_epoch: 1.2975
  train/others_reg_loss_epoch: 3.8099

Epoch 4:
  train/loss: 4.8004
  train/loss_step: 4.8004
  train/reg_loss: 0.7936
  train/reg_loss_step: 0.7936
  train/cls_loss: 2.1665
  train/cls_loss_step: 2.1665
  train/others_reg_loss: 1.8403
  train/others_reg_loss_step: 1.8403
  val/reg_loss: 1.0065
  val_MR: 0.5825
  val_brier-minFDE6: 6.3458
  val_minADE1: 6.3225
  val_minADE6: 2.5635
  val_minFDE1: 13.6440
  val_minFDE6: 5.6479
  train/loss_epoch: 6.7412
  train/reg_loss_epoch: 1.7966
  train/cls_loss_epoch: 1.7139
  train/others_reg_loss_epoch: 3.2308

Epoch 5:
  train/loss: 4.5242
  train/loss_step: 4.5242
  train/reg_loss: 0.7541
  train/reg_loss_step: 0.7541
  train/cls_loss: 2.2429
  train/cls_loss_step: 2.2429
  train/others_reg_loss: 1.5272
  train/others_reg_loss_step: 1.5272
  val/reg_loss: 1.0339
  val_MR: 0.5803
  val_brier-minFDE6: 7.1878
  val_minADE1: 4.2389
  val_minADE6: 2.7998
  val_minFDE1: 10.4027
  val_minFDE6: 6.5001
  train/loss_epoch: 5.8034
  train/reg_loss_epoch: 1.3039
  train/cls_loss_epoch: 2.1163
  train/others_reg_loss_epoch: 2.3832

Epoch 6:
  train/loss: 5.5042
  train/loss_step: 5.5042
  train/reg_loss: 1.3705
  train/reg_loss_step: 1.3705
  train/cls_loss: 2.3922
  train/cls_loss_step: 2.3922
  train/others_reg_loss: 1.7415
  train/others_reg_loss_step: 1.7415
  val/reg_loss: 1.1268
  val_MR: 0.5701
  val_brier-minFDE6: 7.2118
  val_minADE1: 4.9395
  val_minADE6: 3.0334
  val_minFDE1: 11.1850
  val_minFDE6: 6.5008
  train/loss_epoch: 5.6965
  train/reg_loss_epoch: 1.3599
  train/cls_loss_epoch: 2.1999
  train/others_reg_loss_epoch: 2.1367

Epoch 7:
  train/loss: 5.2984
  train/loss_step: 5.2984
  train/reg_loss: 1.4243
  train/reg_loss_step: 1.4243
  train/cls_loss: 2.4085
  train/cls_loss_step: 2.4085
  train/others_reg_loss: 1.4657
  train/others_reg_loss_step: 1.4657
  val/reg_loss: 1.1041
  val_MR: 0.6709
  val_brier-minFDE6: 8.3966
  val_minADE1: 6.6390
  val_minADE6: 3.1389
  val_minFDE1: 16.6451
  val_minFDE6: 7.6826
  train/loss_epoch: 5.0932
  train/reg_loss_epoch: 1.1800
  train/cls_loss_epoch: 2.2283
  train/others_reg_loss_epoch: 1.6849

Epoch 8:
  train/loss: 4.6658
  train/loss_step: 4.6658
  train/reg_loss: 0.9992
  train/reg_loss_step: 0.9992
  train/cls_loss: 2.2545
  train/cls_loss_step: 2.2545
  train/others_reg_loss: 1.4122
  train/others_reg_loss_step: 1.4122
  val/reg_loss: 0.9777
  val_MR: 0.5974
  val_brier-minFDE6: 7.4015
  val_minADE1: 5.2840
  val_minADE6: 2.9406
  val_minFDE1: 12.4059
  val_minFDE6: 6.6935
  train/loss_epoch: 5.0726
  train/reg_loss_epoch: 1.2209
  train/cls_loss_epoch: 2.2105
  train/others_reg_loss_epoch: 1.6413

Epoch 9:
  train/loss: 4.5011
  train/loss_step: 4.5011
  train/reg_loss: 1.1227
  train/reg_loss_step: 1.1227
  train/cls_loss: 2.1959
  train/cls_loss_step: 2.1959
  train/others_reg_loss: 1.1824
  train/others_reg_loss_step: 1.1824
  val/reg_loss: 0.9600
  val_MR: 0.5767
  val_brier-minFDE6: 6.3723
  val_minADE1: 4.7490
  val_minADE6: 2.5370
  val_minFDE1: 11.1016
  val_minFDE6: 5.6782
  train/loss_epoch: 4.8380
  train/reg_loss_epoch: 1.1340
  train/cls_loss_epoch: 2.2058
  train/others_reg_loss_epoch: 1.4982

Epoch 10:
  train/loss: 4.6819
  train/loss_step: 4.6819
  train/reg_loss: 1.0298
  train/reg_loss_step: 1.0298
  train/cls_loss: 2.1433
  train/cls_loss_step: 2.1433
  train/others_reg_loss: 1.5088
  train/others_reg_loss_step: 1.5088
  val/reg_loss: 0.8478
  val_MR: 0.5018
  val_brier-minFDE6: 5.6925
  val_minADE1: 4.3403
  val_minADE6: 2.1990
  val_minFDE1: 10.3207
  val_minFDE6: 4.9969
  train/loss_epoch: 4.7955
  train/reg_loss_epoch: 1.1243
  train/cls_loss_epoch: 2.2213
  train/others_reg_loss_epoch: 1.4499

Epoch 11:
  train/loss: 4.1826
  train/loss_step: 4.1826
  train/reg_loss: 0.7646
  train/reg_loss_step: 0.7646
  train/cls_loss: 2.1199
  train/cls_loss_step: 2.1199
  train/others_reg_loss: 1.2981
  train/others_reg_loss_step: 1.2981
  val/reg_loss: 0.9513
  val_MR: 0.5938
  val_brier-minFDE6: 6.5248
  val_minADE1: 5.1625
  val_minADE6: 2.5327
  val_minFDE1: 12.2179
  val_minFDE6: 5.8234
  train/loss_epoch: 4.6285
  train/reg_loss_epoch: 1.0422
  train/cls_loss_epoch: 2.1860
  train/others_reg_loss_epoch: 1.4003

Epoch 12:
  train/loss: 4.1865
  train/loss_step: 4.1865
  train/reg_loss: 0.8388
  train/reg_loss_step: 0.8388
  train/cls_loss: 2.0641
  train/cls_loss_step: 2.0641
  train/others_reg_loss: 1.2836
  train/others_reg_loss_step: 1.2836
  val/reg_loss: 0.7766
  val_MR: 0.5869
  val_brier-minFDE6: 5.3736
  val_minADE1: 4.2252
  val_minADE6: 2.1049
  val_minFDE1: 10.5045
  val_minFDE6: 4.6875
  train/loss_epoch: 4.4594
  train/reg_loss_epoch: 0.9354
  train/cls_loss_epoch: 2.1751
  train/others_reg_loss_epoch: 1.3489

Epoch 13:
  train/loss: 5.2620
  train/loss_step: 5.2620
  train/reg_loss: 1.0028
  train/reg_loss_step: 1.0028
  train/cls_loss: 2.3664
  train/cls_loss_step: 2.3664
  train/others_reg_loss: 1.8928
  train/others_reg_loss_step: 1.8928
  val/reg_loss: 1.0072
  val_MR: 0.6635
  val_brier-minFDE6: 6.8399
  val_minADE1: 6.9462
  val_minADE6: 3.4439
  val_minFDE1: 14.4666
  val_minFDE6: 6.1369
  train/loss_epoch: 4.2576
  train/reg_loss_epoch: 0.8242
  train/cls_loss_epoch: 2.1637
  train/others_reg_loss_epoch: 1.2697

Epoch 14:
  train/loss: 4.7826
  train/loss_step: 4.7826
  train/reg_loss: 1.0280
  train/reg_loss_step: 1.0280
  train/cls_loss: 2.4536
  train/cls_loss_step: 2.4536
  train/others_reg_loss: 1.3010
  train/others_reg_loss_step: 1.3010
  val/reg_loss: 0.9701
  val_MR: 0.7047
  val_brier-minFDE6: 8.1030
  val_minADE1: 6.9327
  val_minADE6: 3.8435
  val_minFDE1: 15.1389
  val_minFDE6: 7.3765
  train/loss_epoch: 4.3146
  train/reg_loss_epoch: 0.7864
  train/cls_loss_epoch: 2.1832
  train/others_reg_loss_epoch: 1.3450

Epoch 15:
  train/loss: 3.6811
  train/loss_step: 3.6811
  train/reg_loss: 0.5467
  train/reg_loss_step: 0.5467
  train/cls_loss: 2.1250
  train/cls_loss_step: 2.1250
  train/others_reg_loss: 1.0093
  train/others_reg_loss_step: 1.0093
  val/reg_loss: 0.5283
  val_MR: 0.5040
  val_brier-minFDE6: 4.3988
  val_minADE1: 3.3721
  val_minADE6: 1.6811
  val_minFDE1: 8.2708
  val_minFDE6: 3.7193
  train/loss_epoch: 3.9902
  train/reg_loss_epoch: 0.6452
  train/cls_loss_epoch: 2.1335
  train/others_reg_loss_epoch: 1.2115

Epoch 16:
  train/loss: 3.5757
  train/loss_step: 3.5757
  train/reg_loss: 0.4774
  train/reg_loss_step: 0.4774
  train/cls_loss: 2.0437
  train/cls_loss_step: 2.0437
  train/others_reg_loss: 1.0546
  train/others_reg_loss_step: 1.0546
  val/reg_loss: 0.4984
  val_MR: 0.4950
  val_brier-minFDE6: 3.9827
  val_minADE1: 3.2228
  val_minADE6: 1.5276
  val_minFDE1: 8.0158
  val_minFDE6: 3.3064
  train/loss_epoch: 3.8536
  train/reg_loss_epoch: 0.5854
  train/cls_loss_epoch: 2.1008
  train/others_reg_loss_epoch: 1.1675

Epoch 17:
  train/loss: 3.7232
  train/loss_step: 3.7232
  train/reg_loss: 0.5166
  train/reg_loss_step: 0.5166
  train/cls_loss: 2.0745
  train/cls_loss_step: 2.0745
  train/others_reg_loss: 1.1320
  train/others_reg_loss_step: 1.1320
  val/reg_loss: 0.4716
  val_MR: 0.4429
  val_brier-minFDE6: 3.9335
  val_minADE1: 3.4109
  val_minADE6: 1.5102
  val_minFDE1: 8.4406
  val_minFDE6: 3.2462
  train/loss_epoch: 3.7821
  train/reg_loss_epoch: 0.5489
  train/cls_loss_epoch: 2.1008
  train/others_reg_loss_epoch: 1.1324

Epoch 18:
  train/loss: 3.3955
  train/loss_step: 3.3955
  train/reg_loss: 0.3490
  train/reg_loss_step: 0.3490
  train/cls_loss: 2.0267
  train/cls_loss_step: 2.0267
  train/others_reg_loss: 1.0198
  train/others_reg_loss_step: 1.0198
  val/reg_loss: 0.4374
  val_MR: 0.4279
  val_brier-minFDE6: 3.8372
  val_minADE1: 3.1874
  val_minADE6: 1.4267
  val_minFDE1: 7.9857
  val_minFDE6: 3.1594
  train/loss_epoch: 3.6342
  train/reg_loss_epoch: 0.4846
  train/cls_loss_epoch: 2.0796
  train/others_reg_loss_epoch: 1.0700

Epoch 19:
  train/loss: 3.4892
  train/loss_step: 3.4892
  train/reg_loss: 0.5275
  train/reg_loss_step: 0.5275
  train/cls_loss: 2.0444
  train/cls_loss_step: 2.0444
  train/others_reg_loss: 0.9173
  train/others_reg_loss_step: 0.9173
  val/reg_loss: 0.4252
  val_MR: 0.3944
  val_brier-minFDE6: 3.7219
  val_minADE1: 3.0578
  val_minADE6: 1.3986
  val_minFDE1: 7.7383
  val_minFDE6: 3.0465
  train/loss_epoch: 3.5563
  train/reg_loss_epoch: 0.4579
  train/cls_loss_epoch: 2.0622
  train/others_reg_loss_epoch: 1.0362

Epoch 20:
  train/loss: 3.2650
  train/loss_step: 3.2650
  train/reg_loss: 0.3789
  train/reg_loss_step: 0.3789
  train/cls_loss: 1.9840
  train/cls_loss_step: 1.9840
  train/others_reg_loss: 0.9020
  train/others_reg_loss_step: 0.9020
  val/reg_loss: 0.4205
  val_MR: 0.4028
  val_brier-minFDE6: 3.6184
  val_minADE1: 3.0741
  val_minADE6: 1.3531
  val_minFDE1: 7.7625
  val_minFDE6: 2.9492
  train/loss_epoch: 3.4270
  train/reg_loss_epoch: 0.4363
  train/cls_loss_epoch: 2.0320
  train/others_reg_loss_epoch: 0.9588

FINAL VALIDATION RESULTS:
  train/loss: 3.3548
  train/loss_step: 3.2650
  train/reg_loss: 0.4219
  train/reg_loss_step: 0.3789
  train/cls_loss: 2.0269
  train/cls_loss_step: 1.9840
  train/others_reg_loss: 0.9060
  train/others_reg_loss_step: 0.9020
  val/reg_loss: 0.4205
  val_MR: 0.4028
  val_brier-minFDE6: 3.6184
  val_minADE1: 3.0741
  val_minADE6: 1.3531
  val_minFDE1: 7.7625
  val_minFDE6: 2.9492
  train/loss_epoch: 3.3548
  train/reg_loss_epoch: 0.4219
  train/cls_loss_epoch: 2.0269
  train/others_reg_loss_epoch: 0.9060

================================================================================

Experiment 6
--------------------------------------------------
HYPERPARAMETERS:
  dim: 128
  encoder_depth: 3
  num_heads: 8
  mlp_ratio: 2
  attention_type: linear
  decoder_embed_dim: 64
  decoder_num_modes: 3
  decoder_hidden_dim: 256
  model_params: 1,155,505

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4574
  val_MR: 0.9609
  val_brier-minFDE6: 40.4720
  val_minADE1: 20.4468
  val_minADE6: 20.4376
  val_minFDE1: 40.0504
  val_minFDE6: 40.0472

Epoch 1:
  train/loss: 9.3185
  train/loss_step: 9.3185
  train/reg_loss: 4.4498
  train/reg_loss_step: 4.4498
  train/cls_loss: 0.7377
  train/cls_loss_step: 0.7377
  train/others_reg_loss: 4.1310
  train/others_reg_loss_step: 4.1310
  val/reg_loss: 4.1855
  val_MR: 0.9391
  val_brier-minFDE6: 15.9061
  val_minADE1: 8.5789
  val_minADE6: 8.2750
  val_minFDE1: 16.2982
  val_minFDE6: 15.6206

Epoch 2:
  train/loss: 7.3498
  train/loss_step: 7.3498
  train/reg_loss: 2.5477
  train/reg_loss_step: 2.5477
  train/cls_loss: 0.9052
  train/cls_loss_step: 0.9052
  train/others_reg_loss: 3.8969
  train/others_reg_loss_step: 3.8969
  val/reg_loss: 2.1510
  val_MR: 0.8061
  val_brier-minFDE6: 10.3195
  val_minADE1: 5.0522
  val_minADE6: 4.3483
  val_minFDE1: 11.4714
  val_minFDE6: 9.9985
  train/loss_epoch: 12.2878
  train/reg_loss_epoch: 7.6653
  train/cls_loss_epoch: 0.7344
  train/others_reg_loss_epoch: 3.8880

Epoch 3:
  train/loss: 5.0429
  train/loss_step: 5.0429
  train/reg_loss: 1.5316
  train/reg_loss_step: 1.5316
  train/cls_loss: 0.9416
  train/cls_loss_step: 0.9416
  train/others_reg_loss: 2.5697
  train/others_reg_loss_step: 2.5697
  val/reg_loss: 1.8224
  val_MR: 0.7658
  val_brier-minFDE6: 9.0435
  val_minADE1: 4.3561
  val_minADE6: 3.7724
  val_minFDE1: 10.3361
  val_minFDE6: 8.6890
  train/loss_epoch: 7.7815
  train/reg_loss_epoch: 3.1947
  train/cls_loss_epoch: 0.8326
  train/others_reg_loss_epoch: 3.7541

Epoch 4:
  train/loss: 7.1508
  train/loss_step: 7.1508
  train/reg_loss: 2.2840
  train/reg_loss_step: 2.2840
  train/cls_loss: 1.1421
  train/cls_loss_step: 1.1421
  train/others_reg_loss: 3.7247
  train/others_reg_loss_step: 3.7247
  val/reg_loss: 2.3345
  val_MR: 0.7887
  val_brier-minFDE6: 10.3420
  val_minADE1: 9.1325
  val_minADE6: 4.6699
  val_minFDE1: 18.1898
  val_minFDE6: 9.8848
  train/loss_epoch: 6.5985
  train/reg_loss_epoch: 2.3777
  train/cls_loss_epoch: 0.9228
  train/others_reg_loss_epoch: 3.2980

Epoch 5:
  train/loss: 4.9595
  train/loss_step: 4.9595
  train/reg_loss: 1.7909
  train/reg_loss_step: 1.7909
  train/cls_loss: 1.1435
  train/cls_loss_step: 1.1435
  train/others_reg_loss: 2.0251
  train/others_reg_loss_step: 2.0251
  val/reg_loss: 1.4155
  val_MR: 0.7532
  val_brier-minFDE6: 6.9948
  val_minADE1: 4.7789
  val_minADE6: 3.0091
  val_minFDE1: 11.3461
  val_minFDE6: 6.5615
  train/loss_epoch: 5.7597
  train/reg_loss_epoch: 2.1063
  train/cls_loss_epoch: 1.0117
  train/others_reg_loss_epoch: 2.6417

Epoch 6:
  train/loss: 3.7878
  train/loss_step: 3.7878
  train/reg_loss: 1.5889
  train/reg_loss_step: 1.5889
  train/cls_loss: 1.0795
  train/cls_loss_step: 1.0795
  train/others_reg_loss: 1.1195
  train/others_reg_loss_step: 1.1195
  val/reg_loss: 1.3882
  val_MR: 0.7716
  val_brier-minFDE6: 7.1216
  val_minADE1: 4.7110
  val_minADE6: 2.9391
  val_minFDE1: 11.1756
  val_minFDE6: 6.6605
  train/loss_epoch: 5.0351
  train/reg_loss_epoch: 1.7624
  train/cls_loss_epoch: 1.0949
  train/others_reg_loss_epoch: 2.1778

Epoch 7:
  train/loss: 4.4115
  train/loss_step: 4.4115
  train/reg_loss: 1.6424
  train/reg_loss_step: 1.6424
  train/cls_loss: 1.1100
  train/cls_loss_step: 1.1100
  train/others_reg_loss: 1.6591
  train/others_reg_loss_step: 1.6591
  val/reg_loss: 1.6034
  val_MR: 0.7833
  val_brier-minFDE6: 7.9138
  val_minADE1: 5.3707
  val_minADE6: 3.3695
  val_minFDE1: 12.5282
  val_minFDE6: 7.4746
  train/loss_epoch: 4.5568
  train/reg_loss_epoch: 1.6344
  train/cls_loss_epoch: 1.1161
  train/others_reg_loss_epoch: 1.8063

Epoch 8:
  train/loss: 4.3777
  train/loss_step: 4.3777
  train/reg_loss: 1.8014
  train/reg_loss_step: 1.8014
  train/cls_loss: 1.0894
  train/cls_loss_step: 1.0894
  train/others_reg_loss: 1.4869
  train/others_reg_loss_step: 1.4869
  val/reg_loss: 1.3323
  val_MR: 0.7788
  val_brier-minFDE6: 6.8106
  val_minADE1: 4.1477
  val_minADE6: 2.8286
  val_minFDE1: 9.8720
  val_minFDE6: 6.3739
  train/loss_epoch: 4.3576
  train/reg_loss_epoch: 1.5622
  train/cls_loss_epoch: 1.1159
  train/others_reg_loss_epoch: 1.6795

Epoch 9:
  train/loss: 3.9179
  train/loss_step: 3.9179
  train/reg_loss: 1.3962
  train/reg_loss_step: 1.3962
  train/cls_loss: 1.1373
  train/cls_loss_step: 1.1373
  train/others_reg_loss: 1.3844
  train/others_reg_loss_step: 1.3844
  val/reg_loss: 1.3144
  val_MR: 0.7518
  val_brier-minFDE6: 6.8223
  val_minADE1: 4.3788
  val_minADE6: 2.8131
  val_minFDE1: 11.0419
  val_minFDE6: 6.3721
  train/loss_epoch: 4.2260
  train/reg_loss_epoch: 1.5343
  train/cls_loss_epoch: 1.1157
  train/others_reg_loss_epoch: 1.5759

Epoch 10:
  train/loss: 3.7789
  train/loss_step: 3.7789
  train/reg_loss: 1.4167
  train/reg_loss_step: 1.4167
  train/cls_loss: 1.0838
  train/cls_loss_step: 1.0838
  train/others_reg_loss: 1.2785
  train/others_reg_loss_step: 1.2785
  val/reg_loss: 1.3179
  val_MR: 0.7764
  val_brier-minFDE6: 7.0181
  val_minADE1: 4.1455
  val_minADE6: 2.8170
  val_minFDE1: 10.1490
  val_minFDE6: 6.5771
  train/loss_epoch: 4.1306
  train/reg_loss_epoch: 1.5101
  train/cls_loss_epoch: 1.1073
  train/others_reg_loss_epoch: 1.5132

Epoch 11:
  train/loss: 5.5982
  train/loss_step: 5.5982
  train/reg_loss: 2.7193
  train/reg_loss_step: 2.7193
  train/cls_loss: 1.1875
  train/cls_loss_step: 1.1875
  train/others_reg_loss: 1.6913
  train/others_reg_loss_step: 1.6913
  val/reg_loss: 2.5372
  val_MR: 0.8137
  val_brier-minFDE6: 10.4679
  val_minADE1: 8.5964
  val_minADE6: 5.1180
  val_minFDE1: 17.5465
  val_minFDE6: 10.0205
  train/loss_epoch: 4.1074
  train/reg_loss_epoch: 1.5413
  train/cls_loss_epoch: 1.0983
  train/others_reg_loss_epoch: 1.4677

Epoch 12:
  train/loss: 3.6923
  train/loss_step: 3.6923
  train/reg_loss: 1.1253
  train/reg_loss_step: 1.1253
  train/cls_loss: 1.0657
  train/cls_loss_step: 1.0657
  train/others_reg_loss: 1.5013
  train/others_reg_loss_step: 1.5013
  val/reg_loss: 1.1823
  val_MR: 0.7284
  val_brier-minFDE6: 6.5100
  val_minADE1: 3.9446
  val_minADE6: 2.5670
  val_minFDE1: 9.8867
  val_minFDE6: 6.0827
  train/loss_epoch: 3.8219
  train/reg_loss_epoch: 1.3951
  train/cls_loss_epoch: 1.0905
  train/others_reg_loss_epoch: 1.3363

Epoch 13:
  train/loss: 3.4099
  train/loss_step: 3.4099
  train/reg_loss: 1.0550
  train/reg_loss_step: 1.0550
  train/cls_loss: 1.0631
  train/cls_loss_step: 1.0631
  train/others_reg_loss: 1.2918
  train/others_reg_loss_step: 1.2918
  val/reg_loss: 1.1810
  val_MR: 0.7420
  val_brier-minFDE6: 6.2541
  val_minADE1: 3.7707
  val_minADE6: 2.5262
  val_minFDE1: 9.2298
  val_minFDE6: 5.8284
  train/loss_epoch: 3.8507
  train/reg_loss_epoch: 1.4324
  train/cls_loss_epoch: 1.0885
  train/others_reg_loss_epoch: 1.3298

Epoch 14:
  train/loss: 3.0588
  train/loss_step: 3.0588
  train/reg_loss: 0.8031
  train/reg_loss_step: 0.8031
  train/cls_loss: 1.0914
  train/cls_loss_step: 1.0914
  train/others_reg_loss: 1.1643
  train/others_reg_loss_step: 1.1643
  val/reg_loss: 1.0615
  val_MR: 0.7163
  val_brier-minFDE6: 5.7981
  val_minADE1: 3.7703
  val_minADE6: 2.3272
  val_minFDE1: 9.0594
  val_minFDE6: 5.3692
  train/loss_epoch: 3.5024
  train/reg_loss_epoch: 1.2143
  train/cls_loss_epoch: 1.0774
  train/others_reg_loss_epoch: 1.2108

Epoch 15:
  train/loss: 3.1938
  train/loss_step: 3.1938
  train/reg_loss: 1.0974
  train/reg_loss_step: 1.0974
  train/cls_loss: 1.0830
  train/cls_loss_step: 1.0830
  train/others_reg_loss: 1.0133
  train/others_reg_loss_step: 1.0133
  val/reg_loss: 0.8339
  val_MR: 0.6462
  val_brier-minFDE6: 4.8412
  val_minADE1: 3.2004
  val_minADE6: 1.8910
  val_minFDE1: 7.9460
  val_minFDE6: 4.4222
  train/loss_epoch: 3.2067
  train/reg_loss_epoch: 1.0886
  train/cls_loss_epoch: 1.0728
  train/others_reg_loss_epoch: 1.0453

Epoch 16:
  train/loss: 2.7018
  train/loss_step: 2.7018
  train/reg_loss: 0.9402
  train/reg_loss_step: 0.9402
  train/cls_loss: 1.0516
  train/cls_loss_step: 1.0516
  train/others_reg_loss: 0.7101
  train/others_reg_loss_step: 0.7101
  val/reg_loss: 0.7939
  val_MR: 0.6422
  val_brier-minFDE6: 4.6490
  val_minADE1: 3.1126
  val_minADE6: 1.8133
  val_minFDE1: 7.7252
  val_minFDE6: 4.2379
  train/loss_epoch: 2.9311
  train/reg_loss_epoch: 0.9726
  train/cls_loss_epoch: 1.0697
  train/others_reg_loss_epoch: 0.8888

Epoch 17:
  train/loss: 2.8706
  train/loss_step: 2.8706
  train/reg_loss: 1.1917
  train/reg_loss_step: 1.1917
  train/cls_loss: 1.0521
  train/cls_loss_step: 1.0521
  train/others_reg_loss: 0.6268
  train/others_reg_loss_step: 0.6268
  val/reg_loss: 0.7483
  val_MR: 0.6300
  val_brier-minFDE6: 4.4492
  val_minADE1: 3.0776
  val_minADE6: 1.7404
  val_minFDE1: 7.5894
  val_minFDE6: 4.0468
  train/loss_epoch: 2.6978
  train/reg_loss_epoch: 0.8617
  train/cls_loss_epoch: 1.0506
  train/others_reg_loss_epoch: 0.7856

Epoch 18:
  train/loss: 2.3772
  train/loss_step: 2.3772
  train/reg_loss: 0.6859
  train/reg_loss_step: 0.6859
  train/cls_loss: 1.0000
  train/cls_loss_step: 1.0000
  train/others_reg_loss: 0.6914
  train/others_reg_loss_step: 0.6914
  val/reg_loss: 0.7087
  val_MR: 0.6160
  val_brier-minFDE6: 4.2839
  val_minADE1: 2.8826
  val_minADE6: 1.6660
  val_minFDE1: 7.2521
  val_minFDE6: 3.8794
  train/loss_epoch: 2.5881
  train/reg_loss_epoch: 0.8026
  train/cls_loss_epoch: 1.0390
  train/others_reg_loss_epoch: 0.7464

Epoch 19:
  train/loss: 2.4493
  train/loss_step: 2.4493
  train/reg_loss: 0.8213
  train/reg_loss_step: 0.8213
  train/cls_loss: 0.9935
  train/cls_loss_step: 0.9935
  train/others_reg_loss: 0.6346
  train/others_reg_loss_step: 0.6346
  val/reg_loss: 0.6858
  val_MR: 0.6168
  val_brier-minFDE6: 4.2057
  val_minADE1: 2.7903
  val_minADE6: 1.6224
  val_minFDE1: 7.0332
  val_minFDE6: 3.8031
  train/loss_epoch: 2.5012
  train/reg_loss_epoch: 0.7528
  train/cls_loss_epoch: 1.0320
  train/others_reg_loss_epoch: 0.7164

Epoch 20:
  train/loss: 2.4740
  train/loss_step: 2.4740
  train/reg_loss: 0.6424
  train/reg_loss_step: 0.6424
  train/cls_loss: 1.0994
  train/cls_loss_step: 1.0994
  train/others_reg_loss: 0.7322
  train/others_reg_loss_step: 0.7322
  val/reg_loss: 0.6634
  val_MR: 0.6066
  val_brier-minFDE6: 4.0939
  val_minADE1: 2.7598
  val_minADE6: 1.5767
  val_minFDE1: 6.9740
  val_minFDE6: 3.6922
  train/loss_epoch: 2.4326
  train/reg_loss_epoch: 0.7126
  train/cls_loss_epoch: 1.0294
  train/others_reg_loss_epoch: 0.6906

FINAL VALIDATION RESULTS:
  train/loss: 2.3724
  train/loss_step: 2.4740
  train/reg_loss: 0.6744
  train/reg_loss_step: 0.6424
  train/cls_loss: 1.0173
  train/cls_loss_step: 1.0994
  train/others_reg_loss: 0.6807
  train/others_reg_loss_step: 0.7322
  val/reg_loss: 0.6634
  val_MR: 0.6066
  val_brier-minFDE6: 4.0939
  val_minADE1: 2.7598
  val_minADE6: 1.5767
  val_minFDE1: 6.9740
  val_minFDE6: 3.6922
  train/loss_epoch: 2.3724
  train/reg_loss_epoch: 0.6744
  train/cls_loss_epoch: 1.0173
  train/others_reg_loss_epoch: 0.6807

================================================================================

Experiment 7
--------------------------------------------------
HYPERPARAMETERS:
  dim: 32
  encoder_depth: 1
  num_heads: 8
  mlp_ratio: 6
  attention_type: performer
  decoder_embed_dim: 32
  decoder_num_modes: 3
  decoder_hidden_dim: 96
  model_params: 261,201

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4237
  val_MR: 0.9531
  val_brier-minFDE6: 40.1196
  val_minADE1: 20.3965
  val_minADE6: 20.3951
  val_minFDE1: 39.6849
  val_minFDE6: 39.6770

Epoch 1:
  train/loss: 11.5453
  train/loss_step: 11.5453
  train/reg_loss: 7.0102
  train/reg_loss_step: 7.0102
  train/cls_loss: 0.8375
  train/cls_loss_step: 0.8375
  train/others_reg_loss: 3.6976
  train/others_reg_loss_step: 3.6976
  val/reg_loss: 7.4880
  val_MR: 0.9375
  val_brier-minFDE6: 30.1536
  val_minADE1: 14.9868
  val_minADE6: 14.7357
  val_minFDE1: 30.1955
  val_minFDE6: 29.9609

Epoch 2:
  train/loss: 8.4705
  train/loss_step: 8.4705
  train/reg_loss: 2.9381
  train/reg_loss_step: 2.9381
  train/cls_loss: 1.0235
  train/cls_loss_step: 1.0235
  train/others_reg_loss: 4.5089
  train/others_reg_loss_step: 4.5089
  val/reg_loss: 2.2959
  val_MR: 0.8385
  val_brier-minFDE6: 9.7646
  val_minADE1: 7.6300
  val_minADE6: 4.6494
  val_minFDE1: 15.3131
  val_minFDE6: 9.3515
  train/loss_epoch: 13.7185
  train/reg_loss_epoch: 9.1316
  train/cls_loss_epoch: 0.6839
  train/others_reg_loss_epoch: 3.9030

Epoch 3:
  train/loss: 8.0657
  train/loss_step: 8.0657
  train/reg_loss: 2.2779
  train/reg_loss_step: 2.2779
  train/cls_loss: 1.0585
  train/cls_loss_step: 1.0585
  train/others_reg_loss: 4.7293
  train/others_reg_loss_step: 4.7293
  val/reg_loss: 1.7459
  val_MR: 0.8407
  val_brier-minFDE6: 8.0866
  val_minADE1: 6.3668
  val_minADE6: 3.5897
  val_minFDE1: 14.1377
  val_minFDE6: 7.6634
  train/loss_epoch: 9.1468
  train/reg_loss_epoch: 4.3531
  train/cls_loss_epoch: 0.9102
  train/others_reg_loss_epoch: 3.8835

Epoch 4:
  train/loss: 6.6452
  train/loss_step: 6.6452
  train/reg_loss: 2.2500
  train/reg_loss_step: 2.2500
  train/cls_loss: 1.3004
  train/cls_loss_step: 1.3004
  train/others_reg_loss: 3.0947
  train/others_reg_loss_step: 3.0947
  val/reg_loss: 2.4549
  val_MR: 0.8496
  val_brier-minFDE6: 10.9563
  val_minADE1: 8.9561
  val_minADE6: 4.8714
  val_minFDE1: 18.4686
  val_minFDE6: 10.4234
  train/loss_epoch: 6.8984
  train/reg_loss_epoch: 1.9562
  train/cls_loss_epoch: 1.0802
  train/others_reg_loss_epoch: 3.8621

Epoch 5:
  train/loss: 4.6943
  train/loss_step: 4.6943
  train/reg_loss: 1.2210
  train/reg_loss_step: 1.2210
  train/cls_loss: 1.0572
  train/cls_loss_step: 1.0572
  train/others_reg_loss: 2.4161
  train/others_reg_loss_step: 2.4161
  val/reg_loss: 1.5090
  val_MR: 0.7973
  val_brier-minFDE6: 7.2458
  val_minADE1: 5.3921
  val_minADE6: 3.1548
  val_minFDE1: 11.9693
  val_minFDE6: 6.8045
  train/loss_epoch: 6.3331
  train/reg_loss_epoch: 1.7425
  train/cls_loss_epoch: 1.0782
  train/others_reg_loss_epoch: 3.5123

Epoch 6:
  train/loss: 3.7688
  train/loss_step: 3.7688
  train/reg_loss: 1.0948
  train/reg_loss_step: 1.0948
  train/cls_loss: 0.9808
  train/cls_loss_step: 0.9808
  train/others_reg_loss: 1.6932
  train/others_reg_loss_step: 1.6932
  val/reg_loss: 1.3958
  val_MR: 0.7508
  val_brier-minFDE6: 6.9840
  val_minADE1: 4.7148
  val_minADE6: 2.9450
  val_minFDE1: 10.8471
  val_minFDE6: 6.5715
  train/loss_epoch: 5.3179
  train/reg_loss_epoch: 1.5748
  train/cls_loss_epoch: 1.0610
  train/others_reg_loss_epoch: 2.6821

Epoch 7:
  train/loss: 3.8466
  train/loss_step: 3.8466
  train/reg_loss: 0.9742
  train/reg_loss_step: 0.9742
  train/cls_loss: 0.9876
  train/cls_loss_step: 0.9876
  train/others_reg_loss: 1.8848
  train/others_reg_loss_step: 1.8848
  val/reg_loss: 1.3255
  val_MR: 0.7368
  val_brier-minFDE6: 6.8236
  val_minADE1: 4.5591
  val_minADE6: 2.8177
  val_minFDE1: 10.8060
  val_minFDE6: 6.4148
  train/loss_epoch: 4.8845
  train/reg_loss_epoch: 1.4570
  train/cls_loss_epoch: 1.0718
  train/others_reg_loss_epoch: 2.3557

Epoch 8:
  train/loss: 5.1606
  train/loss_step: 5.1606
  train/reg_loss: 1.5814
  train/reg_loss_step: 1.5814
  train/cls_loss: 1.2416
  train/cls_loss_step: 1.2416
  train/others_reg_loss: 2.3376
  train/others_reg_loss_step: 2.3376
  val/reg_loss: 1.7621
  val_MR: 0.7616
  val_brier-minFDE6: 7.7850
  val_minADE1: 6.3582
  val_minADE6: 3.6291
  val_minFDE1: 13.2430
  val_minFDE6: 7.3144
  train/loss_epoch: 4.6012
  train/reg_loss_epoch: 1.3685
  train/cls_loss_epoch: 1.0638
  train/others_reg_loss_epoch: 2.1689

Epoch 9:
  train/loss: 3.6068
  train/loss_step: 3.6068
  train/reg_loss: 1.0555
  train/reg_loss_step: 1.0555
  train/cls_loss: 1.0788
  train/cls_loss_step: 1.0788
  train/others_reg_loss: 1.4726
  train/others_reg_loss_step: 1.4726
  val/reg_loss: 1.2660
  val_MR: 0.7374
  val_brier-minFDE6: 6.6855
  val_minADE1: 4.3297
  val_minADE6: 2.7201
  val_minFDE1: 10.3383
  val_minFDE6: 6.2606
  train/loss_epoch: 4.3879
  train/reg_loss_epoch: 1.3469
  train/cls_loss_epoch: 1.0735
  train/others_reg_loss_epoch: 1.9674

Epoch 10:
  train/loss: 4.4648
  train/loss_step: 4.4648
  train/reg_loss: 1.2953
  train/reg_loss_step: 1.2953
  train/cls_loss: 1.1672
  train/cls_loss_step: 1.1672
  train/others_reg_loss: 2.0023
  train/others_reg_loss_step: 2.0023
  val/reg_loss: 1.4261
  val_MR: 0.7845
  val_brier-minFDE6: 7.2653
  val_minADE1: 4.9763
  val_minADE6: 3.0193
  val_minFDE1: 11.5434
  val_minFDE6: 6.8258
  train/loss_epoch: 4.0495
  train/reg_loss_epoch: 1.2866
  train/cls_loss_epoch: 1.0757
  train/others_reg_loss_epoch: 1.6872

Epoch 11:
  train/loss: 3.8810
  train/loss_step: 3.8810
  train/reg_loss: 1.2925
  train/reg_loss_step: 1.2925
  train/cls_loss: 1.1617
  train/cls_loss_step: 1.1617
  train/others_reg_loss: 1.4268
  train/others_reg_loss_step: 1.4268
  val/reg_loss: 1.2333
  val_MR: 0.7230
  val_brier-minFDE6: 6.6151
  val_minADE1: 4.1208
  val_minADE6: 2.6749
  val_minFDE1: 10.1246
  val_minFDE6: 6.1862
  train/loss_epoch: 4.0189
  train/reg_loss_epoch: 1.3584
  train/cls_loss_epoch: 1.0899
  train/others_reg_loss_epoch: 1.5706

Epoch 12:
  train/loss: 3.8816
  train/loss_step: 3.8816
  train/reg_loss: 1.2869
  train/reg_loss_step: 1.2869
  train/cls_loss: 1.0179
  train/cls_loss_step: 1.0179
  train/others_reg_loss: 1.5768
  train/others_reg_loss_step: 1.5768
  val/reg_loss: 1.2175
  val_MR: 0.7258
  val_brier-minFDE6: 6.5694
  val_minADE1: 4.1720
  val_minADE6: 2.6229
  val_minFDE1: 10.1719
  val_minFDE6: 6.1533
  train/loss_epoch: 3.8395
  train/reg_loss_epoch: 1.2823
  train/cls_loss_epoch: 1.0768
  train/others_reg_loss_epoch: 1.4804

Epoch 13:
  train/loss: 3.4650
  train/loss_step: 3.4650
  train/reg_loss: 1.2359
  train/reg_loss_step: 1.2359
  train/cls_loss: 1.1040
  train/cls_loss_step: 1.1040
  train/others_reg_loss: 1.1251
  train/others_reg_loss_step: 1.1251
  val/reg_loss: 1.2018
  val_MR: 0.7051
  val_brier-minFDE6: 6.5322
  val_minADE1: 4.7697
  val_minADE6: 2.5954
  val_minFDE1: 11.6517
  val_minFDE6: 6.0961
  train/loss_epoch: 3.8447
  train/reg_loss_epoch: 1.3057
  train/cls_loss_epoch: 1.0821
  train/others_reg_loss_epoch: 1.4570

Epoch 14:
  train/loss: 3.1372
  train/loss_step: 3.1372
  train/reg_loss: 1.0864
  train/reg_loss_step: 1.0864
  train/cls_loss: 1.0836
  train/cls_loss_step: 1.0836
  train/others_reg_loss: 0.9672
  train/others_reg_loss_step: 0.9672
  val/reg_loss: 1.1909
  val_MR: 0.7230
  val_brier-minFDE6: 6.4914
  val_minADE1: 3.9676
  val_minADE6: 2.5672
  val_minFDE1: 9.7288
  val_minFDE6: 6.0862
  train/loss_epoch: 3.7564
  train/reg_loss_epoch: 1.2866
  train/cls_loss_epoch: 1.0895
  train/others_reg_loss_epoch: 1.3802

Epoch 15:
  train/loss: 2.9638
  train/loss_step: 2.9638
  train/reg_loss: 0.7121
  train/reg_loss_step: 0.7121
  train/cls_loss: 1.0345
  train/cls_loss_step: 1.0345
  train/others_reg_loss: 1.2171
  train/others_reg_loss_step: 1.2171
  val/reg_loss: 1.1891
  val_MR: 0.7181
  val_brier-minFDE6: 6.4821
  val_minADE1: 3.9126
  val_minADE6: 2.5733
  val_minFDE1: 9.7519
  val_minFDE6: 6.0672
  train/loss_epoch: 3.5546
  train/reg_loss_epoch: 1.2328
  train/cls_loss_epoch: 1.0535
  train/others_reg_loss_epoch: 1.2683

Epoch 16:
  train/loss: 3.2951
  train/loss_step: 3.2951
  train/reg_loss: 1.1570
  train/reg_loss_step: 1.1570
  train/cls_loss: 0.9964
  train/cls_loss_step: 0.9964
  train/others_reg_loss: 1.1418
  train/others_reg_loss_step: 1.1418
  val/reg_loss: 1.1720
  val_MR: 0.7111
  val_brier-minFDE6: 6.3707
  val_minADE1: 3.7790
  val_minADE6: 2.5427
  val_minFDE1: 9.3785
  val_minFDE6: 5.9758
  train/loss_epoch: 3.4748
  train/reg_loss_epoch: 1.2034
  train/cls_loss_epoch: 1.0524
  train/others_reg_loss_epoch: 1.2190

Epoch 17:
  train/loss: 3.5859
  train/loss_step: 3.5859
  train/reg_loss: 1.3366
  train/reg_loss_step: 1.3366
  train/cls_loss: 0.9548
  train/cls_loss_step: 0.9548
  train/others_reg_loss: 1.2945
  train/others_reg_loss_step: 1.2945
  val/reg_loss: 1.1618
  val_MR: 0.7015
  val_brier-minFDE6: 6.3653
  val_minADE1: 3.7122
  val_minADE6: 2.5154
  val_minFDE1: 9.2584
  val_minFDE6: 5.9668
  train/loss_epoch: 3.4040
  train/reg_loss_epoch: 1.1914
  train/cls_loss_epoch: 1.0456
  train/others_reg_loss_epoch: 1.1670

Epoch 18:
  train/loss: 3.6347
  train/loss_step: 3.6347
  train/reg_loss: 1.3956
  train/reg_loss_step: 1.3956
  train/cls_loss: 1.0707
  train/cls_loss_step: 1.0707
  train/others_reg_loss: 1.1684
  train/others_reg_loss_step: 1.1684
  val/reg_loss: 1.1489
  val_MR: 0.6975
  val_brier-minFDE6: 6.3246
  val_minADE1: 3.6800
  val_minADE6: 2.4923
  val_minFDE1: 9.1072
  val_minFDE6: 5.9339
  train/loss_epoch: 3.3104
  train/reg_loss_epoch: 1.1692
  train/cls_loss_epoch: 1.0286
  train/others_reg_loss_epoch: 1.1126

Epoch 19:
  train/loss: 2.8039
  train/loss_step: 2.8039
  train/reg_loss: 0.8780
  train/reg_loss_step: 0.8780
  train/cls_loss: 0.9744
  train/cls_loss_step: 0.9744
  train/others_reg_loss: 0.9515
  train/others_reg_loss_step: 0.9515
  val/reg_loss: 1.1428
  val_MR: 0.6965
  val_brier-minFDE6: 6.2911
  val_minADE1: 3.6947
  val_minADE6: 2.4787
  val_minFDE1: 9.1654
  val_minFDE6: 5.8994
  train/loss_epoch: 3.2044
  train/reg_loss_epoch: 1.1339
  train/cls_loss_epoch: 1.0200
  train/others_reg_loss_epoch: 1.0506

Epoch 20:
  train/loss: 3.1305
  train/loss_step: 3.1305
  train/reg_loss: 1.1154
  train/reg_loss_step: 1.1154
  train/cls_loss: 1.0566
  train/cls_loss_step: 1.0566
  train/others_reg_loss: 0.9585
  train/others_reg_loss_step: 0.9585
  val/reg_loss: 1.1415
  val_MR: 0.6961
  val_brier-minFDE6: 6.2845
  val_minADE1: 3.6416
  val_minADE6: 2.4739
  val_minFDE1: 9.0932
  val_minFDE6: 5.8957
  train/loss_epoch: 3.1762
  train/reg_loss_epoch: 1.1454
  train/cls_loss_epoch: 1.0085
  train/others_reg_loss_epoch: 1.0224

FINAL VALIDATION RESULTS:
  train/loss: 3.1241
  train/loss_step: 3.1305
  train/reg_loss: 1.1273
  train/reg_loss_step: 1.1154
  train/cls_loss: 0.9988
  train/cls_loss_step: 1.0566
  train/others_reg_loss: 0.9980
  train/others_reg_loss_step: 0.9585
  val/reg_loss: 1.1415
  val_MR: 0.6961
  val_brier-minFDE6: 6.2845
  val_minADE1: 3.6416
  val_minADE6: 2.4739
  val_minFDE1: 9.0932
  val_minFDE6: 5.8957
  train/loss_epoch: 3.1241
  train/reg_loss_epoch: 1.1273
  train/cls_loss_epoch: 0.9988
  train/others_reg_loss_epoch: 0.9980

================================================================================

Experiment 8
--------------------------------------------------
HYPERPARAMETERS:
  dim: 96
  encoder_depth: 5
  num_heads: 6
  mlp_ratio: 2
  attention_type: standard
  decoder_embed_dim: 48
  decoder_num_modes: 6
  decoder_hidden_dim: 256
  model_params: 1,061,649

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4288
  val_MR: 0.9531
  val_brier-minFDE6: 40.4851
  val_minADE1: 20.4066
  val_minADE6: 20.4033
  val_minFDE1: 39.8271
  val_minFDE6: 39.7921

Epoch 1:
  train/loss: 7.9269
  train/loss_step: 7.9269
  train/reg_loss: 4.3287
  train/reg_loss_step: 4.3287
  train/cls_loss: 0.8357
  train/cls_loss_step: 0.8357
  train/others_reg_loss: 2.7625
  train/others_reg_loss_step: 2.7625
  val/reg_loss: 4.6613
  val_MR: 0.9295
  val_brier-minFDE6: 17.5863
  val_minADE1: 9.2687
  val_minADE6: 9.1444
  val_minFDE1: 17.4882
  val_minFDE6: 17.2428

Epoch 2:
  train/loss: 7.5486
  train/loss_step: 7.5486
  train/reg_loss: 2.9719
  train/reg_loss_step: 2.9719
  train/cls_loss: 0.7523
  train/cls_loss_step: 0.7523
  train/others_reg_loss: 3.8245
  train/others_reg_loss_step: 3.8245
  val/reg_loss: 3.1242
  val_MR: 0.9131
  val_brier-minFDE6: 13.8433
  val_minADE1: 6.7345
  val_minADE6: 6.2438
  val_minFDE1: 14.4356
  val_minFDE6: 13.5319
  train/loss_epoch: 13.0275
  train/reg_loss_epoch: 8.1094
  train/cls_loss_epoch: 1.0431
  train/others_reg_loss_epoch: 3.8751

Epoch 3:
  train/loss: 5.7856
  train/loss_step: 5.7856
  train/reg_loss: 1.8010
  train/reg_loss_step: 1.8010
  train/cls_loss: 1.1412
  train/cls_loss_step: 1.1412
  train/others_reg_loss: 2.8435
  train/others_reg_loss_step: 2.8435
  val/reg_loss: 1.6087
  val_MR: 0.6937
  val_brier-minFDE6: 8.2825
  val_minADE1: 4.8799
  val_minADE6: 3.3522
  val_minFDE1: 10.5463
  val_minFDE6: 7.8490
  train/loss_epoch: 8.1252
  train/reg_loss_epoch: 3.3912
  train/cls_loss_epoch: 0.9175
  train/others_reg_loss_epoch: 3.8165

Epoch 4:
  train/loss: 5.2033
  train/loss_step: 5.2033
  train/reg_loss: 1.4621
  train/reg_loss_step: 1.4621
  train/cls_loss: 1.5800
  train/cls_loss_step: 1.5800
  train/others_reg_loss: 2.1612
  train/others_reg_loss_step: 2.1612
  val/reg_loss: 1.2850
  val_MR: 0.6282
  val_brier-minFDE6: 6.8005
  val_minADE1: 5.0806
  val_minADE6: 2.7731
  val_minFDE1: 10.9288
  val_minFDE6: 6.2107
  train/loss_epoch: 6.7108
  train/reg_loss_epoch: 2.2500
  train/cls_loss_epoch: 1.1279
  train/others_reg_loss_epoch: 3.3328

Epoch 5:
  train/loss: 5.2463
  train/loss_step: 5.2463
  train/reg_loss: 1.3115
  train/reg_loss_step: 1.3115
  train/cls_loss: 1.7956
  train/cls_loss_step: 1.7956
  train/others_reg_loss: 2.1393
  train/others_reg_loss_step: 2.1393
  val/reg_loss: 1.7127
  val_MR: 0.5956
  val_brier-minFDE6: 6.5304
  val_minADE1: 7.9908
  val_minADE6: 3.6145
  val_minFDE1: 15.1549
  val_minFDE6: 5.8349
  train/loss_epoch: 5.5094
  train/reg_loss_epoch: 1.6499
  train/cls_loss_epoch: 1.3923
  train/others_reg_loss_epoch: 2.4672

Epoch 6:
  train/loss: 4.1873
  train/loss_step: 4.1873
  train/reg_loss: 1.1643
  train/reg_loss_step: 1.1643
  train/cls_loss: 1.8273
  train/cls_loss_step: 1.8273
  train/others_reg_loss: 1.1957
  train/others_reg_loss_step: 1.1957
  val/reg_loss: 1.1499
  val_MR: 0.6204
  val_brier-minFDE6: 6.4982
  val_minADE1: 4.6449
  val_minADE6: 2.5195
  val_minFDE1: 11.3665
  val_minFDE6: 5.8085
  train/loss_epoch: 5.3583
  train/reg_loss_epoch: 1.5070
  train/cls_loss_epoch: 1.6943
  train/others_reg_loss_epoch: 2.1570

Epoch 7:
  train/loss: 5.2053
  train/loss_step: 5.2053
  train/reg_loss: 1.7012
  train/reg_loss_step: 1.7012
  train/cls_loss: 2.0464
  train/cls_loss_step: 2.0464
  train/others_reg_loss: 1.4578
  train/others_reg_loss_step: 1.4578
  val/reg_loss: 1.3625
  val_MR: 0.7590
  val_brier-minFDE6: 7.4130
  val_minADE1: 8.3383
  val_minADE6: 2.9150
  val_minFDE1: 18.9223
  val_minFDE6: 6.6698
  train/loss_epoch: 4.7137
  train/reg_loss_epoch: 1.2588
  train/cls_loss_epoch: 1.8084
  train/others_reg_loss_epoch: 1.6465

Epoch 8:
  train/loss: 4.2474
  train/loss_step: 4.2474
  train/reg_loss: 0.9611
  train/reg_loss_step: 0.9611
  train/cls_loss: 1.7522
  train/cls_loss_step: 1.7522
  train/others_reg_loss: 1.5341
  train/others_reg_loss_step: 1.5341
  val/reg_loss: 1.1397
  val_MR: 0.6370
  val_brier-minFDE6: 6.2332
  val_minADE1: 4.8525
  val_minADE6: 2.5239
  val_minFDE1: 11.0797
  val_minFDE6: 5.5590
  train/loss_epoch: 4.6284
  train/reg_loss_epoch: 1.2617
  train/cls_loss_epoch: 1.8241
  train/others_reg_loss_epoch: 1.5426

Epoch 9:
  train/loss: 3.9555
  train/loss_step: 3.9555
  train/reg_loss: 1.0351
  train/reg_loss_step: 1.0351
  train/cls_loss: 1.6670
  train/cls_loss_step: 1.6670
  train/others_reg_loss: 1.2534
  train/others_reg_loss_step: 1.2534
  val/reg_loss: 1.1284
  val_MR: 0.5968
  val_brier-minFDE6: 5.8447
  val_minADE1: 4.2559
  val_minADE6: 2.5019
  val_minFDE1: 10.2723
  val_minFDE6: 5.1785
  train/loss_epoch: 4.6282
  train/reg_loss_epoch: 1.2848
  train/cls_loss_epoch: 1.8091
  train/others_reg_loss_epoch: 1.5343

Epoch 10:
  train/loss: 3.8232
  train/loss_step: 3.8232
  train/reg_loss: 1.1034
  train/reg_loss_step: 1.1034
  train/cls_loss: 1.6207
  train/cls_loss_step: 1.6207
  train/others_reg_loss: 1.0991
  train/others_reg_loss_step: 1.0991
  val/reg_loss: 1.0622
  val_MR: 0.6248
  val_brier-minFDE6: 6.0080
  val_minADE1: 4.1707
  val_minADE6: 2.3607
  val_minFDE1: 10.2701
  val_minFDE6: 5.3604
  train/loss_epoch: 4.4041
  train/reg_loss_epoch: 1.2004
  train/cls_loss_epoch: 1.7855
  train/others_reg_loss_epoch: 1.4182

Epoch 11:
  train/loss: 5.1933
  train/loss_step: 5.1933
  train/reg_loss: 1.5333
  train/reg_loss_step: 1.5333
  train/cls_loss: 2.0991
  train/cls_loss_step: 2.0991
  train/others_reg_loss: 1.5609
  train/others_reg_loss_step: 1.5609
  val/reg_loss: 1.2086
  val_MR: 0.6424
  val_brier-minFDE6: 6.6145
  val_minADE1: 5.7686
  val_minADE6: 2.6262
  val_minFDE1: 13.1712
  val_minFDE6: 5.8880
  train/loss_epoch: 4.2125
  train/reg_loss_epoch: 1.1263
  train/cls_loss_epoch: 1.7569
  train/others_reg_loss_epoch: 1.3293

Epoch 12:
  train/loss: 3.7926
  train/loss_step: 3.7926
  train/reg_loss: 0.8121
  train/reg_loss_step: 0.8121
  train/cls_loss: 1.6142
  train/cls_loss_step: 1.6142
  train/others_reg_loss: 1.3664
  train/others_reg_loss_step: 1.3664
  val/reg_loss: 1.0107
  val_MR: 0.6617
  val_brier-minFDE6: 5.8529
  val_minADE1: 3.9784
  val_minADE6: 2.2695
  val_minFDE1: 10.1749
  val_minFDE6: 5.2167
  train/loss_epoch: 4.1644
  train/reg_loss_epoch: 1.0849
  train/cls_loss_epoch: 1.7719
  train/others_reg_loss_epoch: 1.3077

Epoch 13:
  train/loss: 3.3731
  train/loss_step: 3.3731
  train/reg_loss: 0.9629
  train/reg_loss_step: 0.9629
  train/cls_loss: 1.6096
  train/cls_loss_step: 1.6096
  train/others_reg_loss: 0.8006
  train/others_reg_loss_step: 0.8006
  val/reg_loss: 0.8042
  val_MR: 0.5208
  val_brier-minFDE6: 4.8577
  val_minADE1: 3.5180
  val_minADE6: 1.8576
  val_minFDE1: 8.9147
  val_minFDE6: 4.2051
  train/loss_epoch: 4.0428
  train/reg_loss_epoch: 1.0441
  train/cls_loss_epoch: 1.7599
  train/others_reg_loss_epoch: 1.2389

Epoch 14:
  train/loss: 3.3011
  train/loss_step: 3.3011
  train/reg_loss: 0.7505
  train/reg_loss_step: 0.7505
  train/cls_loss: 1.7050
  train/cls_loss_step: 1.7050
  train/others_reg_loss: 0.8456
  train/others_reg_loss_step: 0.8456
  val/reg_loss: 0.7432
  val_MR: 0.5403
  val_brier-minFDE6: 4.4593
  val_minADE1: 3.3048
  val_minADE6: 1.7478
  val_minFDE1: 8.1951
  val_minFDE6: 3.8043
  train/loss_epoch: 3.7800
  train/reg_loss_epoch: 0.9493
  train/cls_loss_epoch: 1.7385
  train/others_reg_loss_epoch: 1.0921

Epoch 15:
  train/loss: 3.1718
  train/loss_step: 3.1718
  train/reg_loss: 0.7052
  train/reg_loss_step: 0.7052
  train/cls_loss: 1.6677
  train/cls_loss_step: 1.6677
  train/others_reg_loss: 0.7989
  train/others_reg_loss_step: 0.7989
  val/reg_loss: 0.6074
  val_MR: 0.4886
  val_brier-minFDE6: 3.8632
  val_minADE1: 3.3438
  val_minADE6: 1.4840
  val_minFDE1: 8.1170
  val_minFDE6: 3.2133
  train/loss_epoch: 3.3476
  train/reg_loss_epoch: 0.7820
  train/cls_loss_epoch: 1.7209
  train/others_reg_loss_epoch: 0.8447

Epoch 16:
  train/loss: 2.9701
  train/loss_step: 2.9701
  train/reg_loss: 0.5246
  train/reg_loss_step: 0.5246
  train/cls_loss: 1.6570
  train/cls_loss_step: 1.6570
  train/others_reg_loss: 0.7885
  train/others_reg_loss_step: 0.7885
  val/reg_loss: 0.5371
  val_MR: 0.4579
  val_brier-minFDE6: 3.6179
  val_minADE1: 3.3057
  val_minADE6: 1.3555
  val_minFDE1: 8.4432
  val_minFDE6: 2.9707
  train/loss_epoch: 3.1997
  train/reg_loss_epoch: 0.6906
  train/cls_loss_epoch: 1.7154
  train/others_reg_loss_epoch: 0.7937

Epoch 17:
  train/loss: 3.0722
  train/loss_step: 3.0722
  train/reg_loss: 0.5480
  train/reg_loss_step: 0.5480
  train/cls_loss: 1.7838
  train/cls_loss_step: 1.7838
  train/others_reg_loss: 0.7405
  train/others_reg_loss_step: 0.7405
  val/reg_loss: 0.5496
  val_MR: 0.4862
  val_brier-minFDE6: 3.6168
  val_minADE1: 2.9675
  val_minADE6: 1.3770
  val_minFDE1: 7.3884
  val_minFDE6: 2.9763
  train/loss_epoch: 3.0569
  train/reg_loss_epoch: 0.6117
  train/cls_loss_epoch: 1.7003
  train/others_reg_loss_epoch: 0.7449

Epoch 18:
  train/loss: 2.7377
  train/loss_step: 2.7377
  train/reg_loss: 0.5763
  train/reg_loss_step: 0.5763
  train/cls_loss: 1.5762
  train/cls_loss_step: 1.5762
  train/others_reg_loss: 0.5852
  train/others_reg_loss_step: 0.5852
  val/reg_loss: 0.5007
  val_MR: 0.4303
  val_brier-minFDE6: 3.3734
  val_minADE1: 2.8907
  val_minADE6: 1.2884
  val_minFDE1: 7.1469
  val_minFDE6: 2.7415
  train/loss_epoch: 2.9808
  train/reg_loss_epoch: 0.5652
  train/cls_loss_epoch: 1.6882
  train/others_reg_loss_epoch: 0.7274

Epoch 19:
  train/loss: 2.6695
  train/loss_step: 2.6695
  train/reg_loss: 0.3255
  train/reg_loss_step: 0.3255
  train/cls_loss: 1.6716
  train/cls_loss_step: 1.6716
  train/others_reg_loss: 0.6724
  train/others_reg_loss_step: 0.6724
  val/reg_loss: 0.4834
  val_MR: 0.4275
  val_brier-minFDE6: 3.3679
  val_minADE1: 2.9409
  val_minADE6: 1.2512
  val_minFDE1: 7.4157
  val_minFDE6: 2.7233
  train/loss_epoch: 2.8720
  train/reg_loss_epoch: 0.5166
  train/cls_loss_epoch: 1.6626
  train/others_reg_loss_epoch: 0.6929

Epoch 20:
  train/loss: 2.6567
  train/loss_step: 2.6567
  train/reg_loss: 0.3189
  train/reg_loss_step: 0.3189
  train/cls_loss: 1.5495
  train/cls_loss_step: 1.5495
  train/others_reg_loss: 0.7883
  train/others_reg_loss_step: 0.7883
  val/reg_loss: 0.4661
  val_MR: 0.3960
  val_brier-minFDE6: 3.2611
  val_minADE1: 2.6579
  val_minADE6: 1.2174
  val_minFDE1: 6.7277
  val_minFDE6: 2.6242
  train/loss_epoch: 2.8283
  train/reg_loss_epoch: 0.4950
  train/cls_loss_epoch: 1.6601
  train/others_reg_loss_epoch: 0.6733

FINAL VALIDATION RESULTS:
  train/loss: 2.8039
  train/loss_step: 2.6567
  train/reg_loss: 0.4820
  train/reg_loss_step: 0.3189
  train/cls_loss: 1.6550
  train/cls_loss_step: 1.5495
  train/others_reg_loss: 0.6669
  train/others_reg_loss_step: 0.7883
  val/reg_loss: 0.4661
  val_MR: 0.3960
  val_brier-minFDE6: 3.2611
  val_minADE1: 2.6579
  val_minADE6: 1.2174
  val_minFDE1: 6.7277
  val_minFDE6: 2.6242
  train/loss_epoch: 2.8039
  train/reg_loss_epoch: 0.4820
  train/cls_loss_epoch: 1.6550
  train/others_reg_loss_epoch: 0.6669

================================================================================

Experiment 9
--------------------------------------------------
HYPERPARAMETERS:
  dim: 32
  encoder_depth: 5
  num_heads: 8
  mlp_ratio: 1
  attention_type: standard
  decoder_embed_dim: 32
  decoder_num_modes: 9
  decoder_hidden_dim: 256
  model_params: 315,761

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4283
  val_MR: 0.9609
  val_brier-minFDE6: 40.7280
  val_minADE1: 20.4087
  val_minADE6: 20.4078
  val_minFDE1: 40.0919
  val_minFDE6: 40.0375

Epoch 1:
  train/loss: 13.2125
  train/loss_step: 13.2125
  train/reg_loss: 8.0235
  train/reg_loss_step: 8.0235
  train/cls_loss: 1.0801
  train/cls_loss_step: 1.0801
  train/others_reg_loss: 4.1089
  train/others_reg_loss_step: 4.1089
  val/reg_loss: 7.2858
  val_MR: 0.9389
  val_brier-minFDE6: 30.1792
  val_minADE1: 14.5734
  val_minADE6: 14.2691
  val_minFDE1: 30.1615
  val_minFDE6: 29.9327

Epoch 2:
  train/loss: 7.7716
  train/loss_step: 7.7716
  train/reg_loss: 2.2040
  train/reg_loss_step: 2.2040
  train/cls_loss: 1.6301
  train/cls_loss_step: 1.6301
  train/others_reg_loss: 3.9375
  train/others_reg_loss_step: 3.9375
  val/reg_loss: 2.0454
  val_MR: 0.7380
  val_brier-minFDE6: 9.4456
  val_minADE1: 7.6088
  val_minADE6: 4.1921
  val_minFDE1: 15.0927
  val_minFDE6: 8.9300
  train/loss_epoch: 14.2995
  train/reg_loss_epoch: 9.1089
  train/cls_loss_epoch: 1.3185
  train/others_reg_loss_epoch: 3.8721

Epoch 3:
  train/loss: 5.9807
  train/loss_step: 5.9807
  train/reg_loss: 1.0875
  train/reg_loss_step: 1.0875
  train/cls_loss: 1.9772
  train/cls_loss_step: 1.9772
  train/others_reg_loss: 2.9159
  train/others_reg_loss_step: 2.9159
  val/reg_loss: 1.2837
  val_MR: 0.6520
  val_brier-minFDE6: 6.7470
  val_minADE1: 7.9963
  val_minADE6: 2.8418
  val_minFDE1: 16.4738
  val_minFDE6: 6.0521
  train/loss_epoch: 9.1778
  train/reg_loss_epoch: 4.1082
  train/cls_loss_epoch: 1.2648
  train/others_reg_loss_epoch: 3.8048

Epoch 4:
  train/loss: 5.2869
  train/loss_step: 5.2869
  train/reg_loss: 0.8439
  train/reg_loss_step: 0.8439
  train/cls_loss: 2.1802
  train/cls_loss_step: 2.1802
  train/others_reg_loss: 2.2629
  train/others_reg_loss_step: 2.2629
  val/reg_loss: 1.1310
  val_MR: 0.6018
  val_brier-minFDE6: 6.4108
  val_minADE1: 5.6796
  val_minADE6: 2.7166
  val_minFDE1: 12.5863
  val_minFDE6: 5.7170
  train/loss_epoch: 7.0416
  train/reg_loss_epoch: 1.5807
  train/cls_loss_epoch: 1.8730
  train/others_reg_loss_epoch: 3.5878

Epoch 5:
  train/loss: 5.3876
  train/loss_step: 5.3876
  train/reg_loss: 1.3630
  train/reg_loss_step: 1.3630
  train/cls_loss: 2.1357
  train/cls_loss_step: 2.1357
  train/others_reg_loss: 1.8889
  train/others_reg_loss_step: 1.8889
  val/reg_loss: 1.0401
  val_MR: 0.5733
  val_brier-minFDE6: 6.6727
  val_minADE1: 4.5792
  val_minADE6: 2.6740
  val_minFDE1: 10.5683
  val_minFDE6: 5.9791
  train/loss_epoch: 6.1336
  train/reg_loss_epoch: 1.2609
  train/cls_loss_epoch: 2.1500
  train/others_reg_loss_epoch: 2.7226

Epoch 6:
  train/loss: 4.8923
  train/loss_step: 4.8923
  train/reg_loss: 0.7909
  train/reg_loss_step: 0.7909
  train/cls_loss: 2.0554
  train/cls_loss_step: 2.0554
  train/others_reg_loss: 2.0460
  train/others_reg_loss_step: 2.0460
  val/reg_loss: 1.0812
  val_MR: 0.6540
  val_brier-minFDE6: 7.3901
  val_minADE1: 5.0421
  val_minADE6: 2.8904
  val_minFDE1: 11.9986
  val_minFDE6: 6.6847
  train/loss_epoch: 5.5439
  train/reg_loss_epoch: 1.1143
  train/cls_loss_epoch: 2.1664
  train/others_reg_loss_epoch: 2.2632

Epoch 7:
  train/loss: 4.7510
  train/loss_step: 4.7510
  train/reg_loss: 0.8365
  train/reg_loss_step: 0.8365
  train/cls_loss: 2.0080
  train/cls_loss_step: 2.0080
  train/others_reg_loss: 1.9065
  train/others_reg_loss_step: 1.9065
  val/reg_loss: 1.1054
  val_MR: 0.5631
  val_brier-minFDE6: 6.1114
  val_minADE1: 4.5796
  val_minADE6: 2.6446
  val_minFDE1: 10.3660
  val_minFDE6: 5.4260
  train/loss_epoch: 5.1005
  train/reg_loss_epoch: 1.0573
  train/cls_loss_epoch: 2.1342
  train/others_reg_loss_epoch: 1.9089

Epoch 8:
  train/loss: 4.9259
  train/loss_step: 4.9259
  train/reg_loss: 1.0425
  train/reg_loss_step: 1.0425
  train/cls_loss: 1.9748
  train/cls_loss_step: 1.9748
  train/others_reg_loss: 1.9086
  train/others_reg_loss_step: 1.9086
  val/reg_loss: 1.1086
  val_MR: 0.5397
  val_brier-minFDE6: 6.1559
  val_minADE1: 4.5083
  val_minADE6: 2.6779
  val_minFDE1: 10.2586
  val_minFDE6: 5.4698
  train/loss_epoch: 4.7793
  train/reg_loss_epoch: 1.0461
  train/cls_loss_epoch: 2.1293
  train/others_reg_loss_epoch: 1.6039

Epoch 9:
  train/loss: 4.5374
  train/loss_step: 4.5374
  train/reg_loss: 1.1528
  train/reg_loss_step: 1.1528
  train/cls_loss: 2.0609
  train/cls_loss_step: 2.0609
  train/others_reg_loss: 1.3236
  train/others_reg_loss_step: 1.3236
  val/reg_loss: 0.9634
  val_MR: 0.5551
  val_brier-minFDE6: 6.6399
  val_minADE1: 4.5377
  val_minADE6: 2.5778
  val_minFDE1: 11.1860
  val_minFDE6: 5.9430
  train/loss_epoch: 4.7338
  train/reg_loss_epoch: 1.0530
  train/cls_loss_epoch: 2.1329
  train/others_reg_loss_epoch: 1.5479

Epoch 10:
  train/loss: 4.4160
  train/loss_step: 4.4160
  train/reg_loss: 0.8254
  train/reg_loss_step: 0.8254
  train/cls_loss: 2.2199
  train/cls_loss_step: 2.2199
  train/others_reg_loss: 1.3707
  train/others_reg_loss_step: 1.3707
  val/reg_loss: 1.0009
  val_MR: 0.5777
  val_brier-minFDE6: 6.8773
  val_minADE1: 5.2711
  val_minADE6: 2.6676
  val_minFDE1: 12.3357
  val_minFDE6: 6.1633
  train/loss_epoch: 4.6309
  train/reg_loss_epoch: 1.0308
  train/cls_loss_epoch: 2.1378
  train/others_reg_loss_epoch: 1.4624

Epoch 11:
  train/loss: 4.3772
  train/loss_step: 4.3772
  train/reg_loss: 0.9038
  train/reg_loss_step: 0.9038
  train/cls_loss: 2.0356
  train/cls_loss_step: 2.0356
  train/others_reg_loss: 1.4378
  train/others_reg_loss_step: 1.4378
  val/reg_loss: 0.9425
  val_MR: 0.5403
  val_brier-minFDE6: 6.0131
  val_minADE1: 4.0229
  val_minADE6: 2.3363
  val_minFDE1: 9.8586
  val_minFDE6: 5.3346
  train/loss_epoch: 4.5741
  train/reg_loss_epoch: 1.0049
  train/cls_loss_epoch: 2.1409
  train/others_reg_loss_epoch: 1.4282

Epoch 12:
  train/loss: 4.6876
  train/loss_step: 4.6876
  train/reg_loss: 1.0208
  train/reg_loss_step: 1.0208
  train/cls_loss: 2.2324
  train/cls_loss_step: 2.2324
  train/others_reg_loss: 1.4343
  train/others_reg_loss_step: 1.4343
  val/reg_loss: 0.9432
  val_MR: 0.5743
  val_brier-minFDE6: 6.1499
  val_minADE1: 4.6152
  val_minADE6: 2.4159
  val_minFDE1: 11.3881
  val_minFDE6: 5.4608
  train/loss_epoch: 4.5574
  train/reg_loss_epoch: 1.0173
  train/cls_loss_epoch: 2.1585
  train/others_reg_loss_epoch: 1.3816

Epoch 13:
  train/loss: 5.2092
  train/loss_step: 5.2092
  train/reg_loss: 1.2167
  train/reg_loss_step: 1.2167
  train/cls_loss: 2.1600
  train/cls_loss_step: 2.1600
  train/others_reg_loss: 1.8326
  train/others_reg_loss_step: 1.8326
  val/reg_loss: 0.9289
  val_MR: 0.6056
  val_brier-minFDE6: 6.7940
  val_minADE1: 4.2143
  val_minADE6: 2.6276
  val_minFDE1: 10.2908
  val_minFDE6: 6.0996
  train/loss_epoch: 4.4373
  train/reg_loss_epoch: 0.9900
  train/cls_loss_epoch: 2.1114
  train/others_reg_loss_epoch: 1.3358

Epoch 14:
  train/loss: 4.7933
  train/loss_step: 4.7933
  train/reg_loss: 1.4619
  train/reg_loss_step: 1.4619
  train/cls_loss: 2.2216
  train/cls_loss_step: 2.2216
  train/others_reg_loss: 1.1098
  train/others_reg_loss_step: 1.1098
  val/reg_loss: 0.9268
  val_MR: 0.5264
  val_brier-minFDE6: 6.1839
  val_minADE1: 4.2574
  val_minADE6: 2.4502
  val_minFDE1: 10.2146
  val_minFDE6: 5.4875
  train/loss_epoch: 4.4030
  train/reg_loss_epoch: 0.9791
  train/cls_loss_epoch: 2.1050
  train/others_reg_loss_epoch: 1.3189

Epoch 15:
  train/loss: 4.1432
  train/loss_step: 4.1432
  train/reg_loss: 0.9733
  train/reg_loss_step: 0.9733
  train/cls_loss: 2.0582
  train/cls_loss_step: 2.0582
  train/others_reg_loss: 1.1118
  train/others_reg_loss_step: 1.1118
  val/reg_loss: 0.9260
  val_MR: 0.5048
  val_brier-minFDE6: 6.1073
  val_minADE1: 3.8069
  val_minADE6: 2.3799
  val_minFDE1: 9.3959
  val_minFDE6: 5.4216
  train/loss_epoch: 4.3456
  train/reg_loss_epoch: 0.9571
  train/cls_loss_epoch: 2.1186
  train/others_reg_loss_epoch: 1.2699

Epoch 16:
  train/loss: 4.3085
  train/loss_step: 4.3085
  train/reg_loss: 1.1530
  train/reg_loss_step: 1.1530
  train/cls_loss: 2.1139
  train/cls_loss_step: 2.1139
  train/others_reg_loss: 1.0416
  train/others_reg_loss_step: 1.0416
  val/reg_loss: 0.9116
  val_MR: 0.5329
  val_brier-minFDE6: 6.1336
  val_minADE1: 4.3360
  val_minADE6: 2.3411
  val_minFDE1: 11.1766
  val_minFDE6: 5.4363
  train/loss_epoch: 4.2810
  train/reg_loss_epoch: 0.9352
  train/cls_loss_epoch: 2.1062
  train/others_reg_loss_epoch: 1.2397

Epoch 17:
  train/loss: 3.7733
  train/loss_step: 3.7733
  train/reg_loss: 0.9194
  train/reg_loss_step: 0.9194
  train/cls_loss: 2.0402
  train/cls_loss_step: 2.0402
  train/others_reg_loss: 0.8137
  train/others_reg_loss_step: 0.8137
  val/reg_loss: 0.8716
  val_MR: 0.4712
  val_brier-minFDE6: 5.8001
  val_minADE1: 3.7218
  val_minADE6: 2.2391
  val_minFDE1: 9.3047
  val_minFDE6: 5.1186
  train/loss_epoch: 4.2174
  train/reg_loss_epoch: 0.9152
  train/cls_loss_epoch: 2.1108
  train/others_reg_loss_epoch: 1.1915

Epoch 18:
  train/loss: 3.7924
  train/loss_step: 3.7924
  train/reg_loss: 0.7745
  train/reg_loss_step: 0.7745
  train/cls_loss: 1.9752
  train/cls_loss_step: 1.9752
  train/others_reg_loss: 1.0427
  train/others_reg_loss_step: 1.0427
  val/reg_loss: 0.8747
  val_MR: 0.4675
  val_brier-minFDE6: 5.7995
  val_minADE1: 3.6178
  val_minADE6: 2.2385
  val_minFDE1: 9.0187
  val_minFDE6: 5.1152
  train/loss_epoch: 4.1077
  train/reg_loss_epoch: 0.8863
  train/cls_loss_epoch: 2.0558
  train/others_reg_loss_epoch: 1.1655

Epoch 19:
  train/loss: 3.8496
  train/loss_step: 3.8496
  train/reg_loss: 0.7860
  train/reg_loss_step: 0.7860
  train/cls_loss: 2.0723
  train/cls_loss_step: 2.0723
  train/others_reg_loss: 0.9913
  train/others_reg_loss_step: 0.9913
  val/reg_loss: 0.8525
  val_MR: 0.4429
  val_brier-minFDE6: 5.6262
  val_minADE1: 3.6092
  val_minADE6: 2.1746
  val_minFDE1: 9.0089
  val_minFDE6: 4.9489
  train/loss_epoch: 3.9993
  train/reg_loss_epoch: 0.8535
  train/cls_loss_epoch: 2.0282
  train/others_reg_loss_epoch: 1.1176

Epoch 20:
  train/loss: 4.0357
  train/loss_step: 4.0357
  train/reg_loss: 0.9093
  train/reg_loss_step: 0.9093
  train/cls_loss: 1.9787
  train/cls_loss_step: 1.9787
  train/others_reg_loss: 1.1477
  train/others_reg_loss_step: 1.1477
  val/reg_loss: 0.8492
  val_MR: 0.4429
  val_brier-minFDE6: 5.6205
  val_minADE1: 3.6067
  val_minADE6: 2.1624
  val_minFDE1: 9.0337
  val_minFDE6: 4.9416
  train/loss_epoch: 3.9881
  train/reg_loss_epoch: 0.8649
  train/cls_loss_epoch: 2.0249
  train/others_reg_loss_epoch: 1.0983

FINAL VALIDATION RESULTS:
  train/loss: 3.9401
  train/loss_step: 4.0357
  train/reg_loss: 0.8290
  train/reg_loss_step: 0.9093
  train/cls_loss: 2.0112
  train/cls_loss_step: 1.9787
  train/others_reg_loss: 1.0998
  train/others_reg_loss_step: 1.1477
  val/reg_loss: 0.8492
  val_MR: 0.4429
  val_brier-minFDE6: 5.6205
  val_minADE1: 3.6067
  val_minADE6: 2.1624
  val_minFDE1: 9.0337
  val_minFDE6: 4.9416
  train/loss_epoch: 3.9401
  train/reg_loss_epoch: 0.8290
  train/cls_loss_epoch: 2.0112
  train/others_reg_loss_epoch: 1.0998

================================================================================

Experiment 10
--------------------------------------------------
HYPERPARAMETERS:
  dim: 64
  encoder_depth: 3
  num_heads: 2
  mlp_ratio: 5
  attention_type: standard
  decoder_embed_dim: 32
  decoder_num_modes: 3
  decoder_hidden_dim: 64
  model_params: 586,769

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4333
  val_MR: 0.9609
  val_brier-minFDE6: 40.2146
  val_minADE1: 20.4215
  val_minADE6: 20.4169
  val_minFDE1: 39.8296
  val_minFDE6: 39.8238

Epoch 1:
  train/loss: 12.6119
  train/loss_step: 12.6119
  train/reg_loss: 7.7606
  train/reg_loss_step: 7.7606
  train/cls_loss: 0.5987
  train/cls_loss_step: 0.5987
  train/others_reg_loss: 4.2526
  train/others_reg_loss_step: 4.2526
  val/reg_loss: 7.4308
  val_MR: 0.9633
  val_brier-minFDE6: 25.6125
  val_minADE1: 14.5590
  val_minADE6: 14.4647
  val_minFDE1: 25.6300
  val_minFDE6: 25.4021

Epoch 2:
  train/loss: 7.4988
  train/loss_step: 7.4988
  train/reg_loss: 2.8123
  train/reg_loss_step: 2.8123
  train/cls_loss: 0.8320
  train/cls_loss_step: 0.8320
  train/others_reg_loss: 3.8545
  train/others_reg_loss_step: 3.8545
  val/reg_loss: 2.5108
  val_MR: 0.7788
  val_brier-minFDE6: 9.7252
  val_minADE1: 5.9843
  val_minADE6: 5.0332
  val_minFDE1: 11.3855
  val_minFDE6: 9.3869
  train/loss_epoch: 13.7816
  train/reg_loss_epoch: 9.1721
  train/cls_loss_epoch: 0.6521
  train/others_reg_loss_epoch: 3.9574

Epoch 3:
  train/loss: 5.9281
  train/loss_step: 5.9281
  train/reg_loss: 1.8303
  train/reg_loss_step: 1.8303
  train/cls_loss: 1.0095
  train/cls_loss_step: 1.0095
  train/others_reg_loss: 3.0883
  train/others_reg_loss_step: 3.0883
  val/reg_loss: 1.7922
  val_MR: 0.7426
  val_brier-minFDE6: 9.0376
  val_minADE1: 4.8802
  val_minADE6: 3.7198
  val_minFDE1: 11.3063
  val_minFDE6: 8.6568
  train/loss_epoch: 9.0576
  train/reg_loss_epoch: 4.3589
  train/cls_loss_epoch: 0.8110
  train/others_reg_loss_epoch: 3.8877

Epoch 4:
  train/loss: 5.6264
  train/loss_step: 5.6264
  train/reg_loss: 1.4693
  train/reg_loss_step: 1.4693
  train/cls_loss: 1.0706
  train/cls_loss_step: 1.0706
  train/others_reg_loss: 3.0866
  train/others_reg_loss_step: 3.0866
  val/reg_loss: 1.5740
  val_MR: 0.7722
  val_brier-minFDE6: 7.9188
  val_minADE1: 5.9945
  val_minADE6: 3.3106
  val_minFDE1: 12.9867
  val_minFDE6: 7.4877
  train/loss_epoch: 7.0946
  train/reg_loss_epoch: 2.3294
  train/cls_loss_epoch: 0.9531
  train/others_reg_loss_epoch: 3.8121

Epoch 5:
  train/loss: 5.7292
  train/loss_step: 5.7292
  train/reg_loss: 2.3251
  train/reg_loss_step: 2.3251
  train/cls_loss: 1.1501
  train/cls_loss_step: 1.1501
  train/others_reg_loss: 2.2541
  train/others_reg_loss_step: 2.2541
  val/reg_loss: 2.2601
  val_MR: 0.8097
  val_brier-minFDE6: 10.2157
  val_minADE1: 9.2303
  val_minADE6: 4.5669
  val_minFDE1: 18.4331
  val_minFDE6: 9.7582
  train/loss_epoch: 6.5800
  train/reg_loss_epoch: 2.0774
  train/cls_loss_epoch: 1.0307
  train/others_reg_loss_epoch: 3.4719

Epoch 6:
  train/loss: 4.2885
  train/loss_step: 4.2885
  train/reg_loss: 1.5333
  train/reg_loss_step: 1.5333
  train/cls_loss: 1.0375
  train/cls_loss_step: 1.0375
  train/others_reg_loss: 1.7177
  train/others_reg_loss_step: 1.7177
  val/reg_loss: 1.4553
  val_MR: 0.7458
  val_brier-minFDE6: 7.3940
  val_minADE1: 5.4229
  val_minADE6: 3.0745
  val_minFDE1: 12.3079
  val_minFDE6: 6.9369
  train/loss_epoch: 5.4723
  train/reg_loss_epoch: 1.7504
  train/cls_loss_epoch: 1.0950
  train/others_reg_loss_epoch: 2.6269

Epoch 7:
  train/loss: 4.5382
  train/loss_step: 4.5382
  train/reg_loss: 1.6927
  train/reg_loss_step: 1.6927
  train/cls_loss: 1.0618
  train/cls_loss_step: 1.0618
  train/others_reg_loss: 1.7836
  train/others_reg_loss_step: 1.7836
  val/reg_loss: 1.7038
  val_MR: 0.7574
  val_brier-minFDE6: 7.6176
  val_minADE1: 6.1609
  val_minADE6: 3.5519
  val_minFDE1: 12.7282
  val_minFDE6: 7.1962
  train/loss_epoch: 4.6620
  train/reg_loss_epoch: 1.5274
  train/cls_loss_epoch: 1.0981
  train/others_reg_loss_epoch: 2.0365

Epoch 8:
  train/loss: 3.8468
  train/loss_step: 3.8468
  train/reg_loss: 1.4293
  train/reg_loss_step: 1.4293
  train/cls_loss: 1.1005
  train/cls_loss_step: 1.1005
  train/others_reg_loss: 1.3170
  train/others_reg_loss_step: 1.3170
  val/reg_loss: 1.2818
  val_MR: 0.7474
  val_brier-minFDE6: 6.8500
  val_minADE1: 4.2959
  val_minADE6: 2.7569
  val_minFDE1: 10.5838
  val_minFDE6: 6.4107
  train/loss_epoch: 4.1494
  train/reg_loss_epoch: 1.4472
  train/cls_loss_epoch: 1.1003
  train/others_reg_loss_epoch: 1.6019

Epoch 9:
  train/loss: 4.1215
  train/loss_step: 4.1215
  train/reg_loss: 1.5179
  train/reg_loss_step: 1.5179
  train/cls_loss: 1.0940
  train/cls_loss_step: 1.0940
  train/others_reg_loss: 1.5096
  train/others_reg_loss_step: 1.5096
  val/reg_loss: 1.3079
  val_MR: 0.7536
  val_brier-minFDE6: 6.7831
  val_minADE1: 4.4944
  val_minADE6: 2.7936
  val_minFDE1: 10.5310
  val_minFDE6: 6.3540
  train/loss_epoch: 4.1079
  train/reg_loss_epoch: 1.4622
  train/cls_loss_epoch: 1.1109
  train/others_reg_loss_epoch: 1.5348

Epoch 10:
  train/loss: 3.5998
  train/loss_step: 3.5998
  train/reg_loss: 1.1691
  train/reg_loss_step: 1.1691
  train/cls_loss: 1.1562
  train/cls_loss_step: 1.1562
  train/others_reg_loss: 1.2745
  train/others_reg_loss_step: 1.2745
  val/reg_loss: 1.5746
  val_MR: 0.7326
  val_brier-minFDE6: 7.0783
  val_minADE1: 5.0543
  val_minADE6: 3.3095
  val_minFDE1: 10.6495
  val_minFDE6: 6.6225
  train/loss_epoch: 3.9220
  train/reg_loss_epoch: 1.4027
  train/cls_loss_epoch: 1.0975
  train/others_reg_loss_epoch: 1.4217

Epoch 11:
  train/loss: 3.6146
  train/loss_step: 3.6146
  train/reg_loss: 1.3356
  train/reg_loss_step: 1.3356
  train/cls_loss: 1.1409
  train/cls_loss_step: 1.1409
  train/others_reg_loss: 1.1381
  train/others_reg_loss_step: 1.1381
  val/reg_loss: 1.3577
  val_MR: 0.7516
  val_brier-minFDE6: 6.8638
  val_minADE1: 4.5490
  val_minADE6: 2.8867
  val_minFDE1: 10.8943
  val_minFDE6: 6.4022
  train/loss_epoch: 3.9599
  train/reg_loss_epoch: 1.4271
  train/cls_loss_epoch: 1.1004
  train/others_reg_loss_epoch: 1.4324

Epoch 12:
  train/loss: 3.7435
  train/loss_step: 3.7435
  train/reg_loss: 1.2845
  train/reg_loss_step: 1.2845
  train/cls_loss: 1.0236
  train/cls_loss_step: 1.0236
  train/others_reg_loss: 1.4355
  train/others_reg_loss_step: 1.4355
  val/reg_loss: 1.2963
  val_MR: 0.7570
  val_brier-minFDE6: 6.8629
  val_minADE1: 4.1045
  val_minADE6: 2.7782
  val_minFDE1: 9.9574
  val_minFDE6: 6.4689
  train/loss_epoch: 3.8747
  train/reg_loss_epoch: 1.4018
  train/cls_loss_epoch: 1.0919
  train/others_reg_loss_epoch: 1.3810

Epoch 13:
  train/loss: 3.3620
  train/loss_step: 3.3620
  train/reg_loss: 1.1460
  train/reg_loss_step: 1.1460
  train/cls_loss: 1.0657
  train/cls_loss_step: 1.0657
  train/others_reg_loss: 1.1504
  train/others_reg_loss_step: 1.1504
  val/reg_loss: 1.2205
  val_MR: 0.7185
  val_brier-minFDE6: 6.4229
  val_minADE1: 4.0481
  val_minADE6: 2.6352
  val_minFDE1: 9.6519
  val_minFDE6: 6.0012
  train/loss_epoch: 3.6727
  train/reg_loss_epoch: 1.3038
  train/cls_loss_epoch: 1.0677
  train/others_reg_loss_epoch: 1.3013

Epoch 14:
  train/loss: 4.0465
  train/loss_step: 4.0465
  train/reg_loss: 1.2842
  train/reg_loss_step: 1.2842
  train/cls_loss: 1.0949
  train/cls_loss_step: 1.0949
  train/others_reg_loss: 1.6675
  train/others_reg_loss_step: 1.6675
  val/reg_loss: 1.2854
  val_MR: 0.7196
  val_brier-minFDE6: 6.6681
  val_minADE1: 4.1154
  val_minADE6: 2.7420
  val_minFDE1: 9.7616
  val_minFDE6: 6.2379
  train/loss_epoch: 3.7405
  train/reg_loss_epoch: 1.3504
  train/cls_loss_epoch: 1.0822
  train/others_reg_loss_epoch: 1.3079

Epoch 15:
  train/loss: 3.8965
  train/loss_step: 3.8965
  train/reg_loss: 1.6622
  train/reg_loss_step: 1.6622
  train/cls_loss: 1.0788
  train/cls_loss_step: 1.0788
  train/others_reg_loss: 1.1556
  train/others_reg_loss_step: 1.1556
  val/reg_loss: 1.2408
  val_MR: 0.7143
  val_brier-minFDE6: 6.9572
  val_minADE1: 4.2808
  val_minADE6: 2.6653
  val_minFDE1: 10.9554
  val_minFDE6: 6.5068
  train/loss_epoch: 3.6100
  train/reg_loss_epoch: 1.2784
  train/cls_loss_epoch: 1.0835
  train/others_reg_loss_epoch: 1.2481

Epoch 16:
  train/loss: 3.6356
  train/loss_step: 3.6356
  train/reg_loss: 1.4976
  train/reg_loss_step: 1.4976
  train/cls_loss: 1.0908
  train/cls_loss_step: 1.0908
  train/others_reg_loss: 1.0471
  train/others_reg_loss_step: 1.0471
  val/reg_loss: 1.1357
  val_MR: 0.6841
  val_brier-minFDE6: 6.2474
  val_minADE1: 3.6461
  val_minADE6: 2.4815
  val_minFDE1: 9.1412
  val_minFDE6: 5.8444
  train/loss_epoch: 3.5524
  train/reg_loss_epoch: 1.2541
  train/cls_loss_epoch: 1.0765
  train/others_reg_loss_epoch: 1.2218

Epoch 17:
  train/loss: 3.9811
  train/loss_step: 3.9811
  train/reg_loss: 1.3512
  train/reg_loss_step: 1.3512
  train/cls_loss: 1.0288
  train/cls_loss_step: 1.0288
  train/others_reg_loss: 1.6011
  train/others_reg_loss_step: 1.6011
  val/reg_loss: 1.1215
  val_MR: 0.6811
  val_brier-minFDE6: 6.2233
  val_minADE1: 3.4917
  val_minADE6: 2.4534
  val_minFDE1: 8.7313
  val_minFDE6: 5.8182
  train/loss_epoch: 3.3925
  train/reg_loss_epoch: 1.1868
  train/cls_loss_epoch: 1.0560
  train/others_reg_loss_epoch: 1.1497

Epoch 18:
  train/loss: 3.0958
  train/loss_step: 3.0958
  train/reg_loss: 1.0329
  train/reg_loss_step: 1.0329
  train/cls_loss: 1.0374
  train/cls_loss_step: 1.0374
  train/others_reg_loss: 1.0256
  train/others_reg_loss_step: 1.0256
  val/reg_loss: 1.1081
  val_MR: 0.6699
  val_brier-minFDE6: 6.2146
  val_minADE1: 3.5238
  val_minADE6: 2.4258
  val_minFDE1: 8.8415
  val_minFDE6: 5.7917
  train/loss_epoch: 3.3647
  train/reg_loss_epoch: 1.1697
  train/cls_loss_epoch: 1.0635
  train/others_reg_loss_epoch: 1.1315

Epoch 19:
  train/loss: 3.0386
  train/loss_step: 3.0386
  train/reg_loss: 1.0190
  train/reg_loss_step: 1.0190
  train/cls_loss: 1.0442
  train/cls_loss_step: 1.0442
  train/others_reg_loss: 0.9753
  train/others_reg_loss_step: 0.9753
  val/reg_loss: 1.0935
  val_MR: 0.6687
  val_brier-minFDE6: 6.1438
  val_minADE1: 3.4508
  val_minADE6: 2.3949
  val_minFDE1: 8.6642
  val_minFDE6: 5.7372
  train/loss_epoch: 3.2790
  train/reg_loss_epoch: 1.1223
  train/cls_loss_epoch: 1.0455
  train/others_reg_loss_epoch: 1.1111

Epoch 20:
  train/loss: 2.9603
  train/loss_step: 2.9603
  train/reg_loss: 1.0388
  train/reg_loss_step: 1.0388
  train/cls_loss: 1.0163
  train/cls_loss_step: 1.0163
  train/others_reg_loss: 0.9051
  train/others_reg_loss_step: 0.9051
  val/reg_loss: 1.0892
  val_MR: 0.6719
  val_brier-minFDE6: 6.1525
  val_minADE1: 3.4458
  val_minADE6: 2.3860
  val_minFDE1: 8.6648
  val_minFDE6: 5.7410
  train/loss_epoch: 3.2347
  train/reg_loss_epoch: 1.1034
  train/cls_loss_epoch: 1.0441
  train/others_reg_loss_epoch: 1.0872

FINAL VALIDATION RESULTS:
  train/loss: 3.1768
  train/loss_step: 2.9603
  train/reg_loss: 1.0789
  train/reg_loss_step: 1.0388
  train/cls_loss: 1.0327
  train/cls_loss_step: 1.0163
  train/others_reg_loss: 1.0651
  train/others_reg_loss_step: 0.9051
  val/reg_loss: 1.0892
  val_MR: 0.6719
  val_brier-minFDE6: 6.1525
  val_minADE1: 3.4458
  val_minADE6: 2.3860
  val_minFDE1: 8.6648
  val_minFDE6: 5.7410
  train/loss_epoch: 3.1768
  train/reg_loss_epoch: 1.0789
  train/cls_loss_epoch: 1.0327
  train/others_reg_loss_epoch: 1.0651

================================================================================

Experiment 11
--------------------------------------------------
HYPERPARAMETERS:
  dim: 48
  encoder_depth: 5
  num_heads: 6
  mlp_ratio: 3
  attention_type: performer
  decoder_embed_dim: 32
  decoder_num_modes: 9
  decoder_hidden_dim: 64
  model_params: 465,553

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4250
  val_MR: 0.9609
  val_brier-minFDE6: 40.7558
  val_minADE1: 20.4031
  val_minADE6: 20.3984
  val_minFDE1: 40.0974
  val_minFDE6: 40.0638

Epoch 1:
  train/loss: 13.5511
  train/loss_step: 13.5511
  train/reg_loss: 7.7911
  train/reg_loss_step: 7.7911
  train/cls_loss: 1.8120
  train/cls_loss_step: 1.8120
  train/others_reg_loss: 3.9480
  train/others_reg_loss_step: 3.9480
  val/reg_loss: 7.6448
  val_MR: 0.9345
  val_brier-minFDE6: 31.4188
  val_minADE1: 15.0817
  val_minADE6: 14.9315
  val_minFDE1: 30.9030
  val_minFDE6: 30.7675

Epoch 2:
  train/loss: 6.4724
  train/loss_step: 6.4724
  train/reg_loss: 2.1657
  train/reg_loss_step: 2.1657
  train/cls_loss: 1.1875
  train/cls_loss_step: 1.1875
  train/others_reg_loss: 3.1191
  train/others_reg_loss_step: 3.1191
  val/reg_loss: 2.5952
  val_MR: 0.8405
  val_brier-minFDE6: 11.1730
  val_minADE1: 6.0772
  val_minADE6: 5.2461
  val_minFDE1: 12.6894
  val_minFDE6: 10.8026
  train/loss_epoch: 14.6977
  train/reg_loss_epoch: 9.2390
  train/cls_loss_epoch: 1.5916
  train/others_reg_loss_epoch: 3.8671

Epoch 3:
  train/loss: 7.6564
  train/loss_step: 7.6564
  train/reg_loss: 2.6235
  train/reg_loss_step: 2.6235
  train/cls_loss: 1.2497
  train/cls_loss_step: 1.2497
  train/others_reg_loss: 3.7832
  train/others_reg_loss_step: 3.7832
  val/reg_loss: 2.1320
  val_MR: 0.8133
  val_brier-minFDE6: 10.3568
  val_minADE1: 5.3072
  val_minADE6: 4.3706
  val_minFDE1: 12.1779
  val_minFDE6: 9.8983
  train/loss_epoch: 9.3890
  train/reg_loss_epoch: 4.2102
  train/cls_loss_epoch: 1.2872
  train/others_reg_loss_epoch: 3.8916

Epoch 4:
  train/loss: 6.0147
  train/loss_step: 6.0147
  train/reg_loss: 1.8054
  train/reg_loss_step: 1.8054
  train/cls_loss: 1.7517
  train/cls_loss_step: 1.7517
  train/others_reg_loss: 2.4576
  train/others_reg_loss_step: 2.4576
  val/reg_loss: 2.2310
  val_MR: 0.7704
  val_brier-minFDE6: 10.5513
  val_minADE1: 7.2960
  val_minADE6: 4.5732
  val_minFDE1: 15.8563
  val_minFDE6: 9.9480
  train/loss_epoch: 7.4496
  train/reg_loss_epoch: 2.1637
  train/cls_loss_epoch: 1.4533
  train/others_reg_loss_epoch: 3.8326

Epoch 5:
  train/loss: 5.3159
  train/loss_step: 5.3159
  train/reg_loss: 1.0750
  train/reg_loss_step: 1.0750
  train/cls_loss: 2.1226
  train/cls_loss_step: 2.1226
  train/others_reg_loss: 2.1184
  train/others_reg_loss_step: 2.1184
  val/reg_loss: 1.3338
  val_MR: 0.6577
  val_brier-minFDE6: 6.8921
  val_minADE1: 7.9703
  val_minADE6: 2.9458
  val_minFDE1: 17.2488
  val_minFDE6: 6.1849
  train/loss_epoch: 6.9694
  train/reg_loss_epoch: 1.6200
  train/cls_loss_epoch: 1.7646
  train/others_reg_loss_epoch: 3.5847

Epoch 6:
  train/loss: 5.8614
  train/loss_step: 5.8614
  train/reg_loss: 1.4825
  train/reg_loss_step: 1.4825
  train/cls_loss: 2.0750
  train/cls_loss_step: 2.0750
  train/others_reg_loss: 2.3038
  train/others_reg_loss_step: 2.3038
  val/reg_loss: 1.2013
  val_MR: 0.7173
  val_brier-minFDE6: 8.5756
  val_minADE1: 6.9368
  val_minADE6: 3.3370
  val_minFDE1: 16.5234
  val_minFDE6: 7.9202
  train/loss_epoch: 6.0737
  train/reg_loss_epoch: 1.3151
  train/cls_loss_epoch: 2.0850
  train/others_reg_loss_epoch: 2.6736

Epoch 7:
  train/loss: 4.9249
  train/loss_step: 4.9249
  train/reg_loss: 0.9496
  train/reg_loss_step: 0.9496
  train/cls_loss: 2.1584
  train/cls_loss_step: 2.1584
  train/others_reg_loss: 1.8169
  train/others_reg_loss_step: 1.8169
  val/reg_loss: 1.0870
  val_MR: 0.6292
  val_brier-minFDE6: 6.8835
  val_minADE1: 8.2240
  val_minADE6: 2.7497
  val_minFDE1: 18.1819
  val_minFDE6: 6.1878
  train/loss_epoch: 5.7273
  train/reg_loss_epoch: 1.2341
  train/cls_loss_epoch: 2.1498
  train/others_reg_loss_epoch: 2.3434

Epoch 8:
  train/loss: 4.5572
  train/loss_step: 4.5572
  train/reg_loss: 1.0200
  train/reg_loss_step: 1.0200
  train/cls_loss: 2.0415
  train/cls_loss_step: 2.0415
  train/others_reg_loss: 1.4957
  train/others_reg_loss_step: 1.4957
  val/reg_loss: 1.0922
  val_MR: 0.6623
  val_brier-minFDE6: 7.6374
  val_minADE1: 9.8250
  val_minADE6: 3.1181
  val_minFDE1: 21.1744
  val_minFDE6: 6.9074
  train/loss_epoch: 5.2315
  train/reg_loss_epoch: 1.2062
  train/cls_loss_epoch: 2.1323
  train/others_reg_loss_epoch: 1.8931

Epoch 9:
  train/loss: 5.0696
  train/loss_step: 5.0696
  train/reg_loss: 1.1648
  train/reg_loss_step: 1.1648
  train/cls_loss: 2.1758
  train/cls_loss_step: 2.1758
  train/others_reg_loss: 1.7290
  train/others_reg_loss_step: 1.7290
  val/reg_loss: 1.2012
  val_MR: 0.6066
  val_brier-minFDE6: 6.7449
  val_minADE1: 5.2040
  val_minADE6: 3.0426
  val_minFDE1: 11.3081
  val_minFDE6: 6.0524
  train/loss_epoch: 5.1198
  train/reg_loss_epoch: 1.2263
  train/cls_loss_epoch: 2.1118
  train/others_reg_loss_epoch: 1.7817

Epoch 10:
  train/loss: 4.5350
  train/loss_step: 4.5350
  train/reg_loss: 0.9693
  train/reg_loss_step: 0.9693
  train/cls_loss: 2.1218
  train/cls_loss_step: 2.1218
  train/others_reg_loss: 1.4439
  train/others_reg_loss_step: 1.4439
  val/reg_loss: 1.0840
  val_MR: 0.6795
  val_brier-minFDE6: 8.5423
  val_minADE1: 7.7760
  val_minADE6: 3.5497
  val_minFDE1: 17.9663
  val_minFDE6: 7.8337
  train/loss_epoch: 4.9389
  train/reg_loss_epoch: 1.1630
  train/cls_loss_epoch: 2.1241
  train/others_reg_loss_epoch: 1.6518

Epoch 11:
  train/loss: 4.6948
  train/loss_step: 4.6948
  train/reg_loss: 0.9854
  train/reg_loss_step: 0.9854
  train/cls_loss: 1.9695
  train/cls_loss_step: 1.9695
  train/others_reg_loss: 1.7399
  train/others_reg_loss_step: 1.7399
  val/reg_loss: 0.9757
  val_MR: 0.5711
  val_brier-minFDE6: 6.0792
  val_minADE1: 4.1032
  val_minADE6: 2.4144
  val_minFDE1: 10.1423
  val_minFDE6: 5.3958
  train/loss_epoch: 4.8325
  train/reg_loss_epoch: 1.1833
  train/cls_loss_epoch: 2.1536
  train/others_reg_loss_epoch: 1.4957

Epoch 12:
  train/loss: 4.5287
  train/loss_step: 4.5287
  train/reg_loss: 1.0211
  train/reg_loss_step: 1.0211
  train/cls_loss: 2.0214
  train/cls_loss_step: 2.0214
  train/others_reg_loss: 1.4862
  train/others_reg_loss_step: 1.4862
  val/reg_loss: 1.0197
  val_MR: 0.5651
  val_brier-minFDE6: 6.7535
  val_minADE1: 5.0054
  val_minADE6: 2.8063
  val_minFDE1: 11.6941
  val_minFDE6: 6.0415
  train/loss_epoch: 4.6711
  train/reg_loss_epoch: 1.1042
  train/cls_loss_epoch: 2.1433
  train/others_reg_loss_epoch: 1.4235

Epoch 13:
  train/loss: 4.4363
  train/loss_step: 4.4363
  train/reg_loss: 0.9513
  train/reg_loss_step: 0.9513
  train/cls_loss: 2.2204
  train/cls_loss_step: 2.2204
  train/others_reg_loss: 1.2645
  train/others_reg_loss_step: 1.2645
  val/reg_loss: 0.9613
  val_MR: 0.5899
  val_brier-minFDE6: 7.1266
  val_minADE1: 5.3656
  val_minADE6: 2.7827
  val_minFDE1: 13.2516
  val_minFDE6: 6.4082
  train/loss_epoch: 4.6518
  train/reg_loss_epoch: 1.0681
  train/cls_loss_epoch: 2.1744
  train/others_reg_loss_epoch: 1.4092

Epoch 14:
  train/loss: 3.3474
  train/loss_step: 3.3474
  train/reg_loss: 0.5961
  train/reg_loss_step: 0.5961
  train/cls_loss: 1.9330
  train/cls_loss_step: 1.9330
  train/others_reg_loss: 0.8183
  train/others_reg_loss_step: 0.8183
  val/reg_loss: 0.9431
  val_MR: 0.5106
  val_brier-minFDE6: 6.1337
  val_minADE1: 4.0327
  val_minADE6: 2.4447
  val_minFDE1: 9.6669
  val_minFDE6: 5.4477
  train/loss_epoch: 4.4028
  train/reg_loss_epoch: 0.9783
  train/cls_loss_epoch: 2.1300
  train/others_reg_loss_epoch: 1.2945

Epoch 15:
  train/loss: 4.0947
  train/loss_step: 4.0947
  train/reg_loss: 0.9643
  train/reg_loss_step: 0.9643
  train/cls_loss: 2.1891
  train/cls_loss_step: 2.1891
  train/others_reg_loss: 0.9413
  train/others_reg_loss_step: 0.9413
  val/reg_loss: 0.9669
  val_MR: 0.5839
  val_brier-minFDE6: 7.1266
  val_minADE1: 5.0854
  val_minADE6: 2.8141
  val_minFDE1: 12.0635
  val_minFDE6: 6.4229
  train/loss_epoch: 4.3300
  train/reg_loss_epoch: 0.9437
  train/cls_loss_epoch: 2.1204
  train/others_reg_loss_epoch: 1.2659

Epoch 16:
  train/loss: 3.9362
  train/loss_step: 3.9362
  train/reg_loss: 0.8244
  train/reg_loss_step: 0.8244
  train/cls_loss: 1.9973
  train/cls_loss_step: 1.9973
  train/others_reg_loss: 1.1145
  train/others_reg_loss_step: 1.1145
  val/reg_loss: 0.9023
  val_MR: 0.4810
  val_brier-minFDE6: 5.9525
  val_minADE1: 3.8004
  val_minADE6: 2.2949
  val_minFDE1: 9.5450
  val_minFDE6: 5.2685
  train/loss_epoch: 4.2288
  train/reg_loss_epoch: 0.9117
  train/cls_loss_epoch: 2.1100
  train/others_reg_loss_epoch: 1.2070

Epoch 17:
  train/loss: 4.0010
  train/loss_step: 4.0010
  train/reg_loss: 0.6587
  train/reg_loss_step: 0.6587
  train/cls_loss: 1.9395
  train/cls_loss_step: 1.9395
  train/others_reg_loss: 1.4028
  train/others_reg_loss_step: 1.4028
  val/reg_loss: 0.8947
  val_MR: 0.4762
  val_brier-minFDE6: 5.8685
  val_minADE1: 3.7720
  val_minADE6: 2.2371
  val_minFDE1: 9.4723
  val_minFDE6: 5.1840
  train/loss_epoch: 4.1913
  train/reg_loss_epoch: 0.9182
  train/cls_loss_epoch: 2.0908
  train/others_reg_loss_epoch: 1.1823

Epoch 18:
  train/loss: 4.3819
  train/loss_step: 4.3819
  train/reg_loss: 1.0576
  train/reg_loss_step: 1.0576
  train/cls_loss: 2.1097
  train/cls_loss_step: 2.1097
  train/others_reg_loss: 1.2146
  train/others_reg_loss_step: 1.2146
  val/reg_loss: 0.8789
  val_MR: 0.4762
  val_brier-minFDE6: 5.9794
  val_minADE1: 3.6990
  val_minADE6: 2.2658
  val_minFDE1: 9.2697
  val_minFDE6: 5.2915
  train/loss_epoch: 4.0966
  train/reg_loss_epoch: 0.8952
  train/cls_loss_epoch: 2.0488
  train/others_reg_loss_epoch: 1.1525

Epoch 19:
  train/loss: 4.0851
  train/loss_step: 4.0851
  train/reg_loss: 0.8216
  train/reg_loss_step: 0.8216
  train/cls_loss: 2.1573
  train/cls_loss_step: 2.1573
  train/others_reg_loss: 1.1063
  train/others_reg_loss_step: 1.1063
  val/reg_loss: 0.8796
  val_MR: 0.4790
  val_brier-minFDE6: 5.9681
  val_minADE1: 3.5715
  val_minADE6: 2.2658
  val_minFDE1: 8.9642
  val_minFDE6: 5.2816
  train/loss_epoch: 4.0801
  train/reg_loss_epoch: 0.8824
  train/cls_loss_epoch: 2.0657
  train/others_reg_loss_epoch: 1.1320

Epoch 20:
  train/loss: 4.0717
  train/loss_step: 4.0717
  train/reg_loss: 0.8952
  train/reg_loss_step: 0.8952
  train/cls_loss: 2.0149
  train/cls_loss_step: 2.0149
  train/others_reg_loss: 1.1617
  train/others_reg_loss_step: 1.1617
  val/reg_loss: 0.8716
  val_MR: 0.4667
  val_brier-minFDE6: 5.8791
  val_minADE1: 3.6107
  val_minADE6: 2.2310
  val_minFDE1: 9.0972
  val_minFDE6: 5.2003
  train/loss_epoch: 3.9925
  train/reg_loss_epoch: 0.8444
  train/cls_loss_epoch: 2.0304
  train/others_reg_loss_epoch: 1.1177

FINAL VALIDATION RESULTS:
  train/loss: 3.9942
  train/loss_step: 4.0717
  train/reg_loss: 0.8644
  train/reg_loss_step: 0.8952
  train/cls_loss: 2.0193
  train/cls_loss_step: 2.0149
  train/others_reg_loss: 1.1105
  train/others_reg_loss_step: 1.1617
  val/reg_loss: 0.8716
  val_MR: 0.4667
  val_brier-minFDE6: 5.8791
  val_minADE1: 3.6107
  val_minADE6: 2.2310
  val_minFDE1: 9.0972
  val_minFDE6: 5.2003
  train/loss_epoch: 3.9942
  train/reg_loss_epoch: 0.8644
  train/cls_loss_epoch: 2.0193
  train/others_reg_loss_epoch: 1.1105

================================================================================

Experiment 12
--------------------------------------------------
HYPERPARAMETERS:
  dim: 64
  encoder_depth: 2
  num_heads: 4
  mlp_ratio: 1
  attention_type: performer
  decoder_embed_dim: 64
  decoder_num_modes: 9
  decoder_hidden_dim: 256
  model_params: 409,329

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4559
  val_MR: 0.9609
  val_brier-minFDE6: 40.8212
  val_minADE1: 20.4593
  val_minADE6: 20.4572
  val_minFDE1: 40.1428
  val_minFDE6: 40.1306

Epoch 1:
  train/loss: 9.1782
  train/loss_step: 9.1782
  train/reg_loss: 5.4219
  train/reg_loss_step: 5.4219
  train/cls_loss: 0.8392
  train/cls_loss_step: 0.8392
  train/others_reg_loss: 2.9171
  train/others_reg_loss_step: 2.9171
  val/reg_loss: 6.1711
  val_MR: 0.9607
  val_brier-minFDE6: 25.7410
  val_minADE1: 12.7014
  val_minADE6: 12.2077
  val_minFDE1: 26.0322
  val_minFDE6: 25.4865

Epoch 2:
  train/loss: 6.6690
  train/loss_step: 6.6690
  train/reg_loss: 1.4084
  train/reg_loss_step: 1.4084
  train/cls_loss: 1.6905
  train/cls_loss_step: 1.6905
  train/others_reg_loss: 3.5701
  train/others_reg_loss_step: 3.5701
  val/reg_loss: 1.5335
  val_MR: 0.6775
  val_brier-minFDE6: 7.6367
  val_minADE1: 6.5218
  val_minADE6: 3.2342
  val_minFDE1: 13.1553
  val_minFDE6: 7.0460
  train/loss_epoch: 13.5759
  train/reg_loss_epoch: 8.5130
  train/cls_loss_epoch: 1.1740
  train/others_reg_loss_epoch: 3.8889

Epoch 3:
  train/loss: 6.9598
  train/loss_step: 6.9598
  train/reg_loss: 1.4960
  train/reg_loss_step: 1.4960
  train/cls_loss: 2.0675
  train/cls_loss_step: 2.0675
  train/others_reg_loss: 3.3964
  train/others_reg_loss_step: 3.3964
  val/reg_loss: 1.1494
  val_MR: 0.6226
  val_brier-minFDE6: 6.1021
  val_minADE1: 5.6576
  val_minADE6: 2.6362
  val_minFDE1: 12.5136
  val_minFDE6: 5.4150
  train/loss_epoch: 8.2184
  train/reg_loss_epoch: 3.0602
  train/cls_loss_epoch: 1.3279
  train/others_reg_loss_epoch: 3.8303

Epoch 4:
  train/loss: 5.5442
  train/loss_step: 5.5442
  train/reg_loss: 1.2269
  train/reg_loss_step: 1.2269
  train/cls_loss: 2.2696
  train/cls_loss_step: 2.2696
  train/others_reg_loss: 2.0477
  train/others_reg_loss_step: 2.0477
  val/reg_loss: 1.1101
  val_MR: 0.6140
  val_brier-minFDE6: 7.0719
  val_minADE1: 9.0606
  val_minADE6: 2.9309
  val_minFDE1: 18.9020
  val_minFDE6: 6.3592
  train/loss_epoch: 6.9181
  train/reg_loss_epoch: 1.4149
  train/cls_loss_epoch: 1.9611
  train/others_reg_loss_epoch: 3.5421

Epoch 5:
  train/loss: 5.1667
  train/loss_step: 5.1667
  train/reg_loss: 1.2973
  train/reg_loss_step: 1.2973
  train/cls_loss: 2.2121
  train/cls_loss_step: 2.2121
  train/others_reg_loss: 1.6573
  train/others_reg_loss_step: 1.6573
  val/reg_loss: 1.1470
  val_MR: 0.7212
  val_brier-minFDE6: 9.1259
  val_minADE1: 6.8769
  val_minADE6: 3.8678
  val_minFDE1: 14.9865
  val_minFDE6: 8.4222
  train/loss_epoch: 5.9503
  train/reg_loss_epoch: 1.1585
  train/cls_loss_epoch: 2.1797
  train/others_reg_loss_epoch: 2.6121

Epoch 6:
  train/loss: 4.5445
  train/loss_step: 4.5445
  train/reg_loss: 0.8268
  train/reg_loss_step: 0.8268
  train/cls_loss: 2.1161
  train/cls_loss_step: 2.1161
  train/others_reg_loss: 1.6017
  train/others_reg_loss_step: 1.6017
  val/reg_loss: 1.0215
  val_MR: 0.5206
  val_brier-minFDE6: 6.2154
  val_minADE1: 4.2932
  val_minADE6: 2.5328
  val_minFDE1: 9.9605
  val_minFDE6: 5.5238
  train/loss_epoch: 5.3435
  train/reg_loss_epoch: 1.0396
  train/cls_loss_epoch: 2.1728
  train/others_reg_loss_epoch: 2.1311

Epoch 7:
  train/loss: 5.2034
  train/loss_step: 5.2034
  train/reg_loss: 1.4302
  train/reg_loss_step: 1.4302
  train/cls_loss: 2.1677
  train/cls_loss_step: 2.1677
  train/others_reg_loss: 1.6055
  train/others_reg_loss_step: 1.6055
  val/reg_loss: 1.0130
  val_MR: 0.6390
  val_brier-minFDE6: 6.7305
  val_minADE1: 4.8499
  val_minADE6: 2.6058
  val_minFDE1: 12.2858
  val_minFDE6: 6.0302
  train/loss_epoch: 5.0771
  train/reg_loss_epoch: 1.0482
  train/cls_loss_epoch: 2.1543
  train/others_reg_loss_epoch: 1.8745

Epoch 8:
  train/loss: 4.4954
  train/loss_step: 4.4954
  train/reg_loss: 0.9369
  train/reg_loss_step: 0.9369
  train/cls_loss: 2.0838
  train/cls_loss_step: 2.0838
  train/others_reg_loss: 1.4747
  train/others_reg_loss_step: 1.4747
  val/reg_loss: 1.0418
  val_MR: 0.5675
  val_brier-minFDE6: 6.3230
  val_minADE1: 4.9240
  val_minADE6: 2.6160
  val_minFDE1: 11.3748
  val_minFDE6: 5.6325
  train/loss_epoch: 4.9655
  train/reg_loss_epoch: 1.0327
  train/cls_loss_epoch: 2.1659
  train/others_reg_loss_epoch: 1.7669

Epoch 9:
  train/loss: 5.2148
  train/loss_step: 5.2148
  train/reg_loss: 1.2630
  train/reg_loss_step: 1.2630
  train/cls_loss: 2.4056
  train/cls_loss_step: 2.4056
  train/others_reg_loss: 1.5462
  train/others_reg_loss_step: 1.5462
  val/reg_loss: 1.0056
  val_MR: 0.6180
  val_brier-minFDE6: 7.3336
  val_minADE1: 6.3469
  val_minADE6: 2.8593
  val_minFDE1: 16.1194
  val_minFDE6: 6.6235
  train/loss_epoch: 4.8789
  train/reg_loss_epoch: 1.0552
  train/cls_loss_epoch: 2.1756
  train/others_reg_loss_epoch: 1.6480

Epoch 10:
  train/loss: 4.6124
  train/loss_step: 4.6124
  train/reg_loss: 0.9574
  train/reg_loss_step: 0.9574
  train/cls_loss: 2.1743
  train/cls_loss_step: 2.1743
  train/others_reg_loss: 1.4807
  train/others_reg_loss_step: 1.4807
  val/reg_loss: 0.8943
  val_MR: 0.5180
  val_brier-minFDE6: 5.7842
  val_minADE1: 4.2772
  val_minADE6: 2.2640
  val_minFDE1: 10.4552
  val_minFDE6: 5.0956
  train/loss_epoch: 4.7096
  train/reg_loss_epoch: 1.0287
  train/cls_loss_epoch: 2.1538
  train/others_reg_loss_epoch: 1.5272

Epoch 11:
  train/loss: 4.3957
  train/loss_step: 4.3957
  train/reg_loss: 0.8986
  train/reg_loss_step: 0.8986
  train/cls_loss: 2.0854
  train/cls_loss_step: 2.0854
  train/others_reg_loss: 1.4117
  train/others_reg_loss_step: 1.4117
  val/reg_loss: 0.8660
  val_MR: 0.5697
  val_brier-minFDE6: 6.3468
  val_minADE1: 4.4026
  val_minADE6: 2.4767
  val_minFDE1: 10.7207
  val_minFDE6: 5.6471
  train/loss_epoch: 4.7130
  train/reg_loss_epoch: 1.0118
  train/cls_loss_epoch: 2.1787
  train/others_reg_loss_epoch: 1.5225

Epoch 12:
  train/loss: 4.0392
  train/loss_step: 4.0392
  train/reg_loss: 0.8196
  train/reg_loss_step: 0.8196
  train/cls_loss: 2.1679
  train/cls_loss_step: 2.1679
  train/others_reg_loss: 1.0516
  train/others_reg_loss_step: 1.0516
  val/reg_loss: 0.7974
  val_MR: 0.5915
  val_brier-minFDE6: 5.9027
  val_minADE1: 4.8057
  val_minADE6: 2.3128
  val_minFDE1: 11.3425
  val_minFDE6: 5.2044
  train/loss_epoch: 4.6294
  train/reg_loss_epoch: 1.0120
  train/cls_loss_epoch: 2.1796
  train/others_reg_loss_epoch: 1.4378

Epoch 13:
  train/loss: 3.6669
  train/loss_step: 3.6669
  train/reg_loss: 0.5986
  train/reg_loss_step: 0.5986
  train/cls_loss: 2.0820
  train/cls_loss_step: 2.0820
  train/others_reg_loss: 0.9862
  train/others_reg_loss_step: 0.9862
  val/reg_loss: 0.7582
  val_MR: 0.6344
  val_brier-minFDE6: 5.3684
  val_minADE1: 4.8737
  val_minADE6: 2.1575
  val_minFDE1: 11.7153
  val_minFDE6: 4.6720
  train/loss_epoch: 4.4541
  train/reg_loss_epoch: 0.9345
  train/cls_loss_epoch: 2.1684
  train/others_reg_loss_epoch: 1.3512

Epoch 14:
  train/loss: 3.9662
  train/loss_step: 3.9662
  train/reg_loss: 0.7563
  train/reg_loss_step: 0.7563
  train/cls_loss: 2.0745
  train/cls_loss_step: 2.0745
  train/others_reg_loss: 1.1354
  train/others_reg_loss_step: 1.1354
  val/reg_loss: 0.6828
  val_MR: 0.5615
  val_brier-minFDE6: 4.8434
  val_minADE1: 3.9591
  val_minADE6: 2.0758
  val_minFDE1: 9.1457
  val_minFDE6: 4.1611
  train/loss_epoch: 4.2307
  train/reg_loss_epoch: 0.8233
  train/cls_loss_epoch: 2.1205
  train/others_reg_loss_epoch: 1.2869

Epoch 15:
  train/loss: 3.5464
  train/loss_step: 3.5464
  train/reg_loss: 0.5184
  train/reg_loss_step: 0.5184
  train/cls_loss: 2.0207
  train/cls_loss_step: 2.0207
  train/others_reg_loss: 1.0073
  train/others_reg_loss_step: 1.0073
  val/reg_loss: 0.5674
  val_MR: 0.5250
  val_brier-minFDE6: 4.1615
  val_minADE1: 3.5016
  val_minADE6: 1.6607
  val_minFDE1: 8.5063
  val_minFDE6: 3.4819
  train/loss_epoch: 4.0414
  train/reg_loss_epoch: 0.7095
  train/cls_loss_epoch: 2.1239
  train/others_reg_loss_epoch: 1.2080

Epoch 16:
  train/loss: 3.2424
  train/loss_step: 3.2424
  train/reg_loss: 0.4526
  train/reg_loss_step: 0.4526
  train/cls_loss: 1.9384
  train/cls_loss_step: 1.9384
  train/others_reg_loss: 0.8514
  train/others_reg_loss_step: 0.8514
  val/reg_loss: 0.5462
  val_MR: 0.5323
  val_brier-minFDE6: 4.2489
  val_minADE1: 3.8198
  val_minADE6: 1.6599
  val_minFDE1: 9.5545
  val_minFDE6: 3.5746
  train/loss_epoch: 3.7986
  train/reg_loss_epoch: 0.6274
  train/cls_loss_epoch: 2.0815
  train/others_reg_loss_epoch: 1.0896

Epoch 17:
  train/loss: 3.5085
  train/loss_step: 3.5085
  train/reg_loss: 0.4733
  train/reg_loss_step: 0.4733
  train/cls_loss: 2.1102
  train/cls_loss_step: 2.1102
  train/others_reg_loss: 0.9250
  train/others_reg_loss_step: 0.9250
  val/reg_loss: 0.5550
  val_MR: 0.4844
  val_brier-minFDE6: 4.2562
  val_minADE1: 4.0884
  val_minADE6: 1.6729
  val_minFDE1: 9.9957
  val_minFDE6: 3.5654
  train/loss_epoch: 3.5597
  train/reg_loss_epoch: 0.5757
  train/cls_loss_epoch: 2.0437
  train/others_reg_loss_epoch: 0.9403

Epoch 18:
  train/loss: 3.2859
  train/loss_step: 3.2859
  train/reg_loss: 0.5426
  train/reg_loss_step: 0.5426
  train/cls_loss: 1.9081
  train/cls_loss_step: 1.9081
  train/others_reg_loss: 0.8352
  train/others_reg_loss_step: 0.8352
  val/reg_loss: 0.4984
  val_MR: 0.4289
  val_brier-minFDE6: 3.8145
  val_minADE1: 3.2859
  val_minADE6: 1.4827
  val_minFDE1: 8.2903
  val_minFDE6: 3.1555
  train/loss_epoch: 3.4546
  train/reg_loss_epoch: 0.5430
  train/cls_loss_epoch: 2.0318
  train/others_reg_loss_epoch: 0.8798

Epoch 19:
  train/loss: 2.9349
  train/loss_step: 2.9349
  train/reg_loss: 0.3404
  train/reg_loss_step: 0.3404
  train/cls_loss: 1.8736
  train/cls_loss_step: 1.8736
  train/others_reg_loss: 0.7209
  train/others_reg_loss_step: 0.7209
  val/reg_loss: 0.4848
  val_MR: 0.4241
  val_brier-minFDE6: 3.7520
  val_minADE1: 3.3736
  val_minADE6: 1.4695
  val_minFDE1: 8.4128
  val_minFDE6: 3.0894
  train/loss_epoch: 3.3782
  train/reg_loss_epoch: 0.5195
  train/cls_loss_epoch: 2.0121
  train/others_reg_loss_epoch: 0.8466

Epoch 20:
  train/loss: 3.1490
  train/loss_step: 3.1490
  train/reg_loss: 0.4785
  train/reg_loss_step: 0.4785
  train/cls_loss: 2.0404
  train/cls_loss_step: 2.0404
  train/others_reg_loss: 0.6301
  train/others_reg_loss_step: 0.6301
  val/reg_loss: 0.4624
  val_MR: 0.4129
  val_brier-minFDE6: 3.7259
  val_minADE1: 3.1456
  val_minADE6: 1.4234
  val_minFDE1: 7.9959
  val_minFDE6: 3.0636
  train/loss_epoch: 3.2823
  train/reg_loss_epoch: 0.4844
  train/cls_loss_epoch: 1.9880
  train/others_reg_loss_epoch: 0.8099

FINAL VALIDATION RESULTS:
  train/loss: 3.2626
  train/loss_step: 3.1490
  train/reg_loss: 0.4809
  train/reg_loss_step: 0.4785
  train/cls_loss: 1.9839
  train/cls_loss_step: 2.0404
  train/others_reg_loss: 0.7978
  train/others_reg_loss_step: 0.6301
  val/reg_loss: 0.4624
  val_MR: 0.4129
  val_brier-minFDE6: 3.7259
  val_minADE1: 3.1456
  val_minADE6: 1.4234
  val_minFDE1: 7.9959
  val_minFDE6: 3.0636
  train/loss_epoch: 3.2626
  train/reg_loss_epoch: 0.4809
  train/cls_loss_epoch: 1.9839
  train/others_reg_loss_epoch: 0.7978

================================================================================

Experiment 13
--------------------------------------------------
HYPERPARAMETERS:
  dim: 64
  encoder_depth: 3
  num_heads: 4
  mlp_ratio: 2
  attention_type: performer
  decoder_embed_dim: 32
  decoder_num_modes: 9
  decoder_hidden_dim: 256
  model_params: 473,873

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4387
  val_MR: 0.9609
  val_brier-minFDE6: 40.6706
  val_minADE1: 20.4479
  val_minADE6: 20.4261
  val_minFDE1: 40.0590
  val_minFDE6: 39.9689

Epoch 1:
  train/loss: 13.3775
  train/loss_step: 13.3775
  train/reg_loss: 7.6442
  train/reg_loss_step: 7.6442
  train/cls_loss: 0.8757
  train/cls_loss_step: 0.8757
  train/others_reg_loss: 4.8576
  train/others_reg_loss_step: 4.8576
  val/reg_loss: 6.3594
  val_MR: 0.9635
  val_brier-minFDE6: 25.5719
  val_minADE1: 12.7534
  val_minADE6: 12.4915
  val_minFDE1: 25.6268
  val_minFDE6: 25.2887

Epoch 2:
  train/loss: 7.0755
  train/loss_step: 7.0755
  train/reg_loss: 2.3288
  train/reg_loss_step: 2.3288
  train/cls_loss: 1.2845
  train/cls_loss_step: 1.2845
  train/others_reg_loss: 3.4623
  train/others_reg_loss_step: 3.4623
  val/reg_loss: 2.4012
  val_MR: 0.7921
  val_brier-minFDE6: 10.5297
  val_minADE1: 5.6883
  val_minADE6: 4.7985
  val_minFDE1: 12.0776
  val_minFDE6: 10.1732
  train/loss_epoch: 13.9669
  train/reg_loss_epoch: 8.7012
  train/cls_loss_epoch: 1.3544
  train/others_reg_loss_epoch: 3.9113

Epoch 3:
  train/loss: 6.3581
  train/loss_step: 6.3581
  train/reg_loss: 1.9518
  train/reg_loss_step: 1.9518
  train/cls_loss: 1.3550
  train/cls_loss_step: 1.3550
  train/others_reg_loss: 3.0513
  train/others_reg_loss_step: 3.0513
  val/reg_loss: 2.6152
  val_MR: 0.8359
  val_brier-minFDE6: 11.7993
  val_minADE1: 7.1745
  val_minADE6: 5.2266
  val_minFDE1: 15.3159
  val_minFDE6: 11.4031
  train/loss_epoch: 8.4763
  train/reg_loss_epoch: 3.5351
  train/cls_loss_epoch: 1.0787
  train/others_reg_loss_epoch: 3.8624

Epoch 4:
  train/loss: 6.7009
  train/loss_step: 6.7009
  train/reg_loss: 1.7813
  train/reg_loss_step: 1.7813
  train/cls_loss: 1.5672
  train/cls_loss_step: 1.5672
  train/others_reg_loss: 3.3524
  train/others_reg_loss_step: 3.3524
  val/reg_loss: 1.4351
  val_MR: 0.6236
  val_brier-minFDE6: 7.3334
  val_minADE1: 4.9199
  val_minADE6: 3.0396
  val_minFDE1: 10.9729
  val_minFDE6: 6.7471
  train/loss_epoch: 7.2880
  train/reg_loss_epoch: 2.2402
  train/cls_loss_epoch: 1.3215
  train/others_reg_loss_epoch: 3.7263

Epoch 5:
  train/loss: 5.5601
  train/loss_step: 5.5601
  train/reg_loss: 1.0602
  train/reg_loss_step: 1.0602
  train/cls_loss: 2.1849
  train/cls_loss_step: 2.1849
  train/others_reg_loss: 2.3150
  train/others_reg_loss_step: 2.3150
  val/reg_loss: 1.7814
  val_MR: 0.7590
  val_brier-minFDE6: 8.8183
  val_minADE1: 4.9932
  val_minADE6: 3.7162
  val_minFDE1: 11.1712
  val_minFDE6: 8.1881
  train/loss_epoch: 6.4895
  train/reg_loss_epoch: 1.6647
  train/cls_loss_epoch: 1.6207
  train/others_reg_loss_epoch: 3.2041

Epoch 6:
  train/loss: 4.8023
  train/loss_step: 4.8023
  train/reg_loss: 0.9838
  train/reg_loss_step: 0.9838
  train/cls_loss: 2.3375
  train/cls_loss_step: 2.3375
  train/others_reg_loss: 1.4810
  train/others_reg_loss_step: 1.4810
  val/reg_loss: 1.1263
  val_MR: 0.5639
  val_brier-minFDE6: 6.7516
  val_minADE1: 4.2101
  val_minADE6: 2.8216
  val_minFDE1: 9.8951
  val_minFDE6: 6.0640
  train/loss_epoch: 5.7587
  train/reg_loss_epoch: 1.3773
  train/cls_loss_epoch: 1.9130
  train/others_reg_loss_epoch: 2.4683

Epoch 7:
  train/loss: 6.0519
  train/loss_step: 6.0519
  train/reg_loss: 1.5157
  train/reg_loss_step: 1.5157
  train/cls_loss: 2.1956
  train/cls_loss_step: 2.1956
  train/others_reg_loss: 2.3406
  train/others_reg_loss_step: 2.3406
  val/reg_loss: 1.0997
  val_MR: 0.5527
  val_brier-minFDE6: 6.1303
  val_minADE1: 5.1651
  val_minADE6: 2.6172
  val_minFDE1: 12.1261
  val_minFDE6: 5.4370
  train/loss_epoch: 5.3987
  train/reg_loss_epoch: 1.1962
  train/cls_loss_epoch: 2.1674
  train/others_reg_loss_epoch: 2.0350

Epoch 8:
  train/loss: 4.2312
  train/loss_step: 4.2312
  train/reg_loss: 0.6961
  train/reg_loss_step: 0.6961
  train/cls_loss: 2.2463
  train/cls_loss_step: 2.2463
  train/others_reg_loss: 1.2888
  train/others_reg_loss_step: 1.2888
  val/reg_loss: 1.0006
  val_MR: 0.5757
  val_brier-minFDE6: 7.0513
  val_minADE1: 7.0301
  val_minADE6: 2.9166
  val_minFDE1: 15.6793
  val_minFDE6: 6.3459
  train/loss_epoch: 5.0917
  train/reg_loss_epoch: 1.1452
  train/cls_loss_epoch: 2.2038
  train/others_reg_loss_epoch: 1.7427

Epoch 9:
  train/loss: 4.4972
  train/loss_step: 4.4972
  train/reg_loss: 0.9040
  train/reg_loss_step: 0.9040
  train/cls_loss: 2.0944
  train/cls_loss_step: 2.0944
  train/others_reg_loss: 1.4988
  train/others_reg_loss_step: 1.4988
  val/reg_loss: 0.9973
  val_MR: 0.5587
  val_brier-minFDE6: 6.3639
  val_minADE1: 4.6230
  val_minADE6: 2.5523
  val_minFDE1: 10.9864
  val_minFDE6: 5.6708
  train/loss_epoch: 4.9173
  train/reg_loss_epoch: 1.1111
  train/cls_loss_epoch: 2.1973
  train/others_reg_loss_epoch: 1.6090

Epoch 10:
  train/loss: 4.3201
  train/loss_step: 4.3201
  train/reg_loss: 0.8246
  train/reg_loss_step: 0.8246
  train/cls_loss: 2.1244
  train/cls_loss_step: 2.1244
  train/others_reg_loss: 1.3712
  train/others_reg_loss_step: 1.3712
  val/reg_loss: 1.0096
  val_MR: 0.6026
  val_brier-minFDE6: 6.9415
  val_minADE1: 5.1561
  val_minADE6: 2.6531
  val_minFDE1: 13.2066
  val_minFDE6: 6.2395
  train/loss_epoch: 4.8287
  train/reg_loss_epoch: 1.1102
  train/cls_loss_epoch: 2.1899
  train/others_reg_loss_epoch: 1.5286

Epoch 11:
  train/loss: 4.6249
  train/loss_step: 4.6249
  train/reg_loss: 1.1072
  train/reg_loss_step: 1.1072
  train/cls_loss: 2.0680
  train/cls_loss_step: 2.0680
  train/others_reg_loss: 1.4498
  train/others_reg_loss_step: 1.4498
  val/reg_loss: 0.9615
  val_MR: 0.5675
  val_brier-minFDE6: 6.0990
  val_minADE1: 4.4252
  val_minADE6: 2.3858
  val_minFDE1: 10.5780
  val_minFDE6: 5.4102
  train/loss_epoch: 4.6762
  train/reg_loss_epoch: 1.0670
  train/cls_loss_epoch: 2.1712
  train/others_reg_loss_epoch: 1.4380

Epoch 12:
  train/loss: 5.1458
  train/loss_step: 5.1458
  train/reg_loss: 1.3355
  train/reg_loss_step: 1.3355
  train/cls_loss: 2.4821
  train/cls_loss_step: 2.4821
  train/others_reg_loss: 1.3282
  train/others_reg_loss_step: 1.3282
  val/reg_loss: 1.2248
  val_MR: 0.7163
  val_brier-minFDE6: 10.8767
  val_minADE1: 7.1828
  val_minADE6: 4.2420
  val_minFDE1: 17.0788
  val_minFDE6: 10.1553
  train/loss_epoch: 4.5757
  train/reg_loss_epoch: 1.0445
  train/cls_loss_epoch: 2.1555
  train/others_reg_loss_epoch: 1.3757

Epoch 13:
  train/loss: 4.5657
  train/loss_step: 4.5657
  train/reg_loss: 1.0943
  train/reg_loss_step: 1.0943
  train/cls_loss: 2.1363
  train/cls_loss_step: 2.1363
  train/others_reg_loss: 1.3352
  train/others_reg_loss_step: 1.3352
  val/reg_loss: 0.9621
  val_MR: 0.5505
  val_brier-minFDE6: 6.5352
  val_minADE1: 4.7464
  val_minADE6: 2.6846
  val_minFDE1: 11.3546
  val_minFDE6: 5.8432
  train/loss_epoch: 4.5039
  train/reg_loss_epoch: 1.0066
  train/cls_loss_epoch: 2.1411
  train/others_reg_loss_epoch: 1.3562

Epoch 14:
  train/loss: 4.0289
  train/loss_step: 4.0289
  train/reg_loss: 0.8776
  train/reg_loss_step: 0.8776
  train/cls_loss: 2.0498
  train/cls_loss_step: 2.0498
  train/others_reg_loss: 1.1015
  train/others_reg_loss_step: 1.1015
  val/reg_loss: 0.8298
  val_MR: 0.4718
  val_brier-minFDE6: 5.7818
  val_minADE1: 3.7841
  val_minADE6: 2.2417
  val_minFDE1: 9.2705
  val_minFDE6: 5.0888
  train/loss_epoch: 4.4645
  train/reg_loss_epoch: 0.9990
  train/cls_loss_epoch: 2.1688
  train/others_reg_loss_epoch: 1.2967

Epoch 15:
  train/loss: 3.8121
  train/loss_step: 3.8121
  train/reg_loss: 0.8854
  train/reg_loss_step: 0.8854
  train/cls_loss: 2.1104
  train/cls_loss_step: 2.1104
  train/others_reg_loss: 0.8163
  train/others_reg_loss_step: 0.8163
  val/reg_loss: 0.7356
  val_MR: 0.4922
  val_brier-minFDE6: 5.4170
  val_minADE1: 3.8142
  val_minADE6: 2.0384
  val_minFDE1: 9.5993
  val_minFDE6: 4.7238
  train/loss_epoch: 4.1410
  train/reg_loss_epoch: 0.8543
  train/cls_loss_epoch: 2.1173
  train/others_reg_loss_epoch: 1.1695

Epoch 16:
  train/loss: 3.5202
  train/loss_step: 3.5202
  train/reg_loss: 0.6965
  train/reg_loss_step: 0.6965
  train/cls_loss: 2.0158
  train/cls_loss_step: 2.0158
  train/others_reg_loss: 0.8079
  train/others_reg_loss_step: 0.8079
  val/reg_loss: 0.6243
  val_MR: 0.4291
  val_brier-minFDE6: 4.6284
  val_minADE1: 3.4142
  val_minADE6: 1.7107
  val_minFDE1: 8.5728
  val_minFDE6: 3.9372
  train/loss_epoch: 3.8152
  train/reg_loss_epoch: 0.7897
  train/cls_loss_epoch: 2.0629
  train/others_reg_loss_epoch: 0.9626

Epoch 17:
  train/loss: 3.3172
  train/loss_step: 3.3172
  train/reg_loss: 0.5557
  train/reg_loss_step: 0.5557
  train/cls_loss: 2.0394
  train/cls_loss_step: 2.0394
  train/others_reg_loss: 0.7221
  train/others_reg_loss_step: 0.7221
  val/reg_loss: 0.5547
  val_MR: 0.4075
  val_brier-minFDE6: 4.4369
  val_minADE1: 3.1592
  val_minADE6: 1.6454
  val_minFDE1: 7.9830
  val_minFDE6: 3.7520
  train/loss_epoch: 3.6235
  train/reg_loss_epoch: 0.7009
  train/cls_loss_epoch: 2.0709
  train/others_reg_loss_epoch: 0.8516

Epoch 18:
  train/loss: 3.4745
  train/loss_step: 3.4745
  train/reg_loss: 0.7264
  train/reg_loss_step: 0.7264
  train/cls_loss: 2.0510
  train/cls_loss_step: 2.0510
  train/others_reg_loss: 0.6970
  train/others_reg_loss_step: 0.6970
  val/reg_loss: 0.5523
  val_MR: 0.4281
  val_brier-minFDE6: 4.2600
  val_minADE1: 3.2456
  val_minADE6: 1.6156
  val_minFDE1: 7.9932
  val_minFDE6: 3.5689
  train/loss_epoch: 3.4782
  train/reg_loss_epoch: 0.6197
  train/cls_loss_epoch: 2.0613
  train/others_reg_loss_epoch: 0.7971

Epoch 19:
  train/loss: 3.5164
  train/loss_step: 3.5164
  train/reg_loss: 0.6212
  train/reg_loss_step: 0.6212
  train/cls_loss: 2.0533
  train/cls_loss_step: 2.0533
  train/others_reg_loss: 0.8420
  train/others_reg_loss_step: 0.8420
  val/reg_loss: 0.5099
  val_MR: 0.3958
  val_brier-minFDE6: 4.0609
  val_minADE1: 2.9989
  val_minADE6: 1.5109
  val_minFDE1: 7.6188
  val_minFDE6: 3.3802
  train/loss_epoch: 3.3589
  train/reg_loss_epoch: 0.5546
  train/cls_loss_epoch: 2.0466
  train/others_reg_loss_epoch: 0.7578

Epoch 20:
  train/loss: 2.8779
  train/loss_step: 2.8779
  train/reg_loss: 0.2868
  train/reg_loss_step: 0.2868
  train/cls_loss: 1.9904
  train/cls_loss_step: 1.9904
  train/others_reg_loss: 0.6007
  train/others_reg_loss_step: 0.6007
  val/reg_loss: 0.5048
  val_MR: 0.3890
  val_brier-minFDE6: 4.1082
  val_minADE1: 2.9226
  val_minADE6: 1.5258
  val_minFDE1: 7.4439
  val_minFDE6: 3.4294
  train/loss_epoch: 3.3098
  train/reg_loss_epoch: 0.5313
  train/cls_loss_epoch: 2.0411
  train/others_reg_loss_epoch: 0.7373

FINAL VALIDATION RESULTS:
  train/loss: 3.2909
  train/loss_step: 2.8779
  train/reg_loss: 0.5194
  train/reg_loss_step: 0.2868
  train/cls_loss: 2.0384
  train/cls_loss_step: 1.9904
  train/others_reg_loss: 0.7331
  train/others_reg_loss_step: 0.6007
  val/reg_loss: 0.5048
  val_MR: 0.3890
  val_brier-minFDE6: 4.1082
  val_minADE1: 2.9226
  val_minADE6: 1.5258
  val_minFDE1: 7.4439
  val_minFDE6: 3.4294
  train/loss_epoch: 3.2909
  train/reg_loss_epoch: 0.5194
  train/cls_loss_epoch: 2.0384
  train/others_reg_loss_epoch: 0.7331

================================================================================

Experiment 14
--------------------------------------------------
HYPERPARAMETERS:
  dim: 96
  encoder_depth: 5
  num_heads: 6
  mlp_ratio: 2
  attention_type: performer
  decoder_embed_dim: 32
  decoder_num_modes: 9
  decoder_hidden_dim: 96
  model_params: 1,007,025

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4162
  val_MR: 0.9609
  val_brier-minFDE6: 41.0854
  val_minADE1: 20.3831
  val_minADE6: 20.3792
  val_minFDE1: 40.4568
  val_minFDE6: 40.3859

Epoch 1:
  train/loss: 11.0513
  train/loss_step: 11.0513
  train/reg_loss: 5.1725
  train/reg_loss_step: 5.1725
  train/cls_loss: 1.8748
  train/cls_loss_step: 1.8748
  train/others_reg_loss: 4.0041
  train/others_reg_loss_step: 4.0041
  val/reg_loss: 5.6183
  val_MR: 0.9271
  val_brier-minFDE6: 26.9187
  val_minADE1: 11.1491
  val_minADE6: 10.9928
  val_minFDE1: 26.4863
  val_minFDE6: 26.3530

Epoch 2:
  train/loss: 8.1155
  train/loss_step: 8.1155
  train/reg_loss: 3.0143
  train/reg_loss_step: 3.0143
  train/cls_loss: 1.1351
  train/cls_loss_step: 1.1351
  train/others_reg_loss: 3.9661
  train/others_reg_loss_step: 3.9661
  val/reg_loss: 2.1460
  val_MR: 0.8073
  val_brier-minFDE6: 10.0092
  val_minADE1: 5.0383
  val_minADE6: 4.3308
  val_minFDE1: 11.0130
  val_minFDE6: 9.6483
  train/loss_epoch: 14.0748
  train/reg_loss_epoch: 8.5635
  train/cls_loss_epoch: 1.6360
  train/others_reg_loss_epoch: 3.8753

Epoch 3:
  train/loss: 5.4586
  train/loss_step: 5.4586
  train/reg_loss: 1.7513
  train/reg_loss_step: 1.7513
  train/cls_loss: 1.3172
  train/cls_loss_step: 1.3172
  train/others_reg_loss: 2.3900
  train/others_reg_loss_step: 2.3900
  val/reg_loss: 2.1944
  val_MR: 0.8165
  val_brier-minFDE6: 10.2212
  val_minADE1: 5.6773
  val_minADE6: 4.4369
  val_minFDE1: 12.1404
  val_minFDE6: 9.8448
  train/loss_epoch: 8.5332
  train/reg_loss_epoch: 3.4470
  train/cls_loss_epoch: 1.2045
  train/others_reg_loss_epoch: 3.8818

Epoch 4:
  train/loss: 5.9563
  train/loss_step: 5.9563
  train/reg_loss: 2.0865
  train/reg_loss_step: 2.0865
  train/cls_loss: 1.4382
  train/cls_loss_step: 1.4382
  train/others_reg_loss: 2.4317
  train/others_reg_loss_step: 2.4317
  val/reg_loss: 2.3639
  val_MR: 0.7508
  val_brier-minFDE6: 10.5501
  val_minADE1: 8.5704
  val_minADE6: 4.7174
  val_minFDE1: 16.5009
  val_minFDE6: 10.0655
  train/loss_epoch: 7.0003
  train/reg_loss_epoch: 2.2001
  train/cls_loss_epoch: 1.2075
  train/others_reg_loss_epoch: 3.5926

Epoch 5:
  train/loss: 5.8706
  train/loss_step: 5.8706
  train/reg_loss: 1.4692
  train/reg_loss_step: 1.4692
  train/cls_loss: 1.9916
  train/cls_loss_step: 1.9916
  train/others_reg_loss: 2.4098
  train/others_reg_loss_step: 2.4098
  val/reg_loss: 1.4223
  val_MR: 0.6611
  val_brier-minFDE6: 7.1026
  val_minADE1: 5.8243
  val_minADE6: 3.0469
  val_minFDE1: 12.2174
  val_minFDE6: 6.4754
  train/loss_epoch: 6.2343
  train/reg_loss_epoch: 1.9437
  train/cls_loss_epoch: 1.4127
  train/others_reg_loss_epoch: 2.8779

Epoch 6:
  train/loss: 4.7963
  train/loss_step: 4.7963
  train/reg_loss: 1.0161
  train/reg_loss_step: 1.0161
  train/cls_loss: 2.2586
  train/cls_loss_step: 2.2586
  train/others_reg_loss: 1.5216
  train/others_reg_loss_step: 1.5216
  val/reg_loss: 1.1300
  val_MR: 0.6492
  val_brier-minFDE6: 6.4422
  val_minADE1: 5.0881
  val_minADE6: 2.7347
  val_minFDE1: 12.2597
  val_minFDE6: 5.7482
  train/loss_epoch: 5.8472
  train/reg_loss_epoch: 1.6904
  train/cls_loss_epoch: 1.7116
  train/others_reg_loss_epoch: 2.4452

Epoch 7:
  train/loss: 4.5669
  train/loss_step: 4.5669
  train/reg_loss: 1.1208
  train/reg_loss_step: 1.1208
  train/cls_loss: 2.0708
  train/cls_loss_step: 2.0708
  train/others_reg_loss: 1.3752
  train/others_reg_loss_step: 1.3752
  val/reg_loss: 1.1569
  val_MR: 0.5927
  val_brier-minFDE6: 6.6859
  val_minADE1: 4.5132
  val_minADE6: 2.9107
  val_minFDE1: 10.3092
  val_minFDE6: 5.9891
  train/loss_epoch: 5.2057
  train/reg_loss_epoch: 1.2853
  train/cls_loss_epoch: 2.0810
  train/others_reg_loss_epoch: 1.8395

Epoch 8:
  train/loss: 4.4730
  train/loss_step: 4.4730
  train/reg_loss: 1.1338
  train/reg_loss_step: 1.1338
  train/cls_loss: 2.1072
  train/cls_loss_step: 2.1072
  train/others_reg_loss: 1.2321
  train/others_reg_loss_step: 1.2321
  val/reg_loss: 1.0210
  val_MR: 0.5849
  val_brier-minFDE6: 6.4360
  val_minADE1: 4.8113
  val_minADE6: 2.5596
  val_minFDE1: 11.7129
  val_minFDE6: 5.7450
  train/loss_epoch: 4.9300
  train/reg_loss_epoch: 1.1713
  train/cls_loss_epoch: 2.2079
  train/others_reg_loss_epoch: 1.5509

Epoch 9:
  train/loss: 4.2338
  train/loss_step: 4.2338
  train/reg_loss: 0.9734
  train/reg_loss_step: 0.9734
  train/cls_loss: 2.0383
  train/cls_loss_step: 2.0383
  train/others_reg_loss: 1.2221
  train/others_reg_loss_step: 1.2221
  val/reg_loss: 1.0310
  val_MR: 0.5483
  val_brier-minFDE6: 6.0855
  val_minADE1: 4.4477
  val_minADE6: 2.4698
  val_minFDE1: 10.5559
  val_minFDE6: 5.4073
  train/loss_epoch: 4.8823
  train/reg_loss_epoch: 1.1515
  train/cls_loss_epoch: 2.2013
  train/others_reg_loss_epoch: 1.5295

Epoch 10:
  train/loss: 4.7810
  train/loss_step: 4.7810
  train/reg_loss: 0.9658
  train/reg_loss_step: 0.9658
  train/cls_loss: 2.1924
  train/cls_loss_step: 2.1924
  train/others_reg_loss: 1.6228
  train/others_reg_loss_step: 1.6228
  val/reg_loss: 1.0130
  val_MR: 0.5435
  val_brier-minFDE6: 6.3253
  val_minADE1: 5.1919
  val_minADE6: 2.5401
  val_minFDE1: 12.1593
  val_minFDE6: 5.6314
  train/loss_epoch: 4.7944
  train/reg_loss_epoch: 1.1152
  train/cls_loss_epoch: 2.1866
  train/others_reg_loss_epoch: 1.4926

Epoch 11:
  train/loss: 4.1449
  train/loss_step: 4.1449
  train/reg_loss: 1.0789
  train/reg_loss_step: 1.0789
  train/cls_loss: 2.0178
  train/cls_loss_step: 2.0178
  train/others_reg_loss: 1.0482
  train/others_reg_loss_step: 1.0482
  val/reg_loss: 1.0684
  val_MR: 0.6206
  val_brier-minFDE6: 7.5086
  val_minADE1: 5.1881
  val_minADE6: 3.2378
  val_minFDE1: 11.8489
  val_minFDE6: 6.8352
  train/loss_epoch: 4.6522
  train/reg_loss_epoch: 1.0814
  train/cls_loss_epoch: 2.1719
  train/others_reg_loss_epoch: 1.3989

Epoch 12:
  train/loss: 4.4596
  train/loss_step: 4.4596
  train/reg_loss: 1.1900
  train/reg_loss_step: 1.1900
  train/cls_loss: 2.0737
  train/cls_loss_step: 2.0737
  train/others_reg_loss: 1.1958
  train/others_reg_loss_step: 1.1958
  val/reg_loss: 1.0581
  val_MR: 0.5461
  val_brier-minFDE6: 6.1502
  val_minADE1: 4.9201
  val_minADE6: 2.5476
  val_minFDE1: 12.3491
  val_minFDE6: 5.4557
  train/loss_epoch: 4.6320
  train/reg_loss_epoch: 1.0962
  train/cls_loss_epoch: 2.1699
  train/others_reg_loss_epoch: 1.3659

Epoch 13:
  train/loss: 4.4877
  train/loss_step: 4.4877
  train/reg_loss: 1.1797
  train/reg_loss_step: 1.1797
  train/cls_loss: 2.0770
  train/cls_loss_step: 2.0770
  train/others_reg_loss: 1.2310
  train/others_reg_loss_step: 1.2310
  val/reg_loss: 0.9958
  val_MR: 0.5903
  val_brier-minFDE6: 6.1599
  val_minADE1: 4.3861
  val_minADE6: 2.3812
  val_minFDE1: 10.6337
  val_minFDE6: 5.4696
  train/loss_epoch: 4.4487
  train/reg_loss_epoch: 1.0234
  train/cls_loss_epoch: 2.1374
  train/others_reg_loss_epoch: 1.2878

Epoch 14:
  train/loss: 4.1524
  train/loss_step: 4.1524
  train/reg_loss: 0.8514
  train/reg_loss_step: 0.8514
  train/cls_loss: 2.2273
  train/cls_loss_step: 2.2273
  train/others_reg_loss: 1.0737
  train/others_reg_loss_step: 1.0737
  val/reg_loss: 0.9697
  val_MR: 0.6184
  val_brier-minFDE6: 7.8070
  val_minADE1: 5.6583
  val_minADE6: 2.9671
  val_minFDE1: 13.9455
  val_minFDE6: 7.1001
  train/loss_epoch: 4.4038
  train/reg_loss_epoch: 1.0014
  train/cls_loss_epoch: 2.1403
  train/others_reg_loss_epoch: 1.2621

Epoch 15:
  train/loss: 3.8196
  train/loss_step: 3.8196
  train/reg_loss: 0.7011
  train/reg_loss_step: 0.7011
  train/cls_loss: 2.0094
  train/cls_loss_step: 2.0094
  train/others_reg_loss: 1.1091
  train/others_reg_loss_step: 1.1091
  val/reg_loss: 0.9520
  val_MR: 0.5559
  val_brier-minFDE6: 6.4698
  val_minADE1: 4.3937
  val_minADE6: 2.5645
  val_minFDE1: 10.6009
  val_minFDE6: 5.7830
  train/loss_epoch: 4.3050
  train/reg_loss_epoch: 0.9758
  train/cls_loss_epoch: 2.1102
  train/others_reg_loss_epoch: 1.2190

Epoch 16:
  train/loss: 4.1245
  train/loss_step: 4.1245
  train/reg_loss: 0.8679
  train/reg_loss_step: 0.8679
  train/cls_loss: 2.0860
  train/cls_loss_step: 2.0860
  train/others_reg_loss: 1.1706
  train/others_reg_loss_step: 1.1706
  val/reg_loss: 0.8387
  val_MR: 0.4625
  val_brier-minFDE6: 5.7881
  val_minADE1: 3.7943
  val_minADE6: 2.2546
  val_minFDE1: 9.2322
  val_minFDE6: 5.1061
  train/loss_epoch: 4.1165
  train/reg_loss_epoch: 0.9090
  train/cls_loss_epoch: 2.0609
  train/others_reg_loss_epoch: 1.1467

Epoch 17:
  train/loss: 3.9061
  train/loss_step: 3.9061
  train/reg_loss: 0.7335
  train/reg_loss_step: 0.7335
  train/cls_loss: 2.1056
  train/cls_loss_step: 2.1056
  train/others_reg_loss: 1.0670
  train/others_reg_loss_step: 1.0670
  val/reg_loss: 0.7574
  val_MR: 0.4449
  val_brier-minFDE6: 5.5063
  val_minADE1: 4.2030
  val_minADE6: 2.0368
  val_minFDE1: 10.7387
  val_minFDE6: 4.8198
  train/loss_epoch: 4.1160
  train/reg_loss_epoch: 0.8948
  train/cls_loss_epoch: 2.0852
  train/others_reg_loss_epoch: 1.1360

Epoch 18:
  train/loss: 3.7973
  train/loss_step: 3.7973
  train/reg_loss: 0.8873
  train/reg_loss_step: 0.8873
  train/cls_loss: 2.0730
  train/cls_loss_step: 2.0730
  train/others_reg_loss: 0.8370
  train/others_reg_loss_step: 0.8370
  val/reg_loss: 0.7090
  val_MR: 0.4501
  val_brier-minFDE6: 5.3371
  val_minADE1: 3.6035
  val_minADE6: 1.9662
  val_minFDE1: 9.1516
  val_minFDE6: 4.6636
  train/loss_epoch: 3.9532
  train/reg_loss_epoch: 0.8149
  train/cls_loss_epoch: 2.0326
  train/others_reg_loss_epoch: 1.1058

Epoch 19:
  train/loss: 3.7519
  train/loss_step: 3.7519
  train/reg_loss: 0.5574
  train/reg_loss_step: 0.5574
  train/cls_loss: 2.0047
  train/cls_loss_step: 2.0047
  train/others_reg_loss: 1.1897
  train/others_reg_loss_step: 1.1897
  val/reg_loss: 0.6441
  val_MR: 0.4251
  val_brier-minFDE6: 4.7441
  val_minADE1: 3.2553
  val_minADE6: 1.7558
  val_minFDE1: 8.3105
  val_minFDE6: 4.0799
  train/loss_epoch: 3.8233
  train/reg_loss_epoch: 0.7426
  train/cls_loss_epoch: 2.0177
  train/others_reg_loss_epoch: 1.0630

Epoch 20:
  train/loss: 3.6012
  train/loss_step: 3.6012
  train/reg_loss: 0.5901
  train/reg_loss_step: 0.5901
  train/cls_loss: 1.9623
  train/cls_loss_step: 1.9623
  train/others_reg_loss: 1.0487
  train/others_reg_loss_step: 1.0487
  val/reg_loss: 0.6195
  val_MR: 0.4034
  val_brier-minFDE6: 4.6240
  val_minADE1: 3.1938
  val_minADE6: 1.7090
  val_minFDE1: 8.1360
  val_minFDE6: 3.9622
  train/loss_epoch: 3.6977
  train/reg_loss_epoch: 0.6617
  train/cls_loss_epoch: 1.9944
  train/others_reg_loss_epoch: 1.0415

FINAL VALIDATION RESULTS:
  train/loss: 3.6101
  train/loss_step: 3.6012
  train/reg_loss: 0.6461
  train/reg_loss_step: 0.5901
  train/cls_loss: 1.9671
  train/cls_loss_step: 1.9623
  train/others_reg_loss: 0.9970
  train/others_reg_loss_step: 1.0487
  val/reg_loss: 0.6195
  val_MR: 0.4034
  val_brier-minFDE6: 4.6240
  val_minADE1: 3.1938
  val_minADE6: 1.7090
  val_minFDE1: 8.1360
  val_minFDE6: 3.9622
  train/loss_epoch: 3.6101
  train/reg_loss_epoch: 0.6461
  train/cls_loss_epoch: 1.9671
  train/others_reg_loss_epoch: 0.9970

================================================================================

Experiment 15
--------------------------------------------------
HYPERPARAMETERS:
  dim: 48
  encoder_depth: 1
  num_heads: 4
  mlp_ratio: 6
  attention_type: standard
  decoder_embed_dim: 48
  decoder_num_modes: 6
  decoder_hidden_dim: 96
  model_params: 328,289

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4805
  val_MR: 0.9609
  val_brier-minFDE6: 41.3085
  val_minADE1: 20.5014
  val_minADE6: 20.4943
  val_minFDE1: 40.6914
  val_minFDE6: 40.6165

Epoch 1:
  train/loss: 10.3699
  train/loss_step: 10.3699
  train/reg_loss: 6.2278
  train/reg_loss_step: 6.2278
  train/cls_loss: 0.8481
  train/cls_loss_step: 0.8481
  train/others_reg_loss: 3.2940
  train/others_reg_loss_step: 3.2940
  val/reg_loss: 6.7790
  val_MR: 0.9651
  val_brier-minFDE6: 28.2317
  val_minADE1: 13.7983
  val_minADE6: 13.3945
  val_minFDE1: 28.3600
  val_minFDE6: 27.9634

Epoch 2:
  train/loss: 7.1320
  train/loss_step: 7.1320
  train/reg_loss: 1.9013
  train/reg_loss_step: 1.9013
  train/cls_loss: 1.5258
  train/cls_loss_step: 1.5258
  train/others_reg_loss: 3.7049
  train/others_reg_loss_step: 3.7049
  val/reg_loss: 1.8922
  val_MR: 0.7594
  val_brier-minFDE6: 8.7007
  val_minADE1: 8.0265
  val_minADE6: 3.9234
  val_minFDE1: 14.7555
  val_minFDE6: 8.1574
  train/loss_epoch: 14.0140
  train/reg_loss_epoch: 8.9120
  train/cls_loss_epoch: 1.2315
  train/others_reg_loss_epoch: 3.8704

Epoch 3:
  train/loss: 7.0726
  train/loss_step: 7.0726
  train/reg_loss: 1.5711
  train/reg_loss_step: 1.5711
  train/cls_loss: 1.7408
  train/cls_loss_step: 1.7408
  train/others_reg_loss: 3.7607
  train/others_reg_loss_step: 3.7607
  val/reg_loss: 1.8737
  val_MR: 0.7702
  val_brier-minFDE6: 9.0648
  val_minADE1: 9.9158
  val_minADE6: 3.8854
  val_minFDE1: 20.4560
  val_minFDE6: 8.3891
  train/loss_epoch: 8.5202
  train/reg_loss_epoch: 3.4560
  train/cls_loss_epoch: 1.2122
  train/others_reg_loss_epoch: 3.8520

Epoch 4:
  train/loss: 4.8495
  train/loss_step: 4.8495
  train/reg_loss: 1.0460
  train/reg_loss_step: 1.0460
  train/cls_loss: 1.6917
  train/cls_loss_step: 1.6917
  train/others_reg_loss: 2.1117
  train/others_reg_loss_step: 2.1117
  val/reg_loss: 1.2099
  val_MR: 0.6458
  val_brier-minFDE6: 6.1699
  val_minADE1: 5.1414
  val_minADE6: 2.6344
  val_minFDE1: 11.5412
  val_minFDE6: 5.4956
  train/loss_epoch: 7.0208
  train/reg_loss_epoch: 1.5210
  train/cls_loss_epoch: 1.7045
  train/others_reg_loss_epoch: 3.7953

Epoch 5:
  train/loss: 5.5144
  train/loss_step: 5.5144
  train/reg_loss: 1.3633
  train/reg_loss_step: 1.3633
  train/cls_loss: 1.6782
  train/cls_loss_step: 1.6782
  train/others_reg_loss: 2.4730
  train/others_reg_loss_step: 2.4730
  val/reg_loss: 1.1486
  val_MR: 0.6244
  val_brier-minFDE6: 6.0394
  val_minADE1: 4.6412
  val_minADE6: 2.5255
  val_minFDE1: 10.7327
  val_minFDE6: 5.3781
  train/loss_epoch: 6.4457
  train/reg_loss_epoch: 1.3254
  train/cls_loss_epoch: 1.7917
  train/others_reg_loss_epoch: 3.3286

Epoch 6:
  train/loss: 6.0484
  train/loss_step: 6.0484
  train/reg_loss: 1.9073
  train/reg_loss_step: 1.9073
  train/cls_loss: 2.0547
  train/cls_loss_step: 2.0547
  train/others_reg_loss: 2.0864
  train/others_reg_loss_step: 2.0864
  val/reg_loss: 1.7654
  val_MR: 0.8129
  val_brier-minFDE6: 9.0223
  val_minADE1: 9.0951
  val_minADE6: 3.6636
  val_minFDE1: 19.2571
  val_minFDE6: 8.2871
  train/loss_epoch: 5.4515
  train/reg_loss_epoch: 1.2386
  train/cls_loss_epoch: 1.7655
  train/others_reg_loss_epoch: 2.4473

Epoch 7:
  train/loss: 4.4261
  train/loss_step: 4.4261
  train/reg_loss: 1.1025
  train/reg_loss_step: 1.1025
  train/cls_loss: 1.6917
  train/cls_loss_step: 1.6917
  train/others_reg_loss: 1.6319
  train/others_reg_loss_step: 1.6319
  val/reg_loss: 1.0834
  val_MR: 0.6020
  val_brier-minFDE6: 6.0877
  val_minADE1: 4.1721
  val_minADE6: 2.4065
  val_minFDE1: 10.2836
  val_minFDE6: 5.4287
  train/loss_epoch: 5.0424
  train/reg_loss_epoch: 1.1622
  train/cls_loss_epoch: 1.7483
  train/others_reg_loss_epoch: 2.1319

Epoch 8:
  train/loss: 4.6531
  train/loss_step: 4.6531
  train/reg_loss: 0.9781
  train/reg_loss_step: 0.9781
  train/cls_loss: 1.6502
  train/cls_loss_step: 1.6502
  train/others_reg_loss: 2.0248
  train/others_reg_loss_step: 2.0248
  val/reg_loss: 1.0777
  val_MR: 0.6182
  val_brier-minFDE6: 5.8944
  val_minADE1: 4.5018
  val_minADE6: 2.4115
  val_minFDE1: 11.1710
  val_minFDE6: 5.2360
  train/loss_epoch: 4.8629
  train/reg_loss_epoch: 1.1507
  train/cls_loss_epoch: 1.7532
  train/others_reg_loss_epoch: 1.9589

Epoch 9:
  train/loss: 4.7176
  train/loss_step: 4.7176
  train/reg_loss: 1.4921
  train/reg_loss_step: 1.4921
  train/cls_loss: 1.9193
  train/cls_loss_step: 1.9193
  train/others_reg_loss: 1.3062
  train/others_reg_loss_step: 1.3062
  val/reg_loss: 1.0467
  val_MR: 0.6088
  val_brier-minFDE6: 5.9613
  val_minADE1: 5.0814
  val_minADE6: 2.3412
  val_minFDE1: 12.2956
  val_minFDE6: 5.2861
  train/loss_epoch: 4.5589
  train/reg_loss_epoch: 1.1073
  train/cls_loss_epoch: 1.7656
  train/others_reg_loss_epoch: 1.6860

Epoch 10:
  train/loss: 4.2461
  train/loss_step: 4.2461
  train/reg_loss: 1.1086
  train/reg_loss_step: 1.1086
  train/cls_loss: 1.7082
  train/cls_loss_step: 1.7082
  train/others_reg_loss: 1.4292
  train/others_reg_loss_step: 1.4292
  val/reg_loss: 1.2255
  val_MR: 0.6897
  val_brier-minFDE6: 6.4552
  val_minADE1: 5.3433
  val_minADE6: 2.6721
  val_minFDE1: 11.8867
  val_minFDE6: 5.7927
  train/loss_epoch: 4.4234
  train/reg_loss_epoch: 1.0837
  train/cls_loss_epoch: 1.7604
  train/others_reg_loss_epoch: 1.5793

Epoch 11:
  train/loss: 3.6381
  train/loss_step: 3.6381
  train/reg_loss: 0.7362
  train/reg_loss_step: 0.7362
  train/cls_loss: 1.7129
  train/cls_loss_step: 1.7129
  train/others_reg_loss: 1.1890
  train/others_reg_loss_step: 1.1890
  val/reg_loss: 1.0754
  val_MR: 0.6016
  val_brier-minFDE6: 5.9217
  val_minADE1: 4.4907
  val_minADE6: 2.3882
  val_minFDE1: 10.6585
  val_minFDE6: 5.2426
  train/loss_epoch: 4.3673
  train/reg_loss_epoch: 1.0856
  train/cls_loss_epoch: 1.7778
  train/others_reg_loss_epoch: 1.5039

Epoch 12:
  train/loss: 4.4067
  train/loss_step: 4.4067
  train/reg_loss: 1.2599
  train/reg_loss_step: 1.2599
  train/cls_loss: 1.6995
  train/cls_loss_step: 1.6995
  train/others_reg_loss: 1.4473
  train/others_reg_loss_step: 1.4473
  val/reg_loss: 1.1592
  val_MR: 0.5811
  val_brier-minFDE6: 5.8919
  val_minADE1: 4.5287
  val_minADE6: 2.5665
  val_minFDE1: 10.6826
  val_minFDE6: 5.2205
  train/loss_epoch: 4.3142
  train/reg_loss_epoch: 1.1000
  train/cls_loss_epoch: 1.7713
  train/others_reg_loss_epoch: 1.4429

Epoch 13:
  train/loss: 3.5551
  train/loss_step: 3.5551
  train/reg_loss: 0.8351
  train/reg_loss_step: 0.8351
  train/cls_loss: 1.6398
  train/cls_loss_step: 1.6398
  train/others_reg_loss: 1.0802
  train/others_reg_loss_step: 1.0802
  val/reg_loss: 1.0088
  val_MR: 0.5829
  val_brier-minFDE6: 5.8085
  val_minADE1: 4.2184
  val_minADE6: 2.2833
  val_minFDE1: 10.3978
  val_minFDE6: 5.1484
  train/loss_epoch: 4.3236
  train/reg_loss_epoch: 1.1078
  train/cls_loss_epoch: 1.7786
  train/others_reg_loss_epoch: 1.4372

Epoch 14:
  train/loss: 3.3371
  train/loss_step: 3.3371
  train/reg_loss: 0.6291
  train/reg_loss_step: 0.6291
  train/cls_loss: 1.7175
  train/cls_loss_step: 1.7175
  train/others_reg_loss: 0.9905
  train/others_reg_loss_step: 0.9905
  val/reg_loss: 1.0674
  val_MR: 0.5721
  val_brier-minFDE6: 5.9131
  val_minADE1: 5.0777
  val_minADE6: 2.3845
  val_minFDE1: 11.9358
  val_minFDE6: 5.2218
  train/loss_epoch: 4.0498
  train/reg_loss_epoch: 1.0288
  train/cls_loss_epoch: 1.7420
  train/others_reg_loss_epoch: 1.2790

Epoch 15:
  train/loss: 3.6366
  train/loss_step: 3.6366
  train/reg_loss: 0.7128
  train/reg_loss_step: 0.7128
  train/cls_loss: 1.6677
  train/cls_loss_step: 1.6677
  train/others_reg_loss: 1.2561
  train/others_reg_loss_step: 1.2561
  val/reg_loss: 0.9741
  val_MR: 0.5683
  val_brier-minFDE6: 5.6015
  val_minADE1: 4.7971
  val_minADE6: 2.2148
  val_minFDE1: 11.6451
  val_minFDE6: 4.9377
  train/loss_epoch: 4.0075
  train/reg_loss_epoch: 1.0122
  train/cls_loss_epoch: 1.7326
  train/others_reg_loss_epoch: 1.2627

Epoch 16:
  train/loss: 3.1311
  train/loss_step: 3.1311
  train/reg_loss: 0.5471
  train/reg_loss_step: 0.5471
  train/cls_loss: 1.6155
  train/cls_loss_step: 1.6155
  train/others_reg_loss: 0.9685
  train/others_reg_loss_step: 0.9685
  val/reg_loss: 0.9175
  val_MR: 0.5170
  val_brier-minFDE6: 5.3627
  val_minADE1: 3.8573
  val_minADE6: 2.0962
  val_minFDE1: 9.5713
  val_minFDE6: 4.7031
  train/loss_epoch: 3.9233
  train/reg_loss_epoch: 0.9861
  train/cls_loss_epoch: 1.7294
  train/others_reg_loss_epoch: 1.2078

Epoch 17:
  train/loss: 3.5453
  train/loss_step: 3.5453
  train/reg_loss: 0.8599
  train/reg_loss_step: 0.8599
  train/cls_loss: 1.6701
  train/cls_loss_step: 1.6701
  train/others_reg_loss: 1.0153
  train/others_reg_loss_step: 1.0153
  val/reg_loss: 0.9159
  val_MR: 0.5457
  val_brier-minFDE6: 5.2283
  val_minADE1: 3.7884
  val_minADE6: 2.0867
  val_minFDE1: 9.3776
  val_minFDE6: 4.5891
  train/loss_epoch: 3.7750
  train/reg_loss_epoch: 0.9236
  train/cls_loss_epoch: 1.7115
  train/others_reg_loss_epoch: 1.1399

Epoch 18:
  train/loss: 3.8071
  train/loss_step: 3.8071
  train/reg_loss: 1.0929
  train/reg_loss_step: 1.0929
  train/cls_loss: 1.7208
  train/cls_loss_step: 1.7208
  train/others_reg_loss: 0.9935
  train/others_reg_loss_step: 0.9935
  val/reg_loss: 0.8204
  val_MR: 0.5128
  val_brier-minFDE6: 4.9774
  val_minADE1: 3.4814
  val_minADE6: 1.8894
  val_minFDE1: 8.7871
  val_minFDE6: 4.3398
  train/loss_epoch: 3.6046
  train/reg_loss_epoch: 0.8633
  train/cls_loss_epoch: 1.6827
  train/others_reg_loss_epoch: 1.0586

Epoch 19:
  train/loss: 3.2220
  train/loss_step: 3.2220
  train/reg_loss: 0.7717
  train/reg_loss_step: 0.7717
  train/cls_loss: 1.6163
  train/cls_loss_step: 1.6163
  train/others_reg_loss: 0.8340
  train/others_reg_loss_step: 0.8340
  val/reg_loss: 0.7792
  val_MR: 0.5200
  val_brier-minFDE6: 4.8456
  val_minADE1: 3.5554
  val_minADE6: 1.8039
  val_minFDE1: 9.0165
  val_minFDE6: 4.2147
  train/loss_epoch: 3.4845
  train/reg_loss_epoch: 0.8263
  train/cls_loss_epoch: 1.6757
  train/others_reg_loss_epoch: 0.9825

Epoch 20:
  train/loss: 3.1887
  train/loss_step: 3.1887
  train/reg_loss: 0.8203
  train/reg_loss_step: 0.8203
  train/cls_loss: 1.6239
  train/cls_loss_step: 1.6239
  train/others_reg_loss: 0.7445
  train/others_reg_loss_step: 0.7445
  val/reg_loss: 0.7695
  val_MR: 0.4986
  val_brier-minFDE6: 4.8053
  val_minADE1: 3.4327
  val_minADE6: 1.7891
  val_minFDE1: 8.7585
  val_minFDE6: 4.1781
  train/loss_epoch: 3.3796
  train/reg_loss_epoch: 0.7945
  train/cls_loss_epoch: 1.6464
  train/others_reg_loss_epoch: 0.9388

FINAL VALIDATION RESULTS:
  train/loss: 3.2891
  train/loss_step: 3.1887
  train/reg_loss: 0.7467
  train/reg_loss_step: 0.8203
  train/cls_loss: 1.6357
  train/cls_loss_step: 1.6239
  train/others_reg_loss: 0.9068
  train/others_reg_loss_step: 0.7445
  val/reg_loss: 0.7695
  val_MR: 0.4986
  val_brier-minFDE6: 4.8053
  val_minADE1: 3.4327
  val_minADE6: 1.7891
  val_minFDE1: 8.7585
  val_minFDE6: 4.1781
  train/loss_epoch: 3.2891
  train/reg_loss_epoch: 0.7467
  train/cls_loss_epoch: 1.6357
  train/others_reg_loss_epoch: 0.9068

================================================================================

Experiment 16
--------------------------------------------------
HYPERPARAMETERS:
  dim: 48
  encoder_depth: 4
  num_heads: 2
  mlp_ratio: 6
  attention_type: linear
  decoder_embed_dim: 64
  decoder_num_modes: 6
  decoder_hidden_dim: 192
  model_params: 590,449

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4735
  val_MR: 0.9609
  val_brier-minFDE6: 41.3462
  val_minADE1: 20.4960
  val_minADE6: 20.4936
  val_minFDE1: 40.6670
  val_minFDE6: 40.6485

Epoch 1:
  train/loss: 9.9922
  train/loss_step: 9.9922
  train/reg_loss: 5.2282
  train/reg_loss_step: 5.2282
  train/cls_loss: 0.7551
  train/cls_loss_step: 0.7551
  train/others_reg_loss: 4.0088
  train/others_reg_loss_step: 4.0088
  val/reg_loss: 5.2717
  val_MR: 0.9205
  val_brier-minFDE6: 26.7995
  val_minADE1: 10.5443
  val_minADE6: 10.3096
  val_minFDE1: 26.6809
  val_minFDE6: 26.5137

Epoch 2:
  train/loss: 6.4590
  train/loss_step: 6.4590
  train/reg_loss: 2.1824
  train/reg_loss_step: 2.1824
  train/cls_loss: 1.0650
  train/cls_loss_step: 1.0650
  train/others_reg_loss: 3.2116
  train/others_reg_loss_step: 3.2116
  val/reg_loss: 2.1676
  val_MR: 0.7837
  val_brier-minFDE6: 10.4636
  val_minADE1: 6.1591
  val_minADE6: 4.4050
  val_minFDE1: 12.6910
  val_minFDE6: 10.0773
  train/loss_epoch: 13.2108
  train/reg_loss_epoch: 8.2603
  train/cls_loss_epoch: 1.0770
  train/others_reg_loss_epoch: 3.8734

Epoch 3:
  train/loss: 6.8497
  train/loss_step: 6.8497
  train/reg_loss: 2.2028
  train/reg_loss_step: 2.2028
  train/cls_loss: 1.4246
  train/cls_loss_step: 1.4246
  train/others_reg_loss: 3.2222
  train/others_reg_loss_step: 3.2222
  val/reg_loss: 1.6510
  val_MR: 0.7402
  val_brier-minFDE6: 8.4029
  val_minADE1: 4.6474
  val_minADE6: 3.4627
  val_minFDE1: 10.8721
  val_minFDE6: 7.8325
  train/loss_epoch: 8.0961
  train/reg_loss_epoch: 3.2660
  train/cls_loss_epoch: 1.0112
  train/others_reg_loss_epoch: 3.8189

Epoch 4:
  train/loss: 5.4332
  train/loss_step: 5.4332
  train/reg_loss: 1.1762
  train/reg_loss_step: 1.1762
  train/cls_loss: 1.8349
  train/cls_loss_step: 1.8349
  train/others_reg_loss: 2.4221
  train/others_reg_loss_step: 2.4221
  val/reg_loss: 1.3289
  val_MR: 0.6364
  val_brier-minFDE6: 6.8058
  val_minADE1: 6.9477
  val_minADE6: 2.8465
  val_minFDE1: 15.3687
  val_minFDE6: 6.1035
  train/loss_epoch: 7.0556
  train/reg_loss_epoch: 1.9016
  train/cls_loss_epoch: 1.3933
  train/others_reg_loss_epoch: 3.7608

Epoch 5:
  train/loss: 4.4866
  train/loss_step: 4.4866
  train/reg_loss: 0.7674
  train/reg_loss_step: 0.7674
  train/cls_loss: 1.7329
  train/cls_loss_step: 1.7329
  train/others_reg_loss: 1.9864
  train/others_reg_loss_step: 1.9864
  val/reg_loss: 1.1170
  val_MR: 0.6442
  val_brier-minFDE6: 6.1130
  val_minADE1: 4.4426
  val_minADE6: 2.4721
  val_minFDE1: 10.6151
  val_minFDE6: 5.4449
  train/loss_epoch: 6.2790
  train/reg_loss_epoch: 1.4289
  train/cls_loss_epoch: 1.7193
  train/others_reg_loss_epoch: 3.1308

Epoch 6:
  train/loss: 5.3809
  train/loss_step: 5.3809
  train/reg_loss: 1.5851
  train/reg_loss_step: 1.5851
  train/cls_loss: 1.7695
  train/cls_loss_step: 1.7695
  train/others_reg_loss: 2.0263
  train/others_reg_loss_step: 2.0263
  val/reg_loss: 1.2699
  val_MR: 0.6579
  val_brier-minFDE6: 6.4125
  val_minADE1: 5.9382
  val_minADE6: 2.7686
  val_minFDE1: 12.8670
  val_minFDE6: 5.7256
  train/loss_epoch: 5.3810
  train/reg_loss_epoch: 1.2450
  train/cls_loss_epoch: 1.7776
  train/others_reg_loss_epoch: 2.3584

Epoch 7:
  train/loss: 4.4817
  train/loss_step: 4.4817
  train/reg_loss: 1.1275
  train/reg_loss_step: 1.1275
  train/cls_loss: 1.6823
  train/cls_loss_step: 1.6823
  train/others_reg_loss: 1.6719
  train/others_reg_loss_step: 1.6719
  val/reg_loss: 1.0832
  val_MR: 0.5938
  val_brier-minFDE6: 6.0357
  val_minADE1: 4.6575
  val_minADE6: 2.4181
  val_minFDE1: 10.9910
  val_minFDE6: 5.3553
  train/loss_epoch: 5.1090
  train/reg_loss_epoch: 1.2576
  train/cls_loss_epoch: 1.7884
  train/others_reg_loss_epoch: 2.0630

Epoch 8:
  train/loss: 4.8945
  train/loss_step: 4.8945
  train/reg_loss: 1.5347
  train/reg_loss_step: 1.5347
  train/cls_loss: 1.8256
  train/cls_loss_step: 1.8256
  train/others_reg_loss: 1.5343
  train/others_reg_loss_step: 1.5343
  val/reg_loss: 1.2153
  val_MR: 0.6218
  val_brier-minFDE6: 6.1538
  val_minADE1: 4.8988
  val_minADE6: 2.6615
  val_minFDE1: 10.9810
  val_minFDE6: 5.4528
  train/loss_epoch: 4.8344
  train/reg_loss_epoch: 1.2361
  train/cls_loss_epoch: 1.8041
  train/others_reg_loss_epoch: 1.7943

Epoch 9:
  train/loss: 4.4666
  train/loss_step: 4.4666
  train/reg_loss: 1.4412
  train/reg_loss_step: 1.4412
  train/cls_loss: 1.7622
  train/cls_loss_step: 1.7622
  train/others_reg_loss: 1.2632
  train/others_reg_loss_step: 1.2632
  val/reg_loss: 1.3324
  val_MR: 0.5851
  val_brier-minFDE6: 6.2757
  val_minADE1: 4.7063
  val_minADE6: 2.8768
  val_minFDE1: 10.8916
  val_minFDE6: 5.6015
  train/loss_epoch: 4.6183
  train/reg_loss_epoch: 1.2069
  train/cls_loss_epoch: 1.7955
  train/others_reg_loss_epoch: 1.6160

Epoch 10:
  train/loss: 5.6015
  train/loss_step: 5.6015
  train/reg_loss: 1.6420
  train/reg_loss_step: 1.6420
  train/cls_loss: 2.1442
  train/cls_loss_step: 2.1442
  train/others_reg_loss: 1.8153
  train/others_reg_loss_step: 1.8153
  val/reg_loss: 1.4996
  val_MR: 0.7163
  val_brier-minFDE6: 8.2131
  val_minADE1: 7.8776
  val_minADE6: 3.1583
  val_minFDE1: 19.3838
  val_minFDE6: 7.4500
  train/loss_epoch: 4.5689
  train/reg_loss_epoch: 1.2506
  train/cls_loss_epoch: 1.8032
  train/others_reg_loss_epoch: 1.5151

Epoch 11:
  train/loss: 4.0137
  train/loss_step: 4.0137
  train/reg_loss: 1.0450
  train/reg_loss_step: 1.0450
  train/cls_loss: 1.8881
  train/cls_loss_step: 1.8881
  train/others_reg_loss: 1.0806
  train/others_reg_loss_step: 1.0806
  val/reg_loss: 1.0366
  val_MR: 0.6146
  val_brier-minFDE6: 5.8924
  val_minADE1: 4.6781
  val_minADE6: 2.3264
  val_minFDE1: 10.8338
  val_minFDE6: 5.1964
  train/loss_epoch: 4.4259
  train/reg_loss_epoch: 1.1654
  train/cls_loss_epoch: 1.7857
  train/others_reg_loss_epoch: 1.4748

Epoch 12:
  train/loss: 3.9762
  train/loss_step: 3.9762
  train/reg_loss: 0.8837
  train/reg_loss_step: 0.8837
  train/cls_loss: 1.6755
  train/cls_loss_step: 1.6755
  train/others_reg_loss: 1.4170
  train/others_reg_loss_step: 1.4170
  val/reg_loss: 1.0043
  val_MR: 0.6154
  val_brier-minFDE6: 5.8449
  val_minADE1: 3.8165
  val_minADE6: 2.2684
  val_minFDE1: 9.5183
  val_minFDE6: 5.1862
  train/loss_epoch: 4.4659
  train/reg_loss_epoch: 1.2021
  train/cls_loss_epoch: 1.7966
  train/others_reg_loss_epoch: 1.4671

Epoch 13:
  train/loss: 3.6335
  train/loss_step: 3.6335
  train/reg_loss: 0.9419
  train/reg_loss_step: 0.9419
  train/cls_loss: 1.6330
  train/cls_loss_step: 1.6330
  train/others_reg_loss: 1.0587
  train/others_reg_loss_step: 1.0587
  val/reg_loss: 0.9982
  val_MR: 0.5781
  val_brier-minFDE6: 5.7214
  val_minADE1: 3.8988
  val_minADE6: 2.2514
  val_minFDE1: 9.4782
  val_minFDE6: 5.0688
  train/loss_epoch: 4.2199
  train/reg_loss_epoch: 1.0864
  train/cls_loss_epoch: 1.7836
  train/others_reg_loss_epoch: 1.3500

Epoch 14:
  train/loss: 3.9437
  train/loss_step: 3.9437
  train/reg_loss: 1.0284
  train/reg_loss_step: 1.0284
  train/cls_loss: 1.6924
  train/cls_loss_step: 1.6924
  train/others_reg_loss: 1.2229
  train/others_reg_loss_step: 1.2229
  val/reg_loss: 0.9971
  val_MR: 0.5296
  val_brier-minFDE6: 5.4900
  val_minADE1: 3.9088
  val_minADE6: 2.2663
  val_minFDE1: 9.2033
  val_minFDE6: 4.8419
  train/loss_epoch: 4.2103
  train/reg_loss_epoch: 1.0996
  train/cls_loss_epoch: 1.7808
  train/others_reg_loss_epoch: 1.3299

Epoch 15:
  train/loss: 4.2791
  train/loss_step: 4.2791
  train/reg_loss: 0.9096
  train/reg_loss_step: 0.9096
  train/cls_loss: 1.9604
  train/cls_loss_step: 1.9604
  train/others_reg_loss: 1.4091
  train/others_reg_loss_step: 1.4091
  val/reg_loss: 1.1089
  val_MR: 0.5988
  val_brier-minFDE6: 5.6424
  val_minADE1: 4.5879
  val_minADE6: 2.4536
  val_minFDE1: 10.0025
  val_minFDE6: 4.9699
  train/loss_epoch: 3.9758
  train/reg_loss_epoch: 0.9957
  train/cls_loss_epoch: 1.7414
  train/others_reg_loss_epoch: 1.2386

Epoch 16:
  train/loss: 3.8656
  train/loss_step: 3.8656
  train/reg_loss: 0.9571
  train/reg_loss_step: 0.9571
  train/cls_loss: 1.9039
  train/cls_loss_step: 1.9039
  train/others_reg_loss: 1.0046
  train/others_reg_loss_step: 1.0046
  val/reg_loss: 1.0779
  val_MR: 0.6022
  val_brier-minFDE6: 5.6306
  val_minADE1: 4.8646
  val_minADE6: 2.3883
  val_minFDE1: 11.0273
  val_minFDE6: 4.9412
  train/loss_epoch: 4.0105
  train/reg_loss_epoch: 1.0060
  train/cls_loss_epoch: 1.7715
  train/others_reg_loss_epoch: 1.2330

Epoch 17:
  train/loss: 3.4969
  train/loss_step: 3.4969
  train/reg_loss: 0.7417
  train/reg_loss_step: 0.7417
  train/cls_loss: 1.7682
  train/cls_loss_step: 1.7682
  train/others_reg_loss: 0.9870
  train/others_reg_loss_step: 0.9870
  val/reg_loss: 0.9254
  val_MR: 0.5807
  val_brier-minFDE6: 5.3414
  val_minADE1: 4.5094
  val_minADE6: 2.0921
  val_minFDE1: 10.7581
  val_minFDE6: 4.6808
  train/loss_epoch: 3.7937
  train/reg_loss_epoch: 0.9057
  train/cls_loss_epoch: 1.7277
  train/others_reg_loss_epoch: 1.1603

Epoch 18:
  train/loss: 2.8371
  train/loss_step: 2.8371
  train/reg_loss: 0.4440
  train/reg_loss_step: 0.4440
  train/cls_loss: 1.6104
  train/cls_loss_step: 1.6104
  train/others_reg_loss: 0.7827
  train/others_reg_loss_step: 0.7827
  val/reg_loss: 0.8124
  val_MR: 0.4872
  val_brier-minFDE6: 4.9342
  val_minADE1: 3.4635
  val_minADE6: 1.8798
  val_minFDE1: 8.7047
  val_minFDE6: 4.3038
  train/loss_epoch: 3.6665
  train/reg_loss_epoch: 0.8790
  train/cls_loss_epoch: 1.7066
  train/others_reg_loss_epoch: 1.0809

Epoch 19:
  train/loss: 3.6104
  train/loss_step: 3.6104
  train/reg_loss: 0.7749
  train/reg_loss_step: 0.7749
  train/cls_loss: 1.6464
  train/cls_loss_step: 1.6464
  train/others_reg_loss: 1.1891
  train/others_reg_loss_step: 1.1891
  val/reg_loss: 0.7852
  val_MR: 0.4944
  val_brier-minFDE6: 4.8393
  val_minADE1: 3.4458
  val_minADE6: 1.8257
  val_minFDE1: 8.7299
  val_minFDE6: 4.2098
  train/loss_epoch: 3.4844
  train/reg_loss_epoch: 0.8183
  train/cls_loss_epoch: 1.6710
  train/others_reg_loss_epoch: 0.9951

Epoch 20:
  train/loss: 3.1408
  train/loss_step: 3.1408
  train/reg_loss: 0.7177
  train/reg_loss_step: 0.7177
  train/cls_loss: 1.5626
  train/cls_loss_step: 1.5626
  train/others_reg_loss: 0.8605
  train/others_reg_loss_step: 0.8605
  val/reg_loss: 0.7753
  val_MR: 0.4892
  val_brier-minFDE6: 4.8114
  val_minADE1: 3.3936
  val_minADE6: 1.8021
  val_minFDE1: 8.6268
  val_minFDE6: 4.1821
  train/loss_epoch: 3.3938
  train/reg_loss_epoch: 0.7985
  train/cls_loss_epoch: 1.6517
  train/others_reg_loss_epoch: 0.9436

FINAL VALIDATION RESULTS:
  train/loss: 3.3250
  train/loss_step: 3.1408
  train/reg_loss: 0.7742
  train/reg_loss_step: 0.7177
  train/cls_loss: 1.6451
  train/cls_loss_step: 1.5626
  train/others_reg_loss: 0.9057
  train/others_reg_loss_step: 0.8605
  val/reg_loss: 0.7753
  val_MR: 0.4892
  val_brier-minFDE6: 4.8114
  val_minADE1: 3.3936
  val_minADE6: 1.8021
  val_minFDE1: 8.6268
  val_minFDE6: 4.1821
  train/loss_epoch: 3.3250
  train/reg_loss_epoch: 0.7742
  train/cls_loss_epoch: 1.6451
  train/others_reg_loss_epoch: 0.9057

================================================================================

Experiment 17
--------------------------------------------------
HYPERPARAMETERS:
  dim: 48
  encoder_depth: 2
  num_heads: 2
  mlp_ratio: 2
  attention_type: performer
  decoder_embed_dim: 96
  decoder_num_modes: 6
  decoder_hidden_dim: 192
  model_params: 404,849

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4195
  val_MR: 0.9531
  val_brier-minFDE6: 40.4777
  val_minADE1: 20.3916
  val_minADE6: 20.3871
  val_minFDE1: 39.8218
  val_minFDE6: 39.7787

Epoch 1:
  train/loss: 8.6058
  train/loss_step: 8.6058
  train/reg_loss: 4.1585
  train/reg_loss_step: 4.1585
  train/cls_loss: 0.8855
  train/cls_loss_step: 0.8855
  train/others_reg_loss: 3.5618
  train/others_reg_loss_step: 3.5618
  val/reg_loss: 4.3174
  val_MR: 0.9295
  val_brier-minFDE6: 16.8193
  val_minADE1: 8.8565
  val_minADE6: 8.5228
  val_minFDE1: 17.2871
  val_minFDE6: 16.5108

Epoch 2:
  train/loss: 6.8388
  train/loss_step: 6.8388
  train/reg_loss: 1.8559
  train/reg_loss_step: 1.8559
  train/cls_loss: 1.3288
  train/cls_loss_step: 1.3288
  train/others_reg_loss: 3.6542
  train/others_reg_loss_step: 3.6542
  val/reg_loss: 1.9832
  val_MR: 0.7480
  val_brier-minFDE6: 9.6973
  val_minADE1: 5.4302
  val_minADE6: 4.0676
  val_minFDE1: 12.0776
  val_minFDE6: 9.2780
  train/loss_epoch: 12.2937
  train/reg_loss_epoch: 7.3737
  train/cls_loss_epoch: 1.0213
  train/others_reg_loss_epoch: 3.8987

Epoch 3:
  train/loss: 7.2947
  train/loss_step: 7.2947
  train/reg_loss: 1.4597
  train/reg_loss_step: 1.4597
  train/cls_loss: 1.7904
  train/cls_loss_step: 1.7904
  train/others_reg_loss: 4.0446
  train/others_reg_loss_step: 4.0446
  val/reg_loss: 1.3000
  val_MR: 0.6150
  val_brier-minFDE6: 6.5392
  val_minADE1: 7.3741
  val_minADE6: 2.8102
  val_minFDE1: 14.1374
  val_minFDE6: 5.8856
  train/loss_epoch: 8.0173
  train/reg_loss_epoch: 3.0714
  train/cls_loss_epoch: 1.0610
  train/others_reg_loss_epoch: 3.8849

Epoch 4:
  train/loss: 7.1267
  train/loss_step: 7.1267
  train/reg_loss: 1.5588
  train/reg_loss_step: 1.5588
  train/cls_loss: 1.7581
  train/cls_loss_step: 1.7581
  train/others_reg_loss: 3.8099
  train/others_reg_loss_step: 3.8099
  val/reg_loss: 1.3322
  val_MR: 0.7222
  val_brier-minFDE6: 6.7229
  val_minADE1: 7.8064
  val_minADE6: 2.8558
  val_minFDE1: 16.2588
  val_minFDE6: 6.0122
  train/loss_epoch: 7.2360
  train/reg_loss_epoch: 1.9194
  train/cls_loss_epoch: 1.4804
  train/others_reg_loss_epoch: 3.8363

Epoch 5:
  train/loss: 4.9465
  train/loss_step: 4.9465
  train/reg_loss: 1.0331
  train/reg_loss_step: 1.0331
  train/cls_loss: 1.6404
  train/cls_loss_step: 1.6404
  train/others_reg_loss: 2.2729
  train/others_reg_loss_step: 2.2729
  val/reg_loss: 1.2602
  val_MR: 0.7103
  val_brier-minFDE6: 6.5379
  val_minADE1: 5.3361
  val_minADE6: 2.7328
  val_minFDE1: 12.3055
  val_minFDE6: 5.8711
  train/loss_epoch: 7.0327
  train/reg_loss_epoch: 1.5465
  train/cls_loss_epoch: 1.7774
  train/others_reg_loss_epoch: 3.7089

Epoch 6:
  train/loss: 5.5961
  train/loss_step: 5.5961
  train/reg_loss: 1.6285
  train/reg_loss_step: 1.6285
  train/cls_loss: 1.8255
  train/cls_loss_step: 1.8255
  train/others_reg_loss: 2.1421
  train/others_reg_loss_step: 2.1421
  val/reg_loss: 1.1346
  val_MR: 0.6412
  val_brier-minFDE6: 6.0620
  val_minADE1: 4.8263
  val_minADE6: 2.5240
  val_minFDE1: 11.6393
  val_minFDE6: 5.3899
  train/loss_epoch: 5.8054
  train/reg_loss_epoch: 1.3213
  train/cls_loss_epoch: 1.7584
  train/others_reg_loss_epoch: 2.7257

Epoch 7:
  train/loss: 4.0615
  train/loss_step: 4.0615
  train/reg_loss: 0.6851
  train/reg_loss_step: 0.6851
  train/cls_loss: 1.8081
  train/cls_loss_step: 1.8081
  train/others_reg_loss: 1.5683
  train/others_reg_loss_step: 1.5683
  val/reg_loss: 1.0580
  val_MR: 0.6186
  val_brier-minFDE6: 5.9723
  val_minADE1: 4.4910
  val_minADE6: 2.3648
  val_minFDE1: 10.8911
  val_minFDE6: 5.3079
  train/loss_epoch: 5.0620
  train/reg_loss_epoch: 1.2013
  train/cls_loss_epoch: 1.7630
  train/others_reg_loss_epoch: 2.0976

Epoch 8:
  train/loss: 4.2438
  train/loss_step: 4.2438
  train/reg_loss: 1.2685
  train/reg_loss_step: 1.2685
  train/cls_loss: 1.7837
  train/cls_loss_step: 1.7837
  train/others_reg_loss: 1.1916
  train/others_reg_loss_step: 1.1916
  val/reg_loss: 1.1283
  val_MR: 0.6346
  val_brier-minFDE6: 6.2034
  val_minADE1: 4.8543
  val_minADE6: 2.5042
  val_minFDE1: 11.6488
  val_minFDE6: 5.5332
  train/loss_epoch: 4.5220
  train/reg_loss_epoch: 1.1121
  train/cls_loss_epoch: 1.7585
  train/others_reg_loss_epoch: 1.6514

Epoch 9:
  train/loss: 4.3479
  train/loss_step: 4.3479
  train/reg_loss: 1.1696
  train/reg_loss_step: 1.1696
  train/cls_loss: 1.7657
  train/cls_loss_step: 1.7657
  train/others_reg_loss: 1.4127
  train/others_reg_loss_step: 1.4127
  val/reg_loss: 1.0391
  val_MR: 0.5875
  val_brier-minFDE6: 5.8580
  val_minADE1: 4.0761
  val_minADE6: 2.3444
  val_minFDE1: 9.8622
  val_minFDE6: 5.1836
  train/loss_epoch: 4.5718
  train/reg_loss_epoch: 1.1636
  train/cls_loss_epoch: 1.7845
  train/others_reg_loss_epoch: 1.6236

Epoch 10:
  train/loss: 4.9403
  train/loss_step: 4.9403
  train/reg_loss: 1.4247
  train/reg_loss_step: 1.4247
  train/cls_loss: 2.0643
  train/cls_loss_step: 2.0643
  train/others_reg_loss: 1.4513
  train/others_reg_loss_step: 1.4513
  val/reg_loss: 1.1934
  val_MR: 0.6873
  val_brier-minFDE6: 6.5689
  val_minADE1: 6.9380
  val_minADE6: 2.6174
  val_minFDE1: 16.1833
  val_minFDE6: 5.8305
  train/loss_epoch: 4.3127
  train/reg_loss_epoch: 1.1117
  train/cls_loss_epoch: 1.7698
  train/others_reg_loss_epoch: 1.4312

Epoch 11:
  train/loss: 4.2133
  train/loss_step: 4.2133
  train/reg_loss: 0.8057
  train/reg_loss_step: 0.8057
  train/cls_loss: 1.9576
  train/cls_loss_step: 1.9576
  train/others_reg_loss: 1.4500
  train/others_reg_loss_step: 1.4500
  val/reg_loss: 1.0788
  val_MR: 0.6152
  val_brier-minFDE6: 6.1447
  val_minADE1: 6.2705
  val_minADE6: 2.3945
  val_minFDE1: 15.0929
  val_minFDE6: 5.4365
  train/loss_epoch: 4.4051
  train/reg_loss_epoch: 1.1607
  train/cls_loss_epoch: 1.7923
  train/others_reg_loss_epoch: 1.4521

Epoch 12:
  train/loss: 3.9567
  train/loss_step: 3.9567
  train/reg_loss: 1.0762
  train/reg_loss_step: 1.0762
  train/cls_loss: 1.7417
  train/cls_loss_step: 1.7417
  train/others_reg_loss: 1.1388
  train/others_reg_loss_step: 1.1388
  val/reg_loss: 0.9764
  val_MR: 0.5759
  val_brier-minFDE6: 5.3972
  val_minADE1: 5.0941
  val_minADE6: 2.2274
  val_minFDE1: 11.6735
  val_minFDE6: 4.7330
  train/loss_epoch: 4.3261
  train/reg_loss_epoch: 1.1121
  train/cls_loss_epoch: 1.7938
  train/others_reg_loss_epoch: 1.4202

Epoch 13:
  train/loss: 4.3475
  train/loss_step: 4.3475
  train/reg_loss: 0.9962
  train/reg_loss_step: 0.9962
  train/cls_loss: 1.7165
  train/cls_loss_step: 1.7165
  train/others_reg_loss: 1.6347
  train/others_reg_loss_step: 1.6347
  val/reg_loss: 0.9502
  val_MR: 0.6552
  val_brier-minFDE6: 5.5206
  val_minADE1: 4.1939
  val_minADE6: 2.1365
  val_minFDE1: 10.5693
  val_minFDE6: 4.8488
  train/loss_epoch: 4.1801
  train/reg_loss_epoch: 1.0563
  train/cls_loss_epoch: 1.7662
  train/others_reg_loss_epoch: 1.3576

Epoch 14:
  train/loss: 3.6560
  train/loss_step: 3.6560
  train/reg_loss: 0.7174
  train/reg_loss_step: 0.7174
  train/cls_loss: 1.7391
  train/cls_loss_step: 1.7391
  train/others_reg_loss: 1.1994
  train/others_reg_loss_step: 1.1994
  val/reg_loss: 0.7907
  val_MR: 0.5200
  val_brier-minFDE6: 4.7099
  val_minADE1: 3.7190
  val_minADE6: 1.8277
  val_minFDE1: 8.9919
  val_minFDE6: 4.0361
  train/loss_epoch: 4.0753
  train/reg_loss_epoch: 0.9890
  train/cls_loss_epoch: 1.7692
  train/others_reg_loss_epoch: 1.3172

Epoch 15:
  train/loss: 3.4821
  train/loss_step: 3.4821
  train/reg_loss: 0.7885
  train/reg_loss_step: 0.7885
  train/cls_loss: 1.7126
  train/cls_loss_step: 1.7126
  train/others_reg_loss: 0.9811
  train/others_reg_loss_step: 0.9811
  val/reg_loss: 0.7366
  val_MR: 0.5284
  val_brier-minFDE6: 4.4882
  val_minADE1: 3.5426
  val_minADE6: 1.7289
  val_minFDE1: 8.7726
  val_minFDE6: 3.8246
  train/loss_epoch: 3.8810
  train/reg_loss_epoch: 0.8915
  train/cls_loss_epoch: 1.7535
  train/others_reg_loss_epoch: 1.2360

Epoch 16:
  train/loss: 3.4162
  train/loss_step: 3.4162
  train/reg_loss: 0.5395
  train/reg_loss_step: 0.5395
  train/cls_loss: 1.7719
  train/cls_loss_step: 1.7719
  train/others_reg_loss: 1.1049
  train/others_reg_loss_step: 1.1049
  val/reg_loss: 0.6727
  val_MR: 0.5058
  val_brier-minFDE6: 4.2121
  val_minADE1: 3.4121
  val_minADE6: 1.5991
  val_minFDE1: 8.4992
  val_minFDE6: 3.5683
  train/loss_epoch: 3.6672
  train/reg_loss_epoch: 0.8002
  train/cls_loss_epoch: 1.7324
  train/others_reg_loss_epoch: 1.1347

Epoch 17:
  train/loss: 3.6855
  train/loss_step: 3.6855
  train/reg_loss: 0.9043
  train/reg_loss_step: 0.9043
  train/cls_loss: 1.7107
  train/cls_loss_step: 1.7107
  train/others_reg_loss: 1.0705
  train/others_reg_loss_step: 1.0705
  val/reg_loss: 0.6475
  val_MR: 0.5234
  val_brier-minFDE6: 4.0062
  val_minADE1: 3.5482
  val_minADE6: 1.5519
  val_minFDE1: 8.7393
  val_minFDE6: 3.3625
  train/loss_epoch: 3.4660
  train/reg_loss_epoch: 0.7498
  train/cls_loss_epoch: 1.6828
  train/others_reg_loss_epoch: 1.0333

Epoch 18:
  train/loss: 3.3790
  train/loss_step: 3.3790
  train/reg_loss: 0.7763
  train/reg_loss_step: 0.7763
  train/cls_loss: 1.6978
  train/cls_loss_step: 1.6978
  train/others_reg_loss: 0.9050
  train/others_reg_loss_step: 0.9050
  val/reg_loss: 0.6333
  val_MR: 0.5176
  val_brier-minFDE6: 4.0261
  val_minADE1: 3.1817
  val_minADE6: 1.5225
  val_minFDE1: 7.9748
  val_minFDE6: 3.3839
  train/loss_epoch: 3.3134
  train/reg_loss_epoch: 0.6987
  train/cls_loss_epoch: 1.6856
  train/others_reg_loss_epoch: 0.9292

Epoch 19:
  train/loss: 3.0343
  train/loss_step: 3.0343
  train/reg_loss: 0.5411
  train/reg_loss_step: 0.5411
  train/cls_loss: 1.6452
  train/cls_loss_step: 1.6452
  train/others_reg_loss: 0.8480
  train/others_reg_loss_step: 0.8480
  val/reg_loss: 0.5940
  val_MR: 0.4714
  val_brier-minFDE6: 3.7656
  val_minADE1: 3.1452
  val_minADE6: 1.4578
  val_minFDE1: 7.8780
  val_minFDE6: 3.1298
  train/loss_epoch: 3.2094
  train/reg_loss_epoch: 0.6364
  train/cls_loss_epoch: 1.6845
  train/others_reg_loss_epoch: 0.8885

Epoch 20:
  train/loss: 2.8085
  train/loss_step: 2.8085
  train/reg_loss: 0.4181
  train/reg_loss_step: 0.4181
  train/cls_loss: 1.4992
  train/cls_loss_step: 1.4992
  train/others_reg_loss: 0.8911
  train/others_reg_loss_step: 0.8911
  val/reg_loss: 0.5799
  val_MR: 0.4677
  val_brier-minFDE6: 3.7583
  val_minADE1: 3.1516
  val_minADE6: 1.4262
  val_minFDE1: 7.8962
  val_minFDE6: 3.1259
  train/loss_epoch: 3.1152
  train/reg_loss_epoch: 0.6098
  train/cls_loss_epoch: 1.6571
  train/others_reg_loss_epoch: 0.8483

FINAL VALIDATION RESULTS:
  train/loss: 3.0796
  train/loss_step: 2.8085
  train/reg_loss: 0.6016
  train/reg_loss_step: 0.4181
  train/cls_loss: 1.6423
  train/cls_loss_step: 1.4992
  train/others_reg_loss: 0.8357
  train/others_reg_loss_step: 0.8911
  val/reg_loss: 0.5799
  val_MR: 0.4677
  val_brier-minFDE6: 3.7583
  val_minADE1: 3.1516
  val_minADE6: 1.4262
  val_minFDE1: 7.8962
  val_minFDE6: 3.1259
  train/loss_epoch: 3.0796
  train/reg_loss_epoch: 0.6016
  train/cls_loss_epoch: 1.6423
  train/others_reg_loss_epoch: 0.8357

================================================================================

Experiment 18
--------------------------------------------------
HYPERPARAMETERS:
  dim: 64
  encoder_depth: 4
  num_heads: 4
  mlp_ratio: 3
  attention_type: performer
  decoder_embed_dim: 32
  decoder_num_modes: 6
  decoder_hidden_dim: 96
  model_params: 576,657

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4242
  val_MR: 0.9531
  val_brier-minFDE6: 40.3550
  val_minADE1: 20.3865
  val_minADE6: 20.3820
  val_minFDE1: 39.7162
  val_minFDE6: 39.6490

Epoch 1:
  train/loss: 11.4893
  train/loss_step: 11.4893
  train/reg_loss: 6.0733
  train/reg_loss_step: 6.0733
  train/cls_loss: 0.7930
  train/cls_loss_step: 0.7930
  train/others_reg_loss: 4.6230
  train/others_reg_loss_step: 4.6230
  val/reg_loss: 5.7196
  val_MR: 0.9379
  val_brier-minFDE6: 22.0139
  val_minADE1: 11.3449
  val_minADE6: 11.1736
  val_minFDE1: 22.0384
  val_minFDE6: 21.7289

Epoch 2:
  train/loss: 7.5285
  train/loss_step: 7.5285
  train/reg_loss: 2.3561
  train/reg_loss_step: 2.3561
  train/cls_loss: 0.9230
  train/cls_loss_step: 0.9230
  train/others_reg_loss: 4.2494
  train/others_reg_loss_step: 4.2494
  val/reg_loss: 2.6493
  val_MR: 0.8602
  val_brier-minFDE6: 11.7762
  val_minADE1: 5.8398
  val_minADE6: 5.3228
  val_minFDE1: 12.7281
  val_minFDE6: 11.4250
  train/loss_epoch: 13.4178
  train/reg_loss_epoch: 8.4209
  train/cls_loss_epoch: 1.1071
  train/others_reg_loss_epoch: 3.8898

Epoch 3:
  train/loss: 6.8886
  train/loss_step: 6.8886
  train/reg_loss: 1.6766
  train/reg_loss_step: 1.6766
  train/cls_loss: 1.3009
  train/cls_loss_step: 1.3009
  train/others_reg_loss: 3.9111
  train/others_reg_loss_step: 3.9111
  val/reg_loss: 1.5299
  val_MR: 0.6532
  val_brier-minFDE6: 7.9090
  val_minADE1: 4.5715
  val_minADE6: 3.2160
  val_minFDE1: 10.1951
  val_minFDE6: 7.4302
  train/loss_epoch: 8.4898
  train/reg_loss_epoch: 3.5846
  train/cls_loss_epoch: 1.0023
  train/others_reg_loss_epoch: 3.9029

Epoch 4:
  train/loss: 6.6396
  train/loss_step: 6.6396
  train/reg_loss: 1.5042
  train/reg_loss_step: 1.5042
  train/cls_loss: 1.4931
  train/cls_loss_step: 1.4931
  train/others_reg_loss: 3.6422
  train/others_reg_loss_step: 3.6422
  val/reg_loss: 1.4537
  val_MR: 0.6534
  val_brier-minFDE6: 7.4212
  val_minADE1: 6.3254
  val_minADE6: 3.0768
  val_minFDE1: 12.9754
  val_minFDE6: 6.8494
  train/loss_epoch: 7.2637
  train/reg_loss_epoch: 2.2296
  train/cls_loss_epoch: 1.2036
  train/others_reg_loss_epoch: 3.8304

Epoch 5:
  train/loss: 6.0033
  train/loss_step: 6.0033
  train/reg_loss: 1.8557
  train/reg_loss_step: 1.8557
  train/cls_loss: 1.5603
  train/cls_loss_step: 1.5603
  train/others_reg_loss: 2.5873
  train/others_reg_loss_step: 2.5873
  val/reg_loss: 1.7839
  val_MR: 0.7408
  val_brier-minFDE6: 8.6308
  val_minADE1: 4.4317
  val_minADE6: 3.7101
  val_minFDE1: 10.3178
  val_minFDE6: 8.0169
  train/loss_epoch: 6.8046
  train/reg_loss_epoch: 1.8331
  train/cls_loss_epoch: 1.3618
  train/others_reg_loss_epoch: 3.6097

Epoch 6:
  train/loss: 4.5940
  train/loss_step: 4.5940
  train/reg_loss: 1.0423
  train/reg_loss_step: 1.0423
  train/cls_loss: 1.8044
  train/cls_loss_step: 1.8044
  train/others_reg_loss: 1.7473
  train/others_reg_loss_step: 1.7473
  val/reg_loss: 1.2224
  val_MR: 0.6040
  val_brier-minFDE6: 6.2013
  val_minADE1: 7.4276
  val_minADE6: 2.6558
  val_minFDE1: 15.5906
  val_minFDE6: 5.4948
  train/loss_epoch: 5.9381
  train/reg_loss_epoch: 1.5615
  train/cls_loss_epoch: 1.6243
  train/others_reg_loss_epoch: 2.7523

Epoch 7:
  train/loss: 4.9938
  train/loss_step: 4.9938
  train/reg_loss: 0.9747
  train/reg_loss_step: 0.9747
  train/cls_loss: 1.9780
  train/cls_loss_step: 1.9780
  train/others_reg_loss: 2.0411
  train/others_reg_loss_step: 2.0411
  val/reg_loss: 1.1897
  val_MR: 0.6506
  val_brier-minFDE6: 6.3527
  val_minADE1: 8.0646
  val_minADE6: 2.6067
  val_minFDE1: 17.7697
  val_minFDE6: 5.6136
  train/loss_epoch: 5.2797
  train/reg_loss_epoch: 1.2676
  train/cls_loss_epoch: 1.7867
  train/others_reg_loss_epoch: 2.2255

Epoch 8:
  train/loss: 5.0441
  train/loss_step: 5.0441
  train/reg_loss: 1.3597
  train/reg_loss_step: 1.3597
  train/cls_loss: 2.1541
  train/cls_loss_step: 2.1541
  train/others_reg_loss: 1.5304
  train/others_reg_loss_step: 1.5304
  val/reg_loss: 1.3472
  val_MR: 0.6909
  val_brier-minFDE6: 7.0930
  val_minADE1: 8.1975
  val_minADE6: 2.8716
  val_minFDE1: 17.8230
  val_minFDE6: 6.3508
  train/loss_epoch: 4.9292
  train/reg_loss_epoch: 1.2208
  train/cls_loss_epoch: 1.7877
  train/others_reg_loss_epoch: 1.9207

Epoch 9:
  train/loss: 4.5761
  train/loss_step: 4.5761
  train/reg_loss: 1.2117
  train/reg_loss_step: 1.2117
  train/cls_loss: 1.8343
  train/cls_loss_step: 1.8343
  train/others_reg_loss: 1.5301
  train/others_reg_loss_step: 1.5301
  val/reg_loss: 1.1916
  val_MR: 0.6558
  val_brier-minFDE6: 6.3895
  val_minADE1: 4.7957
  val_minADE6: 2.6264
  val_minFDE1: 10.9266
  val_minFDE6: 5.6985
  train/loss_epoch: 4.8897
  train/reg_loss_epoch: 1.3039
  train/cls_loss_epoch: 1.8033
  train/others_reg_loss_epoch: 1.7825

Epoch 10:
  train/loss: 4.4698
  train/loss_step: 4.4698
  train/reg_loss: 1.1558
  train/reg_loss_step: 1.1558
  train/cls_loss: 1.6994
  train/cls_loss_step: 1.6994
  train/others_reg_loss: 1.6146
  train/others_reg_loss_step: 1.6146
  val/reg_loss: 1.0818
  val_MR: 0.6166
  val_brier-minFDE6: 5.8092
  val_minADE1: 4.0315
  val_minADE6: 2.4146
  val_minFDE1: 9.5580
  val_minFDE6: 5.1620
  train/loss_epoch: 4.6051
  train/reg_loss_epoch: 1.2044
  train/cls_loss_epoch: 1.7842
  train/others_reg_loss_epoch: 1.6165

Epoch 11:
  train/loss: 3.8013
  train/loss_step: 3.8013
  train/reg_loss: 0.9556
  train/reg_loss_step: 0.9556
  train/cls_loss: 1.7334
  train/cls_loss_step: 1.7334
  train/others_reg_loss: 1.1123
  train/others_reg_loss_step: 1.1123
  val/reg_loss: 1.0371
  val_MR: 0.6080
  val_brier-minFDE6: 5.9209
  val_minADE1: 4.4662
  val_minADE6: 2.3170
  val_minFDE1: 11.0004
  val_minFDE6: 5.2644
  train/loss_epoch: 4.4987
  train/reg_loss_epoch: 1.2009
  train/cls_loss_epoch: 1.7739
  train/others_reg_loss_epoch: 1.5239

Epoch 12:
  train/loss: 4.2171
  train/loss_step: 4.2171
  train/reg_loss: 1.0325
  train/reg_loss_step: 1.0325
  train/cls_loss: 1.8033
  train/cls_loss_step: 1.8033
  train/others_reg_loss: 1.3812
  train/others_reg_loss_step: 1.3812
  val/reg_loss: 1.0057
  val_MR: 0.6116
  val_brier-minFDE6: 5.8714
  val_minADE1: 4.1413
  val_minADE6: 2.2572
  val_minFDE1: 10.5137
  val_minFDE6: 5.2099
  train/loss_epoch: 4.3612
  train/reg_loss_epoch: 1.1476
  train/cls_loss_epoch: 1.7742
  train/others_reg_loss_epoch: 1.4393

Epoch 13:
  train/loss: 4.3670
  train/loss_step: 4.3670
  train/reg_loss: 1.4102
  train/reg_loss_step: 1.4102
  train/cls_loss: 1.8235
  train/cls_loss_step: 1.8235
  train/others_reg_loss: 1.1332
  train/others_reg_loss_step: 1.1332
  val/reg_loss: 1.0700
  val_MR: 0.5837
  val_brier-minFDE6: 5.9646
  val_minADE1: 5.1017
  val_minADE6: 2.3849
  val_minFDE1: 12.0195
  val_minFDE6: 5.2711
  train/loss_epoch: 4.1177
  train/reg_loss_epoch: 1.0637
  train/cls_loss_epoch: 1.7578
  train/others_reg_loss_epoch: 1.2962

Epoch 14:
  train/loss: 3.6021
  train/loss_step: 3.6021
  train/reg_loss: 0.8060
  train/reg_loss_step: 0.8060
  train/cls_loss: 1.7645
  train/cls_loss_step: 1.7645
  train/others_reg_loss: 1.0316
  train/others_reg_loss_step: 1.0316
  val/reg_loss: 0.9837
  val_MR: 0.5691
  val_brier-minFDE6: 5.6930
  val_minADE1: 3.8647
  val_minADE6: 2.2215
  val_minFDE1: 9.7372
  val_minFDE6: 5.0324
  train/loss_epoch: 4.1409
  train/reg_loss_epoch: 1.0737
  train/cls_loss_epoch: 1.7642
  train/others_reg_loss_epoch: 1.3031

Epoch 15:
  train/loss: 3.4660
  train/loss_step: 3.4660
  train/reg_loss: 0.6486
  train/reg_loss_step: 0.6486
  train/cls_loss: 1.6742
  train/cls_loss_step: 1.6742
  train/others_reg_loss: 1.1432
  train/others_reg_loss_step: 1.1432
  val/reg_loss: 0.9813
  val_MR: 0.5845
  val_brier-minFDE6: 5.6741
  val_minADE1: 3.7653
  val_minADE6: 2.2219
  val_minFDE1: 9.3106
  val_minFDE6: 5.0255
  train/loss_epoch: 3.9670
  train/reg_loss_epoch: 1.0156
  train/cls_loss_epoch: 1.7341
  train/others_reg_loss_epoch: 1.2174

Epoch 16:
  train/loss: 4.8402
  train/loss_step: 4.8402
  train/reg_loss: 1.5474
  train/reg_loss_step: 1.5474
  train/cls_loss: 1.7779
  train/cls_loss_step: 1.7779
  train/others_reg_loss: 1.5148
  train/others_reg_loss_step: 1.5148
  val/reg_loss: 0.9814
  val_MR: 0.5431
  val_brier-minFDE6: 5.2765
  val_minADE1: 4.2927
  val_minADE6: 2.2300
  val_minFDE1: 9.8871
  val_minFDE6: 4.6151
  train/loss_epoch: 3.9644
  train/reg_loss_epoch: 1.0140
  train/cls_loss_epoch: 1.7502
  train/others_reg_loss_epoch: 1.2002

Epoch 17:
  train/loss: 3.4227
  train/loss_step: 3.4227
  train/reg_loss: 0.7466
  train/reg_loss_step: 0.7466
  train/cls_loss: 1.6387
  train/cls_loss_step: 1.6387
  train/others_reg_loss: 1.0375
  train/others_reg_loss_step: 1.0375
  val/reg_loss: 0.7957
  val_MR: 0.4914
  val_brier-minFDE6: 4.8236
  val_minADE1: 3.4087
  val_minADE6: 1.8420
  val_minFDE1: 8.5770
  val_minFDE6: 4.1805
  train/loss_epoch: 3.7985
  train/reg_loss_epoch: 0.9435
  train/cls_loss_epoch: 1.6925
  train/others_reg_loss_epoch: 1.1625

Epoch 18:
  train/loss: 3.4412
  train/loss_step: 3.4412
  train/reg_loss: 0.8692
  train/reg_loss_step: 0.8692
  train/cls_loss: 1.6149
  train/cls_loss_step: 1.6149
  train/others_reg_loss: 0.9571
  train/others_reg_loss_step: 0.9571
  val/reg_loss: 0.7365
  val_MR: 0.4914
  val_brier-minFDE6: 4.5549
  val_minADE1: 3.2598
  val_minADE6: 1.7275
  val_minFDE1: 8.2723
  val_minFDE6: 3.9188
  train/loss_epoch: 3.6871
  train/reg_loss_epoch: 0.8616
  train/cls_loss_epoch: 1.6992
  train/others_reg_loss_epoch: 1.1263

Epoch 19:
  train/loss: 3.1528
  train/loss_step: 3.1528
  train/reg_loss: 0.6222
  train/reg_loss_step: 0.6222
  train/cls_loss: 1.6508
  train/cls_loss_step: 1.6508
  train/others_reg_loss: 0.8798
  train/others_reg_loss_step: 0.8798
  val/reg_loss: 0.7065
  val_MR: 0.4790
  val_brier-minFDE6: 4.4091
  val_minADE1: 3.3018
  val_minADE6: 1.6725
  val_minFDE1: 8.3605
  val_minFDE6: 3.7691
  train/loss_epoch: 3.5350
  train/reg_loss_epoch: 0.7821
  train/cls_loss_epoch: 1.6693
  train/others_reg_loss_epoch: 1.0836

Epoch 20:
  train/loss: 3.5903
  train/loss_step: 3.5903
  train/reg_loss: 0.8234
  train/reg_loss_step: 0.8234
  train/cls_loss: 1.6081
  train/cls_loss_step: 1.6081
  train/others_reg_loss: 1.1589
  train/others_reg_loss_step: 1.1589
  val/reg_loss: 0.6906
  val_MR: 0.4722
  val_brier-minFDE6: 4.3469
  val_minADE1: 3.1898
  val_minADE6: 1.6389
  val_minFDE1: 8.1895
  val_minFDE6: 3.7168
  train/loss_epoch: 3.4419
  train/reg_loss_epoch: 0.7262
  train/cls_loss_epoch: 1.6570
  train/others_reg_loss_epoch: 1.0587

FINAL VALIDATION RESULTS:
  train/loss: 3.3900
  train/loss_step: 3.5903
  train/reg_loss: 0.6948
  train/reg_loss_step: 0.8234
  train/cls_loss: 1.6428
  train/cls_loss_step: 1.6081
  train/others_reg_loss: 1.0524
  train/others_reg_loss_step: 1.1589
  val/reg_loss: 0.6906
  val_MR: 0.4722
  val_brier-minFDE6: 4.3469
  val_minADE1: 3.1898
  val_minADE6: 1.6389
  val_minFDE1: 8.1895
  val_minFDE6: 3.7168
  train/loss_epoch: 3.3900
  train/reg_loss_epoch: 0.6948
  train/cls_loss_epoch: 1.6428
  train/others_reg_loss_epoch: 1.0524

================================================================================

Experiment 19
--------------------------------------------------
HYPERPARAMETERS:
  dim: 32
  encoder_depth: 4
  num_heads: 8
  mlp_ratio: 5
  attention_type: performer
  decoder_embed_dim: 32
  decoder_num_modes: 3
  decoder_hidden_dim: 64
  model_params: 340,081

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4275
  val_MR: 0.9609
  val_brier-minFDE6: 40.9095
  val_minADE1: 20.4086
  val_minADE6: 20.3985
  val_minFDE1: 40.5184
  val_minFDE6: 40.4655

Epoch 1:
  train/loss: 11.8289
  train/loss_step: 11.8289
  train/reg_loss: 7.4444
  train/reg_loss_step: 7.4444
  train/cls_loss: 0.6195
  train/cls_loss_step: 0.6195
  train/others_reg_loss: 3.7651
  train/others_reg_loss_step: 3.7651
  val/reg_loss: 7.5101
  val_MR: 0.9750
  val_brier-minFDE6: 39.9089
  val_minADE1: 14.9883
  val_minADE6: 14.7714
  val_minFDE1: 39.1506
  val_minFDE6: 38.9998

Epoch 2:
  train/loss: 6.0756
  train/loss_step: 6.0756
  train/reg_loss: 1.6051
  train/reg_loss_step: 1.6051
  train/cls_loss: 1.1127
  train/cls_loss_step: 1.1127
  train/others_reg_loss: 3.3577
  train/others_reg_loss_step: 3.3577
  val/reg_loss: 2.0513
  val_MR: 0.8313
  val_brier-minFDE6: 17.3626
  val_minADE1: 7.3435
  val_minADE6: 4.1983
  val_minFDE1: 18.5883
  val_minFDE6: 17.0112
  train/loss_epoch: 13.7099
  train/reg_loss_epoch: 9.1874
  train/cls_loss_epoch: 0.6416
  train/others_reg_loss_epoch: 3.8809

Epoch 3:
  train/loss: 6.8459
  train/loss_step: 6.8459
  train/reg_loss: 1.7031
  train/reg_loss_step: 1.7031
  train/cls_loss: 1.0622
  train/cls_loss_step: 1.0622
  train/others_reg_loss: 4.0807
  train/others_reg_loss_step: 4.0807
  val/reg_loss: 1.7272
  val_MR: 0.8067
  val_brier-minFDE6: 8.1298
  val_minADE1: 6.2083
  val_minADE6: 3.5814
  val_minFDE1: 12.2334
  val_minFDE6: 7.7019
  train/loss_epoch: 8.8686
  train/reg_loss_epoch: 4.1246
  train/cls_loss_epoch: 0.8697
  train/others_reg_loss_epoch: 3.8743

Epoch 4:
  train/loss: 6.7838
  train/loss_step: 6.7838
  train/reg_loss: 2.2317
  train/reg_loss_step: 2.2317
  train/cls_loss: 1.0755
  train/cls_loss_step: 1.0755
  train/others_reg_loss: 3.4767
  train/others_reg_loss_step: 3.4767
  val/reg_loss: 1.5276
  val_MR: 0.7686
  val_brier-minFDE6: 7.5183
  val_minADE1: 5.2494
  val_minADE6: 3.1982
  val_minFDE1: 11.7112
  val_minFDE6: 7.0904
  train/loss_epoch: 6.7334
  train/reg_loss_epoch: 1.8389
  train/cls_loss_epoch: 1.0820
  train/others_reg_loss_epoch: 3.8125

Epoch 5:
  train/loss: 4.6173
  train/loss_step: 4.6173
  train/reg_loss: 1.4671
  train/reg_loss_step: 1.4671
  train/cls_loss: 0.9550
  train/cls_loss_step: 0.9550
  train/others_reg_loss: 2.1952
  train/others_reg_loss_step: 2.1952
  val/reg_loss: 1.4176
  val_MR: 0.7610
  val_brier-minFDE6: 6.9259
  val_minADE1: 4.4213
  val_minADE6: 3.0049
  val_minFDE1: 10.1706
  val_minFDE6: 6.5175
  train/loss_epoch: 6.5114
  train/reg_loss_epoch: 1.6705
  train/cls_loss_epoch: 1.0960
  train/others_reg_loss_epoch: 3.7449

Epoch 6:
  train/loss: 4.3537
  train/loss_step: 4.3537
  train/reg_loss: 1.2567
  train/reg_loss_step: 1.2567
  train/cls_loss: 0.9912
  train/cls_loss_step: 0.9912
  train/others_reg_loss: 2.1057
  train/others_reg_loss_step: 2.1057
  val/reg_loss: 1.4015
  val_MR: 0.7668
  val_brier-minFDE6: 6.9469
  val_minADE1: 4.4780
  val_minADE6: 2.9775
  val_minFDE1: 10.2434
  val_minFDE6: 6.5201
  train/loss_epoch: 5.5367
  train/reg_loss_epoch: 1.5672
  train/cls_loss_epoch: 1.0770
  train/others_reg_loss_epoch: 2.8925

Epoch 7:
  train/loss: 5.1645
  train/loss_step: 5.1645
  train/reg_loss: 1.5866
  train/reg_loss_step: 1.5866
  train/cls_loss: 1.0620
  train/cls_loss_step: 1.0620
  train/others_reg_loss: 2.5159
  train/others_reg_loss_step: 2.5159
  val/reg_loss: 1.3085
  val_MR: 0.7552
  val_brier-minFDE6: 6.8560
  val_minADE1: 4.7211
  val_minADE6: 2.7964
  val_minFDE1: 11.4818
  val_minFDE6: 6.4279
  train/loss_epoch: 4.7193
  train/reg_loss_epoch: 1.4173
  train/cls_loss_epoch: 1.0684
  train/others_reg_loss_epoch: 2.2336

Epoch 8:
  train/loss: 3.3366
  train/loss_step: 3.3366
  train/reg_loss: 0.8795
  train/reg_loss_step: 0.8795
  train/cls_loss: 1.0512
  train/cls_loss_step: 1.0512
  train/others_reg_loss: 1.4059
  train/others_reg_loss_step: 1.4059
  val/reg_loss: 1.3433
  val_MR: 0.7658
  val_brier-minFDE6: 6.8510
  val_minADE1: 4.5376
  val_minADE6: 2.8503
  val_minFDE1: 10.3946
  val_minFDE6: 6.4488
  train/loss_epoch: 4.5278
  train/reg_loss_epoch: 1.3708
  train/cls_loss_epoch: 1.0675
  train/others_reg_loss_epoch: 2.0895

Epoch 9:
  train/loss: 4.0420
  train/loss_step: 4.0420
  train/reg_loss: 1.1056
  train/reg_loss_step: 1.1056
  train/cls_loss: 1.1360
  train/cls_loss_step: 1.1360
  train/others_reg_loss: 1.8004
  train/others_reg_loss_step: 1.8004
  val/reg_loss: 1.3003
  val_MR: 0.7544
  val_brier-minFDE6: 6.7260
  val_minADE1: 4.6990
  val_minADE6: 2.7809
  val_minFDE1: 10.7768
  val_minFDE6: 6.3066
  train/loss_epoch: 4.5269
  train/reg_loss_epoch: 1.3956
  train/cls_loss_epoch: 1.0834
  train/others_reg_loss_epoch: 2.0480

Epoch 10:
  train/loss: 4.3453
  train/loss_step: 4.3453
  train/reg_loss: 1.6130
  train/reg_loss_step: 1.6130
  train/cls_loss: 1.1891
  train/cls_loss_step: 1.1891
  train/others_reg_loss: 1.5432
  train/others_reg_loss_step: 1.5432
  val/reg_loss: 1.2819
  val_MR: 0.7680
  val_brier-minFDE6: 6.7714
  val_minADE1: 4.3456
  val_minADE6: 2.7481
  val_minFDE1: 10.3397
  val_minFDE6: 6.3423
  train/loss_epoch: 4.2058
  train/reg_loss_epoch: 1.3995
  train/cls_loss_epoch: 1.0864
  train/others_reg_loss_epoch: 1.7199

Epoch 11:
  train/loss: 3.7497
  train/loss_step: 3.7497
  train/reg_loss: 1.3282
  train/reg_loss_step: 1.3282
  train/cls_loss: 1.1007
  train/cls_loss_step: 1.1007
  train/others_reg_loss: 1.3208
  train/others_reg_loss_step: 1.3208
  val/reg_loss: 1.2704
  val_MR: 0.7426
  val_brier-minFDE6: 6.6757
  val_minADE1: 4.0366
  val_minADE6: 2.7268
  val_minFDE1: 9.7462
  val_minFDE6: 6.2503
  train/loss_epoch: 3.9846
  train/reg_loss_epoch: 1.3540
  train/cls_loss_epoch: 1.0883
  train/others_reg_loss_epoch: 1.5424

Epoch 12:
  train/loss: 3.7171
  train/loss_step: 3.7171
  train/reg_loss: 1.4004
  train/reg_loss_step: 1.4004
  train/cls_loss: 1.0167
  train/cls_loss_step: 1.0167
  train/others_reg_loss: 1.2999
  train/others_reg_loss_step: 1.2999
  val/reg_loss: 1.2620
  val_MR: 0.7398
  val_brier-minFDE6: 6.5500
  val_minADE1: 4.0370
  val_minADE6: 2.7324
  val_minFDE1: 9.5466
  val_minFDE6: 6.1213
  train/loss_epoch: 3.9322
  train/reg_loss_epoch: 1.3725
  train/cls_loss_epoch: 1.0849
  train/others_reg_loss_epoch: 1.4748

Epoch 13:
  train/loss: 3.7175
  train/loss_step: 3.7175
  train/reg_loss: 1.3227
  train/reg_loss_step: 1.3227
  train/cls_loss: 1.0551
  train/cls_loss_step: 1.0551
  train/others_reg_loss: 1.3396
  train/others_reg_loss_step: 1.3396
  val/reg_loss: 1.3118
  val_MR: 0.7506
  val_brier-minFDE6: 6.7818
  val_minADE1: 4.5388
  val_minADE6: 2.8107
  val_minFDE1: 10.6035
  val_minFDE6: 6.3396
  train/loss_epoch: 3.8386
  train/reg_loss_epoch: 1.3041
  train/cls_loss_epoch: 1.0911
  train/others_reg_loss_epoch: 1.4433

Epoch 14:
  train/loss: 3.5338
  train/loss_step: 3.5338
  train/reg_loss: 1.0064
  train/reg_loss_step: 1.0064
  train/cls_loss: 1.0539
  train/cls_loss_step: 1.0539
  train/others_reg_loss: 1.4736
  train/others_reg_loss_step: 1.4736
  val/reg_loss: 1.2228
  val_MR: 0.7636
  val_brier-minFDE6: 6.6577
  val_minADE1: 3.7214
  val_minADE6: 2.6398
  val_minFDE1: 9.2638
  val_minFDE6: 6.2471
  train/loss_epoch: 3.7359
  train/reg_loss_epoch: 1.2873
  train/cls_loss_epoch: 1.0798
  train/others_reg_loss_epoch: 1.3688

Epoch 15:
  train/loss: 3.5168
  train/loss_step: 3.5168
  train/reg_loss: 1.2229
  train/reg_loss_step: 1.2229
  train/cls_loss: 1.0962
  train/cls_loss_step: 1.0962
  train/others_reg_loss: 1.1977
  train/others_reg_loss_step: 1.1977
  val/reg_loss: 1.1605
  val_MR: 0.7268
  val_brier-minFDE6: 6.4489
  val_minADE1: 3.8051
  val_minADE6: 2.5210
  val_minFDE1: 9.5472
  val_minFDE6: 6.0263
  train/loss_epoch: 3.5886
  train/reg_loss_epoch: 1.2309
  train/cls_loss_epoch: 1.0711
  train/others_reg_loss_epoch: 1.2866

Epoch 16:
  train/loss: 3.5735
  train/loss_step: 3.5735
  train/reg_loss: 1.4192
  train/reg_loss_step: 1.4192
  train/cls_loss: 1.0179
  train/cls_loss_step: 1.0179
  train/others_reg_loss: 1.1364
  train/others_reg_loss_step: 1.1364
  val/reg_loss: 1.1600
  val_MR: 0.7025
  val_brier-minFDE6: 6.4151
  val_minADE1: 3.8170
  val_minADE6: 2.5125
  val_minFDE1: 9.4933
  val_minFDE6: 5.9910
  train/loss_epoch: 3.5850
  train/reg_loss_epoch: 1.2274
  train/cls_loss_epoch: 1.0742
  train/others_reg_loss_epoch: 1.2834

Epoch 17:
  train/loss: 3.6724
  train/loss_step: 3.6724
  train/reg_loss: 1.3430
  train/reg_loss_step: 1.3430
  train/cls_loss: 1.0100
  train/cls_loss_step: 1.0100
  train/others_reg_loss: 1.3194
  train/others_reg_loss_step: 1.3194
  val/reg_loss: 1.1412
  val_MR: 0.7055
  val_brier-minFDE6: 6.3304
  val_minADE1: 3.6908
  val_minADE6: 2.4833
  val_minFDE1: 9.2413
  val_minFDE6: 5.9243
  train/loss_epoch: 3.4606
  train/reg_loss_epoch: 1.1768
  train/cls_loss_epoch: 1.0516
  train/others_reg_loss_epoch: 1.2323

Epoch 18:
  train/loss: 2.9681
  train/loss_step: 2.9681
  train/reg_loss: 1.0348
  train/reg_loss_step: 1.0348
  train/cls_loss: 1.0443
  train/cls_loss_step: 1.0443
  train/others_reg_loss: 0.8890
  train/others_reg_loss_step: 0.8890
  val/reg_loss: 1.1328
  val_MR: 0.6975
  val_brier-minFDE6: 6.2819
  val_minADE1: 3.5411
  val_minADE6: 2.4725
  val_minFDE1: 8.8793
  val_minFDE6: 5.8832
  train/loss_epoch: 3.4285
  train/reg_loss_epoch: 1.1650
  train/cls_loss_epoch: 1.0438
  train/others_reg_loss_epoch: 1.2197

Epoch 19:
  train/loss: 3.8941
  train/loss_step: 3.8941
  train/reg_loss: 1.4102
  train/reg_loss_step: 1.4102
  train/cls_loss: 0.9936
  train/cls_loss_step: 0.9936
  train/others_reg_loss: 1.4903
  train/others_reg_loss_step: 1.4903
  val/reg_loss: 1.1295
  val_MR: 0.6987
  val_brier-minFDE6: 6.2668
  val_minADE1: 3.5474
  val_minADE6: 2.4641
  val_minFDE1: 8.8935
  val_minFDE6: 5.8668
  train/loss_epoch: 3.3474
  train/reg_loss_epoch: 1.1320
  train/cls_loss_epoch: 1.0328
  train/others_reg_loss_epoch: 1.1827

Epoch 20:
  train/loss: 3.4690
  train/loss_step: 3.4690
  train/reg_loss: 1.1405
  train/reg_loss_step: 1.1405
  train/cls_loss: 1.0351
  train/cls_loss_step: 1.0351
  train/others_reg_loss: 1.2934
  train/others_reg_loss_step: 1.2934
  val/reg_loss: 1.1200
  val_MR: 0.7043
  val_brier-minFDE6: 6.2541
  val_minADE1: 3.6107
  val_minADE6: 2.4416
  val_minFDE1: 9.0708
  val_minFDE6: 5.8560
  train/loss_epoch: 3.3343
  train/reg_loss_epoch: 1.1354
  train/cls_loss_epoch: 1.0233
  train/others_reg_loss_epoch: 1.1757

FINAL VALIDATION RESULTS:
  train/loss: 3.2687
  train/loss_step: 3.4690
  train/reg_loss: 1.0946
  train/reg_loss_step: 1.1405
  train/cls_loss: 1.0202
  train/cls_loss_step: 1.0351
  train/others_reg_loss: 1.1539
  train/others_reg_loss_step: 1.2934
  val/reg_loss: 1.1200
  val_MR: 0.7043
  val_brier-minFDE6: 6.2541
  val_minADE1: 3.6107
  val_minADE6: 2.4416
  val_minFDE1: 9.0708
  val_minFDE6: 5.8560
  train/loss_epoch: 3.2687
  train/reg_loss_epoch: 1.0946
  train/cls_loss_epoch: 1.0202
  train/others_reg_loss_epoch: 1.1539

================================================================================

Experiment 20
--------------------------------------------------
HYPERPARAMETERS:
  dim: 24
  encoder_depth: 3
  num_heads: 4
  mlp_ratio: 4
  attention_type: performer
  decoder_embed_dim: 24
  decoder_num_modes: 9
  decoder_hidden_dim: 192
  model_params: 271,937

TRAINING PROGRESS:
Epoch 1:
  val/reg_loss: 10.4325
  val_MR: 0.9609
  val_brier-minFDE6: 40.6413
  val_minADE1: 20.4228
  val_minADE6: 20.4143
  val_minFDE1: 39.9767
  val_minFDE6: 39.9479

Epoch 1:
  train/loss: 13.7905
  train/loss_step: 13.7905
  train/reg_loss: 9.0086
  train/reg_loss_step: 9.0086
  train/cls_loss: 0.6829
  train/cls_loss_step: 0.6829
  train/others_reg_loss: 4.0990
  train/others_reg_loss_step: 4.0990
  val/reg_loss: 7.7171
  val_MR: 0.9079
  val_brier-minFDE6: 33.2644
  val_minADE1: 15.3975
  val_minADE6: 15.1548
  val_minFDE1: 33.1788
  val_minFDE6: 33.0904

Epoch 2:
  train/loss: 7.9776
  train/loss_step: 7.9776
  train/reg_loss: 2.8061
  train/reg_loss_step: 2.8061
  train/cls_loss: 1.4990
  train/cls_loss_step: 1.4990
  train/others_reg_loss: 3.6725
  train/others_reg_loss_step: 3.6725
  val/reg_loss: 2.4580
  val_MR: 0.7899
  val_brier-minFDE6: 14.4835
  val_minADE1: 7.0565
  val_minADE6: 4.9766
  val_minFDE1: 17.0931
  val_minFDE6: 14.0583
  train/loss_epoch: 14.4335
  train/reg_loss_epoch: 9.2831
  train/cls_loss_epoch: 1.2763
  train/others_reg_loss_epoch: 3.8741

Epoch 3:
  train/loss: 6.7446
  train/loss_step: 6.7446
  train/reg_loss: 1.4073
  train/reg_loss_step: 1.4073
  train/cls_loss: 2.0422
  train/cls_loss_step: 2.0422
  train/others_reg_loss: 3.2951
  train/others_reg_loss_step: 3.2951
  val/reg_loss: 1.5166
  val_MR: 0.7131
  val_brier-minFDE6: 7.7915
  val_minADE1: 9.1643
  val_minADE6: 3.2546
  val_minFDE1: 18.7317
  val_minFDE6: 7.1245
  train/loss_epoch: 9.5614
  train/reg_loss_epoch: 4.5155
  train/cls_loss_epoch: 1.1545
  train/others_reg_loss_epoch: 3.8915

Epoch 4:
  train/loss: 6.3937
  train/loss_step: 6.3937
  train/reg_loss: 0.9890
  train/reg_loss_step: 0.9890
  train/cls_loss: 2.2317
  train/cls_loss_step: 2.2317
  train/others_reg_loss: 3.1730
  train/others_reg_loss_step: 3.1730
  val/reg_loss: 1.2088
  val_MR: 0.6909
  val_brier-minFDE6: 7.4637
  val_minADE1: 10.0060
  val_minADE6: 3.1704
  val_minFDE1: 20.7803
  val_minFDE6: 6.7606
  train/loss_epoch: 7.4125
  train/reg_loss_epoch: 1.8170
  train/cls_loss_epoch: 1.8197
  train/others_reg_loss_epoch: 3.7758

Epoch 5:
  train/loss: 5.5412
  train/loss_step: 5.5412
  train/reg_loss: 1.1497
  train/reg_loss_step: 1.1497
  train/cls_loss: 2.1603
  train/cls_loss_step: 2.1603
  train/others_reg_loss: 2.2312
  train/others_reg_loss_step: 2.2312
  val/reg_loss: 1.1202
  val_MR: 0.5707
  val_brier-minFDE6: 6.5805
  val_minADE1: 5.0926
  val_minADE6: 2.7711
  val_minFDE1: 11.5260
  val_minFDE6: 5.8930
  train/loss_epoch: 6.5395
  train/reg_loss_epoch: 1.2694
  train/cls_loss_epoch: 2.1542
  train/others_reg_loss_epoch: 3.1159

Epoch 6:
  train/loss: 4.7661
  train/loss_step: 4.7661
  train/reg_loss: 1.0227
  train/reg_loss_step: 1.0227
  train/cls_loss: 2.1030
  train/cls_loss_step: 2.1030
  train/others_reg_loss: 1.6404
  train/others_reg_loss_step: 1.6404
  val/reg_loss: 1.1466
  val_MR: 0.5938
  val_brier-minFDE6: 7.0892
  val_minADE1: 6.0389
  val_minADE6: 3.0939
  val_minFDE1: 12.9423
  val_minFDE6: 6.3876
  train/loss_epoch: 5.7169
  train/reg_loss_epoch: 1.1498
  train/cls_loss_epoch: 2.1717
  train/others_reg_loss_epoch: 2.3954

Epoch 7:
  train/loss: 5.0585
  train/loss_step: 5.0585
  train/reg_loss: 1.0745
  train/reg_loss_step: 1.0745
  train/cls_loss: 2.1269
  train/cls_loss_step: 2.1269
  train/others_reg_loss: 1.8572
  train/others_reg_loss_step: 1.8572
  val/reg_loss: 1.0658
  val_MR: 0.5835
  val_brier-minFDE6: 6.7607
  val_minADE1: 6.9412
  val_minADE6: 2.9028
  val_minFDE1: 14.7108
  val_minFDE6: 6.0615
  train/loss_epoch: 5.3756
  train/reg_loss_epoch: 1.0996
  train/cls_loss_epoch: 2.1368
  train/others_reg_loss_epoch: 2.1392

Epoch 8:
  train/loss: 5.5752
  train/loss_step: 5.5752
  train/reg_loss: 1.5130
  train/reg_loss_step: 1.5130
  train/cls_loss: 2.1376
  train/cls_loss_step: 2.1376
  train/others_reg_loss: 1.9246
  train/others_reg_loss_step: 1.9246
  val/reg_loss: 1.1182
  val_MR: 0.6026
  val_brier-minFDE6: 7.1063
  val_minADE1: 4.9350
  val_minADE6: 2.8476
  val_minFDE1: 11.9035
  val_minFDE6: 6.4010
  train/loss_epoch: 5.1858
  train/reg_loss_epoch: 1.0890
  train/cls_loss_epoch: 2.1493
  train/others_reg_loss_epoch: 1.9475

Epoch 9:
  train/loss: 5.4676
  train/loss_step: 5.4676
  train/reg_loss: 1.4037
  train/reg_loss_step: 1.4037
  train/cls_loss: 2.2460
  train/cls_loss_step: 2.2460
  train/others_reg_loss: 1.8178
  train/others_reg_loss_step: 1.8178
  val/reg_loss: 1.0493
  val_MR: 0.6725
  val_brier-minFDE6: 7.5853
  val_minADE1: 5.3105
  val_minADE6: 2.9331
  val_minFDE1: 12.8844
  val_minFDE6: 6.8912
  train/loss_epoch: 4.9730
  train/reg_loss_epoch: 1.0707
  train/cls_loss_epoch: 2.1565
  train/others_reg_loss_epoch: 1.7458

Epoch 10:
  train/loss: 5.1008
  train/loss_step: 5.1008
  train/reg_loss: 1.1361
  train/reg_loss_step: 1.1361
  train/cls_loss: 2.3252
  train/cls_loss_step: 2.3252
  train/others_reg_loss: 1.6395
  train/others_reg_loss_step: 1.6395
  val/reg_loss: 0.9780
  val_MR: 0.5791
  val_brier-minFDE6: 6.7545
  val_minADE1: 5.8975
  val_minADE6: 2.6832
  val_minFDE1: 13.8548
  val_minFDE6: 6.0396
  train/loss_epoch: 4.8504
  train/reg_loss_epoch: 1.0707
  train/cls_loss_epoch: 2.1377
  train/others_reg_loss_epoch: 1.6420

Epoch 11:
  train/loss: 4.4410
  train/loss_step: 4.4410
  train/reg_loss: 0.8773
  train/reg_loss_step: 0.8773
  train/cls_loss: 2.1088
  train/cls_loss_step: 2.1088
  train/others_reg_loss: 1.4549
  train/others_reg_loss_step: 1.4549
  val/reg_loss: 0.9731
  val_MR: 0.5355
  val_brier-minFDE6: 6.2904
  val_minADE1: 4.2796
  val_minADE6: 2.4918
  val_minFDE1: 10.4371
  val_minFDE6: 5.6026
  train/loss_epoch: 4.7441
  train/reg_loss_epoch: 1.0276
  train/cls_loss_epoch: 2.1412
  train/others_reg_loss_epoch: 1.5754

Epoch 12:
  train/loss: 4.0068
  train/loss_step: 4.0068
  train/reg_loss: 0.6475
  train/reg_loss_step: 0.6475
  train/cls_loss: 2.0811
  train/cls_loss_step: 2.0811
  train/others_reg_loss: 1.2782
  train/others_reg_loss_step: 1.2782
  val/reg_loss: 0.9521
  val_MR: 0.5347
  val_brier-minFDE6: 6.1920
  val_minADE1: 4.1918
  val_minADE6: 2.4260
  val_minFDE1: 10.2580
  val_minFDE6: 5.5009
  train/loss_epoch: 4.6459
  train/reg_loss_epoch: 1.0272
  train/cls_loss_epoch: 2.1455
  train/others_reg_loss_epoch: 1.4732

Epoch 13:
  train/loss: 4.2876
  train/loss_step: 4.2876
  train/reg_loss: 0.6591
  train/reg_loss_step: 0.6591
  train/cls_loss: 2.1197
  train/cls_loss_step: 2.1197
  train/others_reg_loss: 1.5088
  train/others_reg_loss_step: 1.5088
  val/reg_loss: 1.0203
  val_MR: 0.5339
  val_brier-minFDE6: 6.2074
  val_minADE1: 4.1245
  val_minADE6: 2.5983
  val_minFDE1: 9.8525
  val_minFDE6: 5.5176
  train/loss_epoch: 4.5132
  train/reg_loss_epoch: 1.0015
  train/cls_loss_epoch: 2.1238
  train/others_reg_loss_epoch: 1.3878

Epoch 14:
  train/loss: 4.1307
  train/loss_step: 4.1307
  train/reg_loss: 0.9031
  train/reg_loss_step: 0.9031
  train/cls_loss: 2.1052
  train/cls_loss_step: 2.1052
  train/others_reg_loss: 1.1224
  train/others_reg_loss_step: 1.1224
  val/reg_loss: 0.9321
  val_MR: 0.5192
  val_brier-minFDE6: 6.0452
  val_minADE1: 4.2063
  val_minADE6: 2.3687
  val_minFDE1: 10.2952
  val_minFDE6: 5.3583
  train/loss_epoch: 4.3933
  train/reg_loss_epoch: 0.9668
  train/cls_loss_epoch: 2.1006
  train/others_reg_loss_epoch: 1.3259

Epoch 15:
  train/loss: 4.3650
  train/loss_step: 4.3650
  train/reg_loss: 0.7264
  train/reg_loss_step: 0.7264
  train/cls_loss: 2.2951
  train/cls_loss_step: 2.2951
  train/others_reg_loss: 1.3435
  train/others_reg_loss_step: 1.3435
  val/reg_loss: 0.9210
  val_MR: 0.5268
  val_brier-minFDE6: 6.6170
  val_minADE1: 4.2954
  val_minADE6: 2.5482
  val_minFDE1: 10.7512
  val_minFDE6: 5.9050
  train/loss_epoch: 4.3710
  train/reg_loss_epoch: 0.9531
  train/cls_loss_epoch: 2.1203
  train/others_reg_loss_epoch: 1.2976

Epoch 16:
  train/loss: 4.3841
  train/loss_step: 4.3841
  train/reg_loss: 0.9923
  train/reg_loss_step: 0.9923
  train/cls_loss: 2.0363
  train/cls_loss_step: 2.0363
  train/others_reg_loss: 1.3555
  train/others_reg_loss_step: 1.3555
  val/reg_loss: 0.9003
  val_MR: 0.4910
  val_brier-minFDE6: 5.9503
  val_minADE1: 3.8044
  val_minADE6: 2.2743
  val_minFDE1: 9.5480
  val_minFDE6: 5.2677
  train/loss_epoch: 4.2427
  train/reg_loss_epoch: 0.9187
  train/cls_loss_epoch: 2.0733
  train/others_reg_loss_epoch: 1.2506

Epoch 17:
  train/loss: 4.1862
  train/loss_step: 4.1862
  train/reg_loss: 1.1503
  train/reg_loss_step: 1.1503
  train/cls_loss: 2.0636
  train/cls_loss_step: 2.0636
  train/others_reg_loss: 0.9723
  train/others_reg_loss_step: 0.9723
  val/reg_loss: 0.9333
  val_MR: 0.5128
  val_brier-minFDE6: 6.0204
  val_minADE1: 4.2201
  val_minADE6: 2.3758
  val_minFDE1: 10.1465
  val_minFDE6: 5.3278
  train/loss_epoch: 4.2511
  train/reg_loss_epoch: 0.9354
  train/cls_loss_epoch: 2.0934
  train/others_reg_loss_epoch: 1.2223

Epoch 18:
  train/loss: 4.3543
  train/loss_step: 4.3543
  train/reg_loss: 1.0678
  train/reg_loss_step: 1.0678
  train/cls_loss: 2.1452
  train/cls_loss_step: 2.1452
  train/others_reg_loss: 1.1413
  train/others_reg_loss_step: 1.1413
  val/reg_loss: 0.9029
  val_MR: 0.4968
  val_brier-minFDE6: 5.9580
  val_minADE1: 3.8462
  val_minADE6: 2.2864
  val_minFDE1: 9.6982
  val_minFDE6: 5.2720
  train/loss_epoch: 4.1104
  train/reg_loss_epoch: 0.8896
  train/cls_loss_epoch: 2.0400
  train/others_reg_loss_epoch: 1.1808

Epoch 19:
  train/loss: 3.3395
  train/loss_step: 3.3395
  train/reg_loss: 0.4815
  train/reg_loss_step: 0.4815
  train/cls_loss: 1.9472
  train/cls_loss_step: 1.9472
  train/others_reg_loss: 0.9108
  train/others_reg_loss_step: 0.9108
  val/reg_loss: 0.8947
  val_MR: 0.4830
  val_brier-minFDE6: 5.8208
  val_minADE1: 3.7926
  val_minADE6: 2.2355
  val_minFDE1: 9.5046
  val_minFDE6: 5.1448
  train/loss_epoch: 4.0853
  train/reg_loss_epoch: 0.8965
  train/cls_loss_epoch: 2.0367
  train/others_reg_loss_epoch: 1.1522

Epoch 20:
  train/loss: 3.7280
  train/loss_step: 3.7280
  train/reg_loss: 0.7793
  train/reg_loss_step: 0.7793
  train/cls_loss: 1.9539
  train/cls_loss_step: 1.9539
  train/others_reg_loss: 0.9948
  train/others_reg_loss_step: 0.9948
  val/reg_loss: 0.8921
  val_MR: 0.4778
  val_brier-minFDE6: 5.8568
  val_minADE1: 3.7208
  val_minADE6: 2.2468
  val_minFDE1: 9.3819
  val_minFDE6: 5.1798
  train/loss_epoch: 4.0284
  train/reg_loss_epoch: 0.8657
  train/cls_loss_epoch: 2.0264
  train/others_reg_loss_epoch: 1.1363

FINAL VALIDATION RESULTS:
  train/loss: 4.0226
  train/loss_step: 3.7280
  train/reg_loss: 0.8723
  train/reg_loss_step: 0.7793
  train/cls_loss: 2.0152
  train/cls_loss_step: 1.9539
  train/others_reg_loss: 1.1351
  train/others_reg_loss_step: 0.9948
  val/reg_loss: 0.8921
  val_MR: 0.4778
  val_brier-minFDE6: 5.8568
  val_minADE1: 3.7208
  val_minADE6: 2.2468
  val_minFDE1: 9.3819
  val_minFDE6: 5.1798
  train/loss_epoch: 4.0226
  train/reg_loss_epoch: 0.8723
  train/cls_loss_epoch: 2.0152
  train/others_reg_loss_epoch: 1.1351

================================================================================


================================================================================
SUMMARY
================================================================================
Total experiments: 20
Successful: 20
Failed: 0

TOP 5 CONFIGURATIONS:
--------------------------------------------------

Rank 1 (Experiment 8):
  val_minFDE6: 2.6242
  val_MR: 0.3960
  Parameters: 1,061,649
  Config: {'dim': 96, 'encoder_depth': 5, 'num_heads': 6, 'mlp_ratio': 2, 'attention_type': 'standard', 'decoder_embed_dim': 48, 'decoder_num_modes': 6, 'decoder_hidden_dim': 256}

Rank 2 (Experiment 5):
  val_minFDE6: 2.9492
  val_MR: 0.4028
  Parameters: 2,522,289
  Config: {'dim': 128, 'encoder_depth': 4, 'num_heads': 8, 'mlp_ratio': 6, 'attention_type': 'standard', 'decoder_embed_dim': 128, 'decoder_num_modes': 9, 'decoder_hidden_dim': 192}

Rank 3 (Experiment 12):
  val_minFDE6: 3.0636
  val_MR: 0.4129
  Parameters: 409,329
  Config: {'dim': 64, 'encoder_depth': 2, 'num_heads': 4, 'mlp_ratio': 1, 'attention_type': 'performer', 'decoder_embed_dim': 64, 'decoder_num_modes': 9, 'decoder_hidden_dim': 256}

Rank 4 (Experiment 17):
  val_minFDE6: 3.1259
  val_MR: 0.4677
  Parameters: 404,849
  Config: {'dim': 48, 'encoder_depth': 2, 'num_heads': 2, 'mlp_ratio': 2, 'attention_type': 'performer', 'decoder_embed_dim': 96, 'decoder_num_modes': 6, 'decoder_hidden_dim': 192}

Rank 5 (Experiment 13):
  val_minFDE6: 3.4294
  val_MR: 0.3890
  Parameters: 473,873
  Config: {'dim': 64, 'encoder_depth': 3, 'num_heads': 4, 'mlp_ratio': 2, 'attention_type': 'performer', 'decoder_embed_dim': 32, 'decoder_num_modes': 9, 'decoder_hidden_dim': 256}

Completed: 2025-07-08 23:19:59
